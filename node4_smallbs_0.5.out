/var/spool/slurm/d/job03096/slurm_script:行10: activate: 没有那个文件或目录
2022-05-29 19:59:13 - INFO - Training/evaluation parameters: Namespace(adam_epsilon=1e-06, batch_size=32, bert_cache='data/cache', bert_dir='data/chinese-roberta-wwa-ext', bert_hidden_dropout_prob=0.1, bert_learning_rate=3e-05, bert_max_steps=30000, bert_seq_length=256, bert_warmup_steps=5000, best_score=0.5, ckpt_file='/home/zhangjglab01/daoan/WeChat/challenge/save/v1/model_epoch_9_mean_f1_0.6022.bin', device='cuda', dropout=0.3, fc_size=512, frame_embedding_size=768, learning_rate=5e-05, max_epochs=40, max_frames=32, max_steps=50000, minimum_lr=0.0, n_gpu=4, num_workers=4, prefetch=16, print_steps=20, raw_ckpt='/home/zhangjglab01/daoan/WeChat/checkpoint/uniter_Epoch35.pth', savedmodel_path='save/v1', se_ratio=8, seed=2022, test_annotation='data/annotations/test_a.json', test_batch_size=256, test_output_csv='data/result.csv', test_zip_feats='data/zip_feats/test_a.zip', train_annotation='data/annotations/labeled.json', train_unlabel_annotation='data/annotations/unlabeled.json', train_unlabel_feats='data/zip_feats/unlabeled.zip', train_zip_feats='data/zip_feats/labeled.zip', val_batch_size=256, val_ratio=0.1, vlad_cluster_size=64, vlad_groups=8, vlad_hidden_size=1024, warmup_steps=1000, weight_decay=0.01)
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. 
The class this function is called from is 'BertTokenizer'.
The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. 
The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. 
The class this function is called from is 'BertTokenizer'.
cuda
2022-05-29 19:59:38 - INFO - loading archive file data/chinese-roberta-wwa-ext
2022-05-29 19:59:38 - INFO - Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "directionality": "bidi",
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

2022-05-29 19:59:39 - INFO - loading archive file data/chinese-roberta-wwa-ext
2022-05-29 19:59:39 - INFO - Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "directionality": "bidi",
  "eos_token_id": 2,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_past": true,
  "pad_token_id": 0,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}

2022-05-29 19:59:45 - INFO - Successfully loaded: bert.embeddings.word_embeddings.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.embeddings.position_embeddings.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.embeddings.token_type_embeddings.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.embeddings.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.embeddings.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.img_embeddings.img_linear.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.img_embeddings.img_linear.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.img_embeddings.img_layer_norm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.img_embeddings.img_layer_norm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.img_embeddings.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.img_embeddings.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.pooler.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.pooler.dense.bias
2022-05-29 19:59:45 - INFO - Skipped: cls.predictions.bias
2022-05-29 19:59:45 - INFO - Skipped: cls.predictions.transform.dense.weight
2022-05-29 19:59:45 - INFO - Skipped: cls.predictions.transform.dense.bias
2022-05-29 19:59:45 - INFO - Skipped: cls.predictions.transform.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Skipped: cls.predictions.transform.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Skipped: cls.predictions.decoder.weight
2022-05-29 19:59:45 - INFO - Skipped: cls.seq_relationship.weight
2022-05-29 19:59:45 - INFO - Skipped: cls.seq_relationship.bias
2022-05-29 19:59:45 - INFO - Skipped: obj_predict_head.weight
2022-05-29 19:59:45 - INFO - Skipped: obj_predict_head.bias
2022-05-29 19:59:45 - INFO - Skipped: obj_predict_head.transform.dense.weight
2022-05-29 19:59:45 - INFO - Skipped: obj_predict_head.transform.dense.bias
2022-05-29 19:59:45 - INFO - Skipped: obj_predict_head.transform.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Skipped: obj_predict_head.transform.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.embeddings.word_embeddings.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.embeddings.position_embeddings.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.embeddings.token_type_embeddings.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.embeddings.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.embeddings.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.img_embeddings.img_linear.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.img_embeddings.img_linear.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.img_embeddings.img_layer_norm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.img_embeddings.img_layer_norm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.img_embeddings.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.img_embeddings.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.0.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.1.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.2.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.3.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.4.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.5.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.6.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.7.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.8.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.9.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.10.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.self.query.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.self.query.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.self.key.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.self.key.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.self.value.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.self.value.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.attention.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.intermediate.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.intermediate.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.output.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.output.dense.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.output.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.encoder.layer.11.output.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.pooler.dense.weight
2022-05-29 19:59:45 - INFO - Successfully loaded: bert.pooler.dense.bias
2022-05-29 19:59:45 - INFO - Skipped: cls.predictions.bias
2022-05-29 19:59:45 - INFO - Skipped: cls.predictions.transform.dense.weight
2022-05-29 19:59:45 - INFO - Skipped: cls.predictions.transform.dense.bias
2022-05-29 19:59:45 - INFO - Skipped: cls.predictions.transform.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Skipped: cls.predictions.transform.LayerNorm.bias
2022-05-29 19:59:45 - INFO - Skipped: cls.predictions.decoder.weight
2022-05-29 19:59:45 - INFO - Skipped: cls.seq_relationship.weight
2022-05-29 19:59:45 - INFO - Skipped: cls.seq_relationship.bias
2022-05-29 19:59:45 - INFO - Skipped: obj_predict_head.weight
2022-05-29 19:59:45 - INFO - Skipped: obj_predict_head.bias
2022-05-29 19:59:45 - INFO - Skipped: obj_predict_head.transform.dense.weight
2022-05-29 19:59:45 - INFO - Skipped: obj_predict_head.transform.dense.bias
2022-05-29 19:59:45 - INFO - Skipped: obj_predict_head.transform.LayerNorm.weight
2022-05-29 19:59:45 - INFO - Skipped: obj_predict_head.transform.LayerNorm.bias
/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  FutureWarning,
/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-05-29 20:00:20 - INFO - Epoch 0 step 20 eta 05:28:54: loss_a 5.579, un_loss_a 5.158, loss_b 5.436, un_loss_b 5.613, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:00:41 - INFO - Epoch 0 step 40 eta 19:29:06: loss_a 5.473, un_loss_a 4.789, loss_b 5.575, un_loss_b 5.514, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:01:03 - INFO - Epoch 0 step 60 eta 16:10:08: loss_a 5.301, un_loss_a 4.238, loss_b 5.640, un_loss_b 3.717, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:01:27 - INFO - Epoch 0 step 80 eta 15:36:54: loss_a 5.249, un_loss_a 1.892, loss_b 5.313, un_loss_b 2.269, accuracy_a 0.031, accuracy_b 0.031
2022-05-29 20:01:48 - INFO - Epoch 0 step 100 eta 14:23:31: loss_a 6.018, un_loss_a 0.716, loss_b 5.789, un_loss_b 1.045, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:02:12 - INFO - Epoch 0 step 120 eta 14:05:44: loss_a 5.405, un_loss_a 0.847, loss_b 6.043, un_loss_b 0.772, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:02:33 - INFO - Epoch 0 step 140 eta 13:26:20: loss_a 5.107, un_loss_a 0.743, loss_b 5.253, un_loss_b 0.768, accuracy_a 0.031, accuracy_b 0.031
2022-05-29 20:02:55 - INFO - Epoch 0 step 160 eta 12:56:24: loss_a 4.903, un_loss_a 0.726, loss_b 5.397, un_loss_b 0.770, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:03:18 - INFO - Epoch 0 step 180 eta 12:55:08: loss_a 4.783, un_loss_a 0.745, loss_b 4.995, un_loss_b 0.791, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:03:40 - INFO - Epoch 0 step 200 eta 12:33:49: loss_a 5.087, un_loss_a 0.730, loss_b 5.259, un_loss_b 0.713, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:04:01 - INFO - Epoch 0 step 220 eta 12:16:26: loss_a 4.939, un_loss_a 0.719, loss_b 5.123, un_loss_b 0.737, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:04:25 - INFO - Epoch 0 step 240 eta 12:18:30: loss_a 4.810, un_loss_a 0.726, loss_b 5.104, un_loss_b 0.761, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:04:46 - INFO - Epoch 0 step 260 eta 12:04:50: loss_a 4.571, un_loss_a 0.828, loss_b 4.881, un_loss_b 0.767, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:05:10 - INFO - Epoch 0 step 280 eta 12:06:46: loss_a 4.250, un_loss_a 0.738, loss_b 4.649, un_loss_b 0.703, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:05:31 - INFO - Epoch 0 step 300 eta 11:55:33: loss_a 4.597, un_loss_a 0.749, loss_b 4.937, un_loss_b 0.834, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:05:55 - INFO - Epoch 0 step 320 eta 11:56:33: loss_a 4.224, un_loss_a 0.757, loss_b 4.477, un_loss_b 0.740, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:06:16 - INFO - Epoch 0 step 340 eta 11:47:12: loss_a 3.790, un_loss_a 0.711, loss_b 4.251, un_loss_b 0.725, accuracy_a 0.000, accuracy_b 0.000
2022-05-29 20:06:37 - INFO - Epoch 0 step 360 eta 11:38:52: loss_a 4.121, un_loss_a 0.733, loss_b 4.661, un_loss_b 0.811, accuracy_a 0.062, accuracy_b 0.000
2022-05-29 20:07:01 - INFO - Epoch 0 step 380 eta 11:40:33: loss_a 3.720, un_loss_a 0.711, loss_b 4.547, un_loss_b 0.790, accuracy_a 0.031, accuracy_b 0.031
2022-05-29 20:07:22 - INFO - Epoch 0 step 400 eta 11:33:19: loss_a 3.853, un_loss_a 0.780, loss_b 4.537, un_loss_b 0.855, accuracy_a 0.062, accuracy_b 0.000
2022-05-29 20:07:46 - INFO - Epoch 0 step 420 eta 11:35:00: loss_a 3.592, un_loss_a 0.642, loss_b 3.976, un_loss_b 0.722, accuracy_a 0.094, accuracy_b 0.094
2022-05-29 20:08:07 - INFO - Epoch 0 step 440 eta 11:28:37: loss_a 3.411, un_loss_a 0.681, loss_b 3.952, un_loss_b 0.867, accuracy_a 0.094, accuracy_b 0.000
2022-05-29 20:08:28 - INFO - Epoch 0 step 460 eta 11:22:45: loss_a 3.414, un_loss_a 0.883, loss_b 4.147, un_loss_b 1.024, accuracy_a 0.062, accuracy_b 0.000
2022-05-29 20:08:52 - INFO - Epoch 0 step 480 eta 11:24:36: loss_a 2.751, un_loss_a 0.871, loss_b 3.433, un_loss_b 0.967, accuracy_a 0.281, accuracy_b 0.219
2022-05-29 20:09:13 - INFO - Epoch 0 step 500 eta 11:19:17: loss_a 3.424, un_loss_a 1.116, loss_b 3.780, un_loss_b 1.211, accuracy_a 0.188, accuracy_b 0.156
2022-05-29 20:09:36 - INFO - Epoch 0 step 520 eta 11:20:56: loss_a 2.755, un_loss_a 1.058, loss_b 3.352, un_loss_b 1.137, accuracy_a 0.375, accuracy_b 0.344
2022-05-29 20:09:58 - INFO - Epoch 0 step 540 eta 11:16:07: loss_a 2.867, un_loss_a 0.921, loss_b 3.550, un_loss_b 0.997, accuracy_a 0.312, accuracy_b 0.281
2022-05-29 20:10:22 - INFO - Epoch 0 step 560 eta 11:19:11: loss_a 1.993, un_loss_a 0.888, loss_b 2.788, un_loss_b 0.902, accuracy_a 0.562, accuracy_b 0.438
2022-05-29 20:10:43 - INFO - Epoch 0 step 580 eta 11:14:42: loss_a 2.141, un_loss_a 0.800, loss_b 2.590, un_loss_b 1.024, accuracy_a 0.562, accuracy_b 0.500
2022-05-29 20:11:05 - INFO - Epoch 0 step 600 eta 11:10:31: loss_a 2.007, un_loss_a 1.114, loss_b 2.270, un_loss_b 1.074, accuracy_a 0.531, accuracy_b 0.562
2022-05-29 20:11:28 - INFO - Epoch 0 step 620 eta 11:12:44: loss_a 1.978, un_loss_a 0.712, loss_b 2.431, un_loss_b 0.688, accuracy_a 0.594, accuracy_b 0.469
2022-05-29 20:11:49 - INFO - Epoch 0 step 640 eta 11:08:48: loss_a 2.256, un_loss_a 0.937, loss_b 2.309, un_loss_b 1.112, accuracy_a 0.375, accuracy_b 0.375
2022-05-29 20:12:11 - INFO - Epoch 0 step 660 eta 11:05:05: loss_a 2.465, un_loss_a 0.670, loss_b 2.483, un_loss_b 0.757, accuracy_a 0.500, accuracy_b 0.531
2022-05-29 20:12:34 - INFO - Epoch 0 step 680 eta 11:06:41: loss_a 2.155, un_loss_a 0.721, loss_b 2.321, un_loss_b 0.844, accuracy_a 0.500, accuracy_b 0.469
2022-05-29 20:12:56 - INFO - Epoch 0 step 700 eta 11:03:13: loss_a 2.514, un_loss_a 0.548, loss_b 2.944, un_loss_b 0.675, accuracy_a 0.469, accuracy_b 0.438
2022-05-29 20:13:19 - INFO - Epoch 0 step 720 eta 11:04:41: loss_a 1.942, un_loss_a 0.687, loss_b 2.356, un_loss_b 0.677, accuracy_a 0.531, accuracy_b 0.531
2022-05-29 20:13:40 - INFO - Epoch 0 step 740 eta 11:01:24: loss_a 2.582, un_loss_a 0.526, loss_b 2.522, un_loss_b 0.625, accuracy_a 0.469, accuracy_b 0.500
2022-05-29 20:14:02 - INFO - Epoch 0 step 760 eta 10:58:19: loss_a 2.305, un_loss_a 0.713, loss_b 2.658, un_loss_b 0.659, accuracy_a 0.438, accuracy_b 0.438
2022-05-29 20:14:25 - INFO - Epoch 0 step 780 eta 10:59:46: loss_a 1.493, un_loss_a 0.484, loss_b 1.620, un_loss_b 0.626, accuracy_a 0.719, accuracy_b 0.625
2022-05-29 20:14:47 - INFO - Epoch 0 step 800 eta 10:56:49: loss_a 2.524, un_loss_a 0.899, loss_b 2.728, un_loss_b 1.044, accuracy_a 0.500, accuracy_b 0.469
2022-05-29 20:15:08 - INFO - Epoch 0 step 820 eta 10:54:00: loss_a 1.944, un_loss_a 0.634, loss_b 2.412, un_loss_b 0.697, accuracy_a 0.562, accuracy_b 0.375
2022-05-29 20:15:32 - INFO - Epoch 0 step 840 eta 10:55:58: loss_a 1.753, un_loss_a 0.694, loss_b 2.039, un_loss_b 0.807, accuracy_a 0.625, accuracy_b 0.594
2022-05-29 20:15:53 - INFO - Epoch 0 step 860 eta 10:53:15: loss_a 2.161, un_loss_a 0.473, loss_b 2.290, un_loss_b 0.525, accuracy_a 0.438, accuracy_b 0.406
2022-05-29 20:16:17 - INFO - Epoch 0 step 880 eta 10:54:59: loss_a 2.066, un_loss_a 0.429, loss_b 2.108, un_loss_b 0.423, accuracy_a 0.500, accuracy_b 0.469
2022-05-29 20:16:38 - INFO - Epoch 0 step 900 eta 10:52:25: loss_a 1.748, un_loss_a 0.861, loss_b 1.913, un_loss_b 0.731, accuracy_a 0.625, accuracy_b 0.594
2022-05-29 20:16:59 - INFO - Epoch 0 step 920 eta 10:49:56: loss_a 1.897, un_loss_a 0.777, loss_b 2.097, un_loss_b 0.992, accuracy_a 0.562, accuracy_b 0.562
2022-05-29 20:17:23 - INFO - Epoch 0 step 940 eta 10:51:10: loss_a 2.087, un_loss_a 0.628, loss_b 1.975, un_loss_b 0.457, accuracy_a 0.500, accuracy_b 0.531
2022-05-29 20:17:44 - INFO - Epoch 0 step 960 eta 10:48:46: loss_a 1.315, un_loss_a 1.015, loss_b 1.759, un_loss_b 1.010, accuracy_a 0.688, accuracy_b 0.562
2022-05-29 20:18:08 - INFO - Epoch 0 step 980 eta 10:49:54: loss_a 1.914, un_loss_a 0.594, loss_b 1.929, un_loss_b 0.702, accuracy_a 0.594, accuracy_b 0.656
2022-05-29 20:18:29 - INFO - Epoch 0 step 1000 eta 10:47:34: loss_a 2.129, un_loss_a 0.693, loss_b 2.170, un_loss_b 0.881, accuracy_a 0.469, accuracy_b 0.438
2022-05-29 20:18:50 - INFO - Epoch 0 step 1020 eta 10:45:20: loss_a 1.546, un_loss_a 0.950, loss_b 1.639, un_loss_b 1.176, accuracy_a 0.688, accuracy_b 0.594
2022-05-29 20:19:14 - INFO - Epoch 0 step 1040 eta 10:46:27: loss_a 1.426, un_loss_a 0.760, loss_b 1.724, un_loss_b 1.083, accuracy_a 0.719, accuracy_b 0.656
2022-05-29 20:19:35 - INFO - Epoch 0 step 1060 eta 10:44:18: loss_a 1.809, un_loss_a 0.670, loss_b 1.762, un_loss_b 0.649, accuracy_a 0.531, accuracy_b 0.531
2022-05-29 20:19:58 - INFO - Epoch 0 step 1080 eta 10:45:22: loss_a 1.950, un_loss_a 0.447, loss_b 2.188, un_loss_b 0.593, accuracy_a 0.531, accuracy_b 0.500
2022-05-29 20:20:20 - INFO - Epoch 0 step 1100 eta 10:43:18: loss_a 1.781, un_loss_a 0.729, loss_b 1.945, un_loss_b 0.763, accuracy_a 0.500, accuracy_b 0.531
2022-05-29 20:20:41 - INFO - Epoch 0 step 1120 eta 10:41:16: loss_a 2.047, un_loss_a 0.844, loss_b 1.999, un_loss_b 0.640, accuracy_a 0.531, accuracy_b 0.531
2022-05-29 20:21:05 - INFO - Epoch 0 step 1140 eta 10:42:18: loss_a 1.100, un_loss_a 0.921, loss_b 1.474, un_loss_b 0.928, accuracy_a 0.750, accuracy_b 0.688
2022-05-29 20:21:26 - INFO - Epoch 0 step 1160 eta 10:40:21: loss_a 1.688, un_loss_a 0.593, loss_b 1.688, un_loss_b 0.925, accuracy_a 0.562, accuracy_b 0.562
2022-05-29 20:21:49 - INFO - Epoch 0 step 1180 eta 10:41:20: loss_a 2.266, un_loss_a 0.505, loss_b 2.117, un_loss_b 0.572, accuracy_a 0.531, accuracy_b 0.500
2022-05-29 20:22:11 - INFO - Epoch 0 step 1200 eta 10:39:26: loss_a 1.805, un_loss_a 0.456, loss_b 1.664, un_loss_b 0.577, accuracy_a 0.531, accuracy_b 0.500
2022-05-29 20:22:34 - INFO - Epoch 0 step 1220 eta 10:40:22: loss_a 2.105, un_loss_a 0.740, loss_b 2.020, un_loss_b 0.912, accuracy_a 0.531, accuracy_b 0.562
2022-05-29 20:22:56 - INFO - Epoch 0 step 1240 eta 10:38:33: loss_a 1.552, un_loss_a 0.508, loss_b 1.623, un_loss_b 0.641, accuracy_a 0.656, accuracy_b 0.625
2022-05-29 20:23:17 - INFO - Epoch 0 step 1260 eta 10:36:46: loss_a 1.500, un_loss_a 0.367, loss_b 1.668, un_loss_b 0.394, accuracy_a 0.688, accuracy_b 0.625
2022-05-29 20:23:40 - INFO - Epoch 0 step 1280 eta 10:37:43: loss_a 2.462, un_loss_a 0.677, loss_b 2.618, un_loss_b 0.809, accuracy_a 0.344, accuracy_b 0.375
2022-05-29 20:24:02 - INFO - Epoch 0 step 1300 eta 10:35:59: loss_a 1.497, un_loss_a 0.480, loss_b 1.469, un_loss_b 0.597, accuracy_a 0.594, accuracy_b 0.656
2022-05-29 20:24:23 - INFO - Epoch 0 step 1320 eta 10:34:16: loss_a 1.417, un_loss_a 0.726, loss_b 1.665, un_loss_b 0.751, accuracy_a 0.688, accuracy_b 0.625
2022-05-29 20:24:47 - INFO - Epoch 0 step 1340 eta 10:35:09: loss_a 2.137, un_loss_a 0.757, loss_b 2.241, un_loss_b 0.660, accuracy_a 0.500, accuracy_b 0.438
2022-05-29 20:25:08 - INFO - Epoch 0 step 1360 eta 10:33:30: loss_a 1.578, un_loss_a 0.565, loss_b 1.612, un_loss_b 0.676, accuracy_a 0.594, accuracy_b 0.594
2022-05-29 20:25:31 - INFO - Epoch 0 step 1380 eta 10:34:22: loss_a 1.950, un_loss_a 0.660, loss_b 1.799, un_loss_b 0.569, accuracy_a 0.531, accuracy_b 0.594
2022-05-29 20:25:53 - INFO - Epoch 0 step 1400 eta 10:32:44: loss_a 1.860, un_loss_a 0.487, loss_b 1.961, un_loss_b 0.496, accuracy_a 0.531, accuracy_b 0.594
2022-05-29 20:26:14 - INFO - Epoch 0 step 1420 eta 10:31:09: loss_a 1.368, un_loss_a 0.374, loss_b 1.423, un_loss_b 0.605, accuracy_a 0.688, accuracy_b 0.625
2022-05-29 20:26:38 - INFO - Epoch 0 step 1440 eta 10:32:08: loss_a 1.675, un_loss_a 0.654, loss_b 1.574, un_loss_b 0.690, accuracy_a 0.531, accuracy_b 0.594
2022-05-29 20:26:59 - INFO - Epoch 0 step 1460 eta 10:30:35: loss_a 1.743, un_loss_a 0.996, loss_b 1.423, un_loss_b 0.723, accuracy_a 0.531, accuracy_b 0.562
2022-05-29 20:27:21 - INFO - Epoch 0 step 1480 eta 10:29:03: loss_a 2.238, un_loss_a 0.523, loss_b 2.531, un_loss_b 0.515, accuracy_a 0.438, accuracy_b 0.375
2022-05-29 20:27:44 - INFO - Epoch 0 step 1500 eta 10:29:58: loss_a 1.220, un_loss_a 0.644, loss_b 1.619, un_loss_b 0.720, accuracy_a 0.656, accuracy_b 0.656
2022-05-29 20:28:06 - INFO - Epoch 0 step 1520 eta 10:28:27: loss_a 1.832, un_loss_a 0.590, loss_b 1.979, un_loss_b 0.924, accuracy_a 0.531, accuracy_b 0.562
2022-05-29 20:28:29 - INFO - Epoch 0 step 1540 eta 10:29:11: loss_a 2.039, un_loss_a 0.452, loss_b 2.070, un_loss_b 0.440, accuracy_a 0.562, accuracy_b 0.562
2022-05-29 20:28:50 - INFO - Epoch 0 step 1560 eta 10:27:42: loss_a 1.080, un_loss_a 0.478, loss_b 1.037, un_loss_b 0.649, accuracy_a 0.688, accuracy_b 0.750
2022-05-29 20:29:12 - INFO - Epoch 0 step 1580 eta 10:26:15: loss_a 1.587, un_loss_a 0.681, loss_b 1.658, un_loss_b 0.710, accuracy_a 0.594, accuracy_b 0.594
2022-05-29 20:29:35 - INFO - Epoch 0 step 1600 eta 10:26:57: loss_a 2.278, un_loss_a 0.617, loss_b 2.379, un_loss_b 0.663, accuracy_a 0.406, accuracy_b 0.406
2022-05-29 20:29:56 - INFO - Epoch 0 step 1620 eta 10:25:31: loss_a 1.457, un_loss_a 0.430, loss_b 1.399, un_loss_b 0.615, accuracy_a 0.656, accuracy_b 0.625
2022-05-29 20:30:20 - INFO - Epoch 0 step 1640 eta 10:26:13: loss_a 1.252, un_loss_a 0.715, loss_b 1.388, un_loss_b 0.845, accuracy_a 0.594, accuracy_b 0.625
2022-05-29 20:30:41 - INFO - Epoch 0 step 1660 eta 10:24:49: loss_a 1.659, un_loss_a 0.573, loss_b 1.553, un_loss_b 0.534, accuracy_a 0.594, accuracy_b 0.562
2022-05-29 20:31:03 - INFO - Epoch 0 step 1680 eta 10:23:27: loss_a 1.831, un_loss_a 0.556, loss_b 2.024, un_loss_b 0.644, accuracy_a 0.562, accuracy_b 0.531
2022-05-29 20:31:26 - INFO - Epoch 0 step 1700 eta 10:24:06: loss_a 2.250, un_loss_a 0.766, loss_b 2.173, un_loss_b 0.756, accuracy_a 0.438, accuracy_b 0.469
2022-05-29 20:31:47 - INFO - Epoch 0 step 1720 eta 10:22:46: loss_a 1.919, un_loss_a 0.638, loss_b 1.922, un_loss_b 0.603, accuracy_a 0.594, accuracy_b 0.562
2022-05-29 20:32:11 - INFO - Epoch 0 step 1740 eta 10:23:49: loss_a 1.973, un_loss_a 0.501, loss_b 1.998, un_loss_b 0.451, accuracy_a 0.531, accuracy_b 0.500
2022-05-29 20:32:33 - INFO - Epoch 0 step 1760 eta 10:22:29: loss_a 1.015, un_loss_a 0.831, loss_b 1.236, un_loss_b 0.857, accuracy_a 0.688, accuracy_b 0.750
2022-05-29 20:32:56 - INFO - Epoch 0 step 1780 eta 10:23:19: loss_a 1.561, un_loss_a 0.766, loss_b 1.760, un_loss_b 0.662, accuracy_a 0.562, accuracy_b 0.562
2022-05-29 20:33:17 - INFO - Epoch 0 step 1800 eta 10:22:01: loss_a 1.860, un_loss_a 0.500, loss_b 1.999, un_loss_b 0.444, accuracy_a 0.594, accuracy_b 0.500
2022-05-29 20:33:39 - INFO - Epoch 0 step 1820 eta 10:20:44: loss_a 1.255, un_loss_a 0.637, loss_b 1.280, un_loss_b 0.700, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 20:34:02 - INFO - Epoch 0 step 1840 eta 10:21:15: loss_a 1.129, un_loss_a 0.560, loss_b 1.218, un_loss_b 0.520, accuracy_a 0.625, accuracy_b 0.688
2022-05-29 20:34:24 - INFO - Epoch 0 step 1860 eta 10:19:59: loss_a 1.264, un_loss_a 0.716, loss_b 1.495, un_loss_b 0.755, accuracy_a 0.625, accuracy_b 0.562
2022-05-29 20:34:47 - INFO - Epoch 0 step 1880 eta 10:20:28: loss_a 1.394, un_loss_a 0.643, loss_b 1.260, un_loss_b 0.732, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 20:35:08 - INFO - Epoch 0 step 1900 eta 10:19:13: loss_a 0.880, un_loss_a 0.806, loss_b 0.888, un_loss_b 0.751, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 20:35:30 - INFO - Epoch 0 step 1920 eta 10:18:00: loss_a 1.913, un_loss_a 0.674, loss_b 1.747, un_loss_b 0.677, accuracy_a 0.531, accuracy_b 0.531
2022-05-29 20:35:53 - INFO - Epoch 0 step 1940 eta 10:18:33: loss_a 1.268, un_loss_a 0.691, loss_b 1.367, un_loss_b 0.470, accuracy_a 0.625, accuracy_b 0.625
2022-05-29 20:36:15 - INFO - Epoch 0 step 1960 eta 10:17:20: loss_a 1.592, un_loss_a 0.661, loss_b 1.530, un_loss_b 0.633, accuracy_a 0.688, accuracy_b 0.625
2022-05-29 20:36:38 - INFO - Epoch 0 step 1980 eta 10:17:48: loss_a 1.284, un_loss_a 0.368, loss_b 1.479, un_loss_b 0.446, accuracy_a 0.656, accuracy_b 0.562
2022-05-29 20:36:59 - INFO - Epoch 0 step 2000 eta 10:16:36: loss_a 1.385, un_loss_a 0.558, loss_b 1.650, un_loss_b 0.526, accuracy_a 0.625, accuracy_b 0.594
2022-05-29 20:37:21 - INFO - Epoch 0 step 2020 eta 10:15:26: loss_a 1.683, un_loss_a 0.492, loss_b 1.638, un_loss_b 0.467, accuracy_a 0.594, accuracy_b 0.625
2022-05-29 20:37:44 - INFO - Epoch 0 step 2040 eta 10:15:52: loss_a 0.963, un_loss_a 0.725, loss_b 0.877, un_loss_b 0.567, accuracy_a 0.812, accuracy_b 0.844
2022-05-29 20:38:05 - INFO - Epoch 0 step 2060 eta 10:14:42: loss_a 1.432, un_loss_a 0.671, loss_b 1.467, un_loss_b 0.620, accuracy_a 0.625, accuracy_b 0.625
2022-05-29 20:38:27 - INFO - Epoch 0 step 2080 eta 10:13:33: loss_a 1.649, un_loss_a 0.450, loss_b 1.545, un_loss_b 0.499, accuracy_a 0.594, accuracy_b 0.625
2022-05-29 20:38:50 - INFO - Epoch 0 step 2100 eta 10:14:01: loss_a 1.803, un_loss_a 0.795, loss_b 1.830, un_loss_b 0.792, accuracy_a 0.594, accuracy_b 0.625
2022-05-29 20:39:12 - INFO - Epoch 0 step 2120 eta 10:12:53: loss_a 2.463, un_loss_a 0.516, loss_b 2.312, un_loss_b 0.522, accuracy_a 0.438, accuracy_b 0.469
2022-05-29 20:39:33 - INFO - Epoch 0 step 2140 eta 10:11:46: loss_a 1.759, un_loss_a 0.678, loss_b 1.988, un_loss_b 0.526, accuracy_a 0.531, accuracy_b 0.469
2022-05-29 20:39:56 - INFO - Epoch 0 step 2160 eta 10:12:09: loss_a 1.666, un_loss_a 0.381, loss_b 1.799, un_loss_b 0.551, accuracy_a 0.562, accuracy_b 0.531
2022-05-29 20:40:18 - INFO - Epoch 0 step 2180 eta 10:11:03: loss_a 1.757, un_loss_a 0.601, loss_b 1.870, un_loss_b 0.601, accuracy_a 0.594, accuracy_b 0.500
2022-05-29 20:40:41 - INFO - Epoch 0 step 2200 eta 10:11:31: loss_a 1.540, un_loss_a 0.851, loss_b 1.785, un_loss_b 0.634, accuracy_a 0.656, accuracy_b 0.531
2022-05-29 20:41:02 - INFO - Epoch 0 step 2220 eta 10:10:25: loss_a 1.310, un_loss_a 0.459, loss_b 1.226, un_loss_b 0.460, accuracy_a 0.625, accuracy_b 0.719
2022-05-29 20:41:24 - INFO - Epoch 0 step 2240 eta 10:09:21: loss_a 0.864, un_loss_a 0.533, loss_b 0.769, un_loss_b 0.402, accuracy_a 0.656, accuracy_b 0.750
2022-05-29 20:41:47 - INFO - Epoch 0 step 2260 eta 10:09:45: loss_a 1.145, un_loss_a 0.625, loss_b 1.332, un_loss_b 0.514, accuracy_a 0.688, accuracy_b 0.625
2022-05-29 20:42:09 - INFO - Epoch 0 step 2280 eta 10:08:41: loss_a 2.154, un_loss_a 0.407, loss_b 1.873, un_loss_b 0.430, accuracy_a 0.531, accuracy_b 0.531
2022-05-29 20:42:32 - INFO - Epoch 0 step 2300 eta 10:09:02: loss_a 1.089, un_loss_a 0.690, loss_b 1.532, un_loss_b 0.850, accuracy_a 0.656, accuracy_b 0.562
2022-05-29 20:42:53 - INFO - Epoch 0 step 2320 eta 10:07:59: loss_a 1.627, un_loss_a 0.449, loss_b 1.771, un_loss_b 0.521, accuracy_a 0.562, accuracy_b 0.562
2022-05-29 20:43:15 - INFO - Epoch 0 step 2340 eta 10:06:56: loss_a 2.049, un_loss_a 0.520, loss_b 2.140, un_loss_b 0.551, accuracy_a 0.469, accuracy_b 0.500
2022-05-29 20:43:38 - INFO - Epoch 0 step 2360 eta 10:07:23: loss_a 1.289, un_loss_a 0.413, loss_b 1.335, un_loss_b 0.455, accuracy_a 0.531, accuracy_b 0.531
2022-05-29 20:44:00 - INFO - Epoch 0 step 2380 eta 10:06:21: loss_a 1.381, un_loss_a 0.513, loss_b 1.512, un_loss_b 0.579, accuracy_a 0.562, accuracy_b 0.562
2022-05-29 20:44:23 - INFO - Epoch 0 step 2400 eta 10:06:44: loss_a 1.776, un_loss_a 0.723, loss_b 1.835, un_loss_b 0.709, accuracy_a 0.500, accuracy_b 0.531
2022-05-29 20:44:44 - INFO - Epoch 0 step 2420 eta 10:05:43: loss_a 1.348, un_loss_a 0.594, loss_b 1.363, un_loss_b 0.831, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 20:45:08 - INFO - Epoch 0 step 2440 eta 10:06:05: loss_a 1.343, un_loss_a 0.648, loss_b 1.238, un_loss_b 0.634, accuracy_a 0.656, accuracy_b 0.656
2022-05-29 20:45:29 - INFO - Epoch 0 step 2460 eta 10:05:04: loss_a 1.440, un_loss_a 0.720, loss_b 1.471, un_loss_b 0.504, accuracy_a 0.625, accuracy_b 0.625
2022-05-29 20:45:50 - INFO - Epoch 0 step 2480 eta 10:04:04: loss_a 1.113, un_loss_a 0.597, loss_b 0.910, un_loss_b 0.748, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 20:46:14 - INFO - Epoch 0 step 2500 eta 10:04:26: loss_a 0.719, un_loss_a 0.562, loss_b 0.750, un_loss_b 0.597, accuracy_a 0.812, accuracy_b 0.781
2022-05-29 20:46:35 - INFO - Epoch 0 step 2520 eta 10:03:26: loss_a 1.592, un_loss_a 0.733, loss_b 1.667, un_loss_b 0.598, accuracy_a 0.500, accuracy_b 0.562
2022-05-29 20:46:59 - INFO - Epoch 0 step 2540 eta 10:03:46: loss_a 1.931, un_loss_a 0.601, loss_b 1.982, un_loss_b 0.663, accuracy_a 0.438, accuracy_b 0.469
2022-05-29 20:47:20 - INFO - Epoch 0 step 2560 eta 10:02:47: loss_a 1.540, un_loss_a 0.737, loss_b 1.445, un_loss_b 0.546, accuracy_a 0.656, accuracy_b 0.625
2022-05-29 20:47:41 - INFO - Epoch 0 step 2580 eta 10:01:49: loss_a 1.344, un_loss_a 0.593, loss_b 1.132, un_loss_b 0.796, accuracy_a 0.688, accuracy_b 0.719
2022-05-29 20:48:05 - INFO - Epoch 0 step 2600 eta 10:02:09: loss_a 1.126, un_loss_a 0.346, loss_b 0.968, un_loss_b 0.392, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 20:48:26 - INFO - Epoch 0 step 2620 eta 10:01:11: loss_a 1.110, un_loss_a 0.395, loss_b 1.100, un_loss_b 0.485, accuracy_a 0.781, accuracy_b 0.688
2022-05-29 20:48:49 - INFO - Epoch 0 step 2640 eta 10:01:31: loss_a 1.747, un_loss_a 0.640, loss_b 1.911, un_loss_b 0.624, accuracy_a 0.594, accuracy_b 0.531
2022-05-29 20:49:11 - INFO - Epoch 0 step 2660 eta 10:00:34: loss_a 1.521, un_loss_a 0.576, loss_b 1.610, un_loss_b 0.635, accuracy_a 0.625, accuracy_b 0.625
2022-05-29 20:49:32 - INFO - Epoch 0 step 2680 eta 09:59:36: loss_a 2.025, un_loss_a 0.367, loss_b 2.014, un_loss_b 0.388, accuracy_a 0.594, accuracy_b 0.594
2022-05-29 20:49:56 - INFO - Epoch 0 step 2700 eta 09:59:55: loss_a 1.538, un_loss_a 0.619, loss_b 1.364, un_loss_b 0.646, accuracy_a 0.625, accuracy_b 0.625
2022-05-29 20:50:17 - INFO - Epoch 0 step 2720 eta 09:58:58: loss_a 1.694, un_loss_a 0.634, loss_b 1.586, un_loss_b 0.498, accuracy_a 0.531, accuracy_b 0.656
2022-05-29 20:50:39 - INFO - Epoch 0 step 2740 eta 09:58:02: loss_a 1.221, un_loss_a 0.699, loss_b 1.329, un_loss_b 0.617, accuracy_a 0.750, accuracy_b 0.656
2022-05-29 20:51:02 - INFO - Epoch 0 step 2760 eta 09:58:18: loss_a 1.450, un_loss_a 0.529, loss_b 1.396, un_loss_b 0.622, accuracy_a 0.531, accuracy_b 0.625
2022-05-29 20:51:23 - INFO - Epoch 0 step 2780 eta 09:57:22: loss_a 1.689, un_loss_a 0.364, loss_b 1.762, un_loss_b 0.450, accuracy_a 0.531, accuracy_b 0.531
2022-05-29 20:51:47 - INFO - Epoch 0 step 2800 eta 09:57:38: loss_a 1.517, un_loss_a 0.888, loss_b 1.533, un_loss_b 0.754, accuracy_a 0.531, accuracy_b 0.562
Begin Validation
2022-05-29 20:54:03 - INFO - Epoch 0 step 2812:, {'lv1_acc': 0.7419, 'lv2_acc': 0.6163, 'lv1_f1_micro': 0.7419, 'lv1_f1_macro': 0.6758, 'lv2_f1_micro': 0.6163, 'lv2_f1_macro': 0.3815, 'mean_f1': 0.6039}, {'lv1_acc': 0.7442, 'lv2_acc': 0.619, 'lv1_f1_micro': 0.7442, 'lv1_f1_macro': 0.7002, 'lv2_f1_micro': 0.619, 'lv2_f1_macro': 0.3886, 'mean_f1': 0.613}
/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-05-29 20:54:15 - INFO - Epoch 1 step 2820 eta 11:18:56: loss_a 1.496, un_loss_a 0.573, loss_b 1.677, un_loss_b 0.471, accuracy_a 0.500, accuracy_b 0.562
2022-05-29 20:54:36 - INFO - Epoch 1 step 2840 eta 11:17:27: loss_a 0.938, un_loss_a 0.697, loss_b 1.020, un_loss_b 0.539, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 20:55:00 - INFO - Epoch 1 step 2860 eta 11:17:16: loss_a 1.154, un_loss_a 0.521, loss_b 1.169, un_loss_b 0.333, accuracy_a 0.688, accuracy_b 0.719
2022-05-29 20:55:21 - INFO - Epoch 1 step 2880 eta 11:15:48: loss_a 0.833, un_loss_a 0.439, loss_b 0.988, un_loss_b 0.570, accuracy_a 0.719, accuracy_b 0.719
2022-05-29 20:55:45 - INFO - Epoch 1 step 2900 eta 11:15:44: loss_a 0.544, un_loss_a 0.508, loss_b 0.672, un_loss_b 0.586, accuracy_a 0.844, accuracy_b 0.812
2022-05-29 20:56:06 - INFO - Epoch 1 step 2920 eta 11:14:15: loss_a 1.227, un_loss_a 0.552, loss_b 1.299, un_loss_b 0.546, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 20:56:28 - INFO - Epoch 1 step 2940 eta 11:12:50: loss_a 1.267, un_loss_a 0.556, loss_b 1.364, un_loss_b 0.674, accuracy_a 0.625, accuracy_b 0.625
2022-05-29 20:56:51 - INFO - Epoch 1 step 2960 eta 11:12:43: loss_a 1.412, un_loss_a 0.539, loss_b 1.343, un_loss_b 0.539, accuracy_a 0.625, accuracy_b 0.625
2022-05-29 20:57:13 - INFO - Epoch 1 step 2980 eta 11:11:19: loss_a 0.743, un_loss_a 0.417, loss_b 0.927, un_loss_b 0.542, accuracy_a 0.812, accuracy_b 0.781
2022-05-29 20:57:36 - INFO - Epoch 1 step 3000 eta 11:11:02: loss_a 1.500, un_loss_a 0.804, loss_b 1.663, un_loss_b 0.665, accuracy_a 0.594, accuracy_b 0.625
2022-05-29 20:57:58 - INFO - Epoch 1 step 3020 eta 11:09:38: loss_a 1.488, un_loss_a 0.591, loss_b 1.519, un_loss_b 0.549, accuracy_a 0.562, accuracy_b 0.500
2022-05-29 20:58:21 - INFO - Epoch 1 step 3040 eta 11:09:21: loss_a 0.942, un_loss_a 0.564, loss_b 1.120, un_loss_b 0.608, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 20:58:42 - INFO - Epoch 1 step 3060 eta 11:07:58: loss_a 1.067, un_loss_a 0.441, loss_b 1.366, un_loss_b 0.455, accuracy_a 0.656, accuracy_b 0.594
2022-05-29 20:59:04 - INFO - Epoch 1 step 3080 eta 11:06:36: loss_a 1.091, un_loss_a 0.598, loss_b 1.203, un_loss_b 0.560, accuracy_a 0.750, accuracy_b 0.656
2022-05-29 20:59:27 - INFO - Epoch 1 step 3100 eta 11:06:20: loss_a 1.161, un_loss_a 0.664, loss_b 1.341, un_loss_b 0.589, accuracy_a 0.656, accuracy_b 0.656
2022-05-29 20:59:49 - INFO - Epoch 1 step 3120 eta 11:05:00: loss_a 0.894, un_loss_a 0.440, loss_b 1.036, un_loss_b 0.545, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 21:00:10 - INFO - Epoch 1 step 3140 eta 11:03:40: loss_a 1.147, un_loss_a 0.442, loss_b 0.987, un_loss_b 0.486, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 21:00:33 - INFO - Epoch 1 step 3160 eta 11:03:21: loss_a 1.115, un_loss_a 0.600, loss_b 1.191, un_loss_b 0.552, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 21:00:55 - INFO - Epoch 1 step 3180 eta 11:02:03: loss_a 1.340, un_loss_a 0.646, loss_b 1.396, un_loss_b 0.648, accuracy_a 0.625, accuracy_b 0.562
2022-05-29 21:01:18 - INFO - Epoch 1 step 3200 eta 11:01:47: loss_a 0.977, un_loss_a 0.465, loss_b 1.042, un_loss_b 0.413, accuracy_a 0.688, accuracy_b 0.625
2022-05-29 21:01:40 - INFO - Epoch 1 step 3220 eta 11:00:29: loss_a 0.569, un_loss_a 0.727, loss_b 0.696, un_loss_b 0.599, accuracy_a 0.781, accuracy_b 0.781
2022-05-29 21:02:01 - INFO - Epoch 1 step 3240 eta 10:59:12: loss_a 0.975, un_loss_a 0.471, loss_b 1.099, un_loss_b 0.395, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 21:02:24 - INFO - Epoch 1 step 3260 eta 10:58:55: loss_a 1.343, un_loss_a 0.641, loss_b 1.398, un_loss_b 0.632, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 21:02:46 - INFO - Epoch 1 step 3280 eta 10:57:39: loss_a 1.372, un_loss_a 0.386, loss_b 1.204, un_loss_b 0.477, accuracy_a 0.719, accuracy_b 0.750
2022-05-29 21:03:07 - INFO - Epoch 1 step 3300 eta 10:56:23: loss_a 1.208, un_loss_a 0.585, loss_b 1.391, un_loss_b 0.712, accuracy_a 0.656, accuracy_b 0.656
2022-05-29 21:03:31 - INFO - Epoch 1 step 3320 eta 10:56:20: loss_a 0.920, un_loss_a 0.660, loss_b 1.014, un_loss_b 0.728, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 21:03:52 - INFO - Epoch 1 step 3340 eta 10:55:06: loss_a 0.894, un_loss_a 0.643, loss_b 0.885, un_loss_b 0.702, accuracy_a 0.719, accuracy_b 0.719
2022-05-29 21:04:16 - INFO - Epoch 1 step 3360 eta 10:54:58: loss_a 0.626, un_loss_a 0.483, loss_b 0.524, un_loss_b 0.477, accuracy_a 0.875, accuracy_b 0.812
2022-05-29 21:04:37 - INFO - Epoch 1 step 3380 eta 10:53:45: loss_a 1.780, un_loss_a 0.866, loss_b 2.235, un_loss_b 0.652, accuracy_a 0.531, accuracy_b 0.438
2022-05-29 21:04:59 - INFO - Epoch 1 step 3400 eta 10:52:31: loss_a 1.017, un_loss_a 0.418, loss_b 0.918, un_loss_b 0.421, accuracy_a 0.625, accuracy_b 0.688
2022-05-29 21:05:22 - INFO - Epoch 1 step 3420 eta 10:52:14: loss_a 0.702, un_loss_a 0.682, loss_b 0.690, un_loss_b 0.645, accuracy_a 0.719, accuracy_b 0.781
2022-05-29 21:05:43 - INFO - Epoch 1 step 3440 eta 10:51:02: loss_a 0.560, un_loss_a 0.557, loss_b 0.660, un_loss_b 0.434, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 21:06:07 - INFO - Epoch 1 step 3460 eta 10:51:03: loss_a 1.264, un_loss_a 0.399, loss_b 1.286, un_loss_b 0.361, accuracy_a 0.719, accuracy_b 0.719
2022-05-29 21:06:29 - INFO - Epoch 1 step 3480 eta 10:49:52: loss_a 0.803, un_loss_a 0.376, loss_b 0.892, un_loss_b 0.495, accuracy_a 0.781, accuracy_b 0.688
2022-05-29 21:06:50 - INFO - Epoch 1 step 3500 eta 10:48:40: loss_a 1.133, un_loss_a 0.766, loss_b 1.047, un_loss_b 0.541, accuracy_a 0.719, accuracy_b 0.719
2022-05-29 21:07:14 - INFO - Epoch 1 step 3520 eta 10:48:29: loss_a 1.541, un_loss_a 0.585, loss_b 1.775, un_loss_b 0.570, accuracy_a 0.531, accuracy_b 0.594
2022-05-29 21:07:35 - INFO - Epoch 1 step 3540 eta 10:47:18: loss_a 1.275, un_loss_a 0.787, loss_b 1.435, un_loss_b 0.569, accuracy_a 0.656, accuracy_b 0.625
2022-05-29 21:07:58 - INFO - Epoch 1 step 3560 eta 10:47:05: loss_a 0.996, un_loss_a 0.790, loss_b 0.997, un_loss_b 0.783, accuracy_a 0.688, accuracy_b 0.531
2022-05-29 21:08:20 - INFO - Epoch 1 step 3580 eta 10:45:55: loss_a 1.023, un_loss_a 0.459, loss_b 1.025, un_loss_b 0.359, accuracy_a 0.719, accuracy_b 0.719
2022-05-29 21:08:41 - INFO - Epoch 1 step 3600 eta 10:44:46: loss_a 1.848, un_loss_a 0.481, loss_b 1.915, un_loss_b 0.557, accuracy_a 0.594, accuracy_b 0.531
2022-05-29 21:09:05 - INFO - Epoch 1 step 3620 eta 10:44:33: loss_a 1.321, un_loss_a 0.322, loss_b 1.070, un_loss_b 0.584, accuracy_a 0.594, accuracy_b 0.625
2022-05-29 21:09:26 - INFO - Epoch 1 step 3640 eta 10:43:25: loss_a 0.821, un_loss_a 0.707, loss_b 1.138, un_loss_b 0.604, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 21:09:49 - INFO - Epoch 1 step 3660 eta 10:43:13: loss_a 1.087, un_loss_a 0.504, loss_b 1.128, un_loss_b 0.592, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 21:10:11 - INFO - Epoch 1 step 3680 eta 10:42:06: loss_a 1.406, un_loss_a 0.767, loss_b 1.436, un_loss_b 0.630, accuracy_a 0.594, accuracy_b 0.688
2022-05-29 21:10:34 - INFO - Epoch 1 step 3700 eta 10:41:52: loss_a 1.109, un_loss_a 0.765, loss_b 1.213, un_loss_b 0.637, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 21:10:56 - INFO - Epoch 1 step 3720 eta 10:40:45: loss_a 1.547, un_loss_a 0.305, loss_b 1.326, un_loss_b 0.348, accuracy_a 0.562, accuracy_b 0.562
2022-05-29 21:11:17 - INFO - Epoch 1 step 3740 eta 10:39:39: loss_a 0.881, un_loss_a 0.616, loss_b 0.899, un_loss_b 0.706, accuracy_a 0.656, accuracy_b 0.750
2022-05-29 21:11:40 - INFO - Epoch 1 step 3760 eta 10:39:28: loss_a 1.498, un_loss_a 0.438, loss_b 1.691, un_loss_b 0.404, accuracy_a 0.625, accuracy_b 0.562
2022-05-29 21:12:02 - INFO - Epoch 1 step 3780 eta 10:38:22: loss_a 1.948, un_loss_a 0.585, loss_b 1.943, un_loss_b 0.464, accuracy_a 0.531, accuracy_b 0.562
2022-05-29 21:12:23 - INFO - Epoch 1 step 3800 eta 10:37:17: loss_a 1.457, un_loss_a 0.618, loss_b 1.736, un_loss_b 0.549, accuracy_a 0.625, accuracy_b 0.594
2022-05-29 21:12:47 - INFO - Epoch 1 step 3820 eta 10:37:05: loss_a 1.236, un_loss_a 0.807, loss_b 1.490, un_loss_b 0.615, accuracy_a 0.625, accuracy_b 0.594
2022-05-29 21:13:08 - INFO - Epoch 1 step 3840 eta 10:36:00: loss_a 1.469, un_loss_a 0.705, loss_b 1.628, un_loss_b 0.609, accuracy_a 0.625, accuracy_b 0.500
2022-05-29 21:13:31 - INFO - Epoch 1 step 3860 eta 10:35:47: loss_a 1.743, un_loss_a 0.586, loss_b 1.953, un_loss_b 0.576, accuracy_a 0.562, accuracy_b 0.625
2022-05-29 21:13:53 - INFO - Epoch 1 step 3880 eta 10:34:43: loss_a 0.965, un_loss_a 0.501, loss_b 1.171, un_loss_b 0.567, accuracy_a 0.719, accuracy_b 0.656
2022-05-29 21:14:14 - INFO - Epoch 1 step 3900 eta 10:33:40: loss_a 1.406, un_loss_a 0.598, loss_b 1.397, un_loss_b 0.746, accuracy_a 0.625, accuracy_b 0.688
2022-05-29 21:14:38 - INFO - Epoch 1 step 3920 eta 10:33:26: loss_a 0.810, un_loss_a 0.556, loss_b 0.885, un_loss_b 0.495, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 21:14:59 - INFO - Epoch 1 step 3940 eta 10:32:23: loss_a 0.938, un_loss_a 0.268, loss_b 1.181, un_loss_b 0.303, accuracy_a 0.719, accuracy_b 0.656
2022-05-29 21:15:21 - INFO - Epoch 1 step 3960 eta 10:31:20: loss_a 0.855, un_loss_a 0.458, loss_b 0.863, un_loss_b 0.585, accuracy_a 0.719, accuracy_b 0.781
2022-05-29 21:15:44 - INFO - Epoch 1 step 3980 eta 10:31:09: loss_a 1.365, un_loss_a 0.352, loss_b 1.559, un_loss_b 0.513, accuracy_a 0.625, accuracy_b 0.625
2022-05-29 21:16:05 - INFO - Epoch 1 step 4000 eta 10:30:07: loss_a 0.823, un_loss_a 0.298, loss_b 0.914, un_loss_b 0.309, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 21:16:29 - INFO - Epoch 1 step 4020 eta 10:29:54: loss_a 0.765, un_loss_a 0.701, loss_b 0.790, un_loss_b 0.549, accuracy_a 0.812, accuracy_b 0.844
2022-05-29 21:16:50 - INFO - Epoch 1 step 4040 eta 10:28:53: loss_a 1.337, un_loss_a 0.522, loss_b 1.437, un_loss_b 0.416, accuracy_a 0.688, accuracy_b 0.719
2022-05-29 21:17:12 - INFO - Epoch 1 step 4060 eta 10:27:52: loss_a 1.187, un_loss_a 0.376, loss_b 1.224, un_loss_b 0.319, accuracy_a 0.688, accuracy_b 0.719
2022-05-29 21:17:35 - INFO - Epoch 1 step 4080 eta 10:27:39: loss_a 0.953, un_loss_a 0.424, loss_b 0.935, un_loss_b 0.548, accuracy_a 0.750, accuracy_b 0.781
2022-05-29 21:17:56 - INFO - Epoch 1 step 4100 eta 10:26:39: loss_a 1.105, un_loss_a 0.469, loss_b 0.955, un_loss_b 0.644, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 21:18:20 - INFO - Epoch 1 step 4120 eta 10:26:28: loss_a 1.183, un_loss_a 0.632, loss_b 1.214, un_loss_b 0.499, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 21:18:41 - INFO - Epoch 1 step 4140 eta 10:25:28: loss_a 0.629, un_loss_a 0.460, loss_b 0.727, un_loss_b 0.451, accuracy_a 0.875, accuracy_b 0.812
2022-05-29 21:19:03 - INFO - Epoch 1 step 4160 eta 10:24:28: loss_a 1.430, un_loss_a 0.555, loss_b 1.562, un_loss_b 0.464, accuracy_a 0.688, accuracy_b 0.594
2022-05-29 21:19:26 - INFO - Epoch 1 step 4180 eta 10:24:17: loss_a 1.456, un_loss_a 0.296, loss_b 1.497, un_loss_b 0.356, accuracy_a 0.625, accuracy_b 0.656
2022-05-29 21:19:47 - INFO - Epoch 1 step 4200 eta 10:23:18: loss_a 0.624, un_loss_a 0.454, loss_b 0.678, un_loss_b 0.416, accuracy_a 0.812, accuracy_b 0.781
2022-05-29 21:20:11 - INFO - Epoch 1 step 4220 eta 10:23:17: loss_a 1.355, un_loss_a 0.527, loss_b 1.279, un_loss_b 0.535, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 21:20:33 - INFO - Epoch 1 step 4240 eta 10:22:19: loss_a 1.292, un_loss_a 0.519, loss_b 1.169, un_loss_b 0.650, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 21:20:56 - INFO - Epoch 1 step 4260 eta 10:22:12: loss_a 1.031, un_loss_a 0.793, loss_b 0.871, un_loss_b 0.650, accuracy_a 0.812, accuracy_b 0.750
2022-05-29 21:21:18 - INFO - Epoch 1 step 4280 eta 10:21:14: loss_a 1.850, un_loss_a 0.538, loss_b 1.674, un_loss_b 0.430, accuracy_a 0.625, accuracy_b 0.594
2022-05-29 21:21:39 - INFO - Epoch 1 step 4300 eta 10:20:16: loss_a 0.887, un_loss_a 0.415, loss_b 0.808, un_loss_b 0.389, accuracy_a 0.750, accuracy_b 0.781
2022-05-29 21:22:02 - INFO - Epoch 1 step 4320 eta 10:20:05: loss_a 1.234, un_loss_a 0.368, loss_b 1.358, un_loss_b 0.334, accuracy_a 0.719, accuracy_b 0.781
2022-05-29 21:22:24 - INFO - Epoch 1 step 4340 eta 10:19:08: loss_a 1.278, un_loss_a 0.506, loss_b 0.989, un_loss_b 0.500, accuracy_a 0.719, accuracy_b 0.812
2022-05-29 21:22:47 - INFO - Epoch 1 step 4360 eta 10:19:03: loss_a 1.311, un_loss_a 0.652, loss_b 1.323, un_loss_b 0.583, accuracy_a 0.562, accuracy_b 0.594
2022-05-29 21:23:09 - INFO - Epoch 1 step 4380 eta 10:18:06: loss_a 0.983, un_loss_a 0.551, loss_b 0.900, un_loss_b 0.523, accuracy_a 0.781, accuracy_b 0.719
2022-05-29 21:23:30 - INFO - Epoch 1 step 4400 eta 10:17:09: loss_a 1.460, un_loss_a 0.437, loss_b 1.485, un_loss_b 0.505, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 21:23:54 - INFO - Epoch 1 step 4420 eta 10:17:04: loss_a 0.907, un_loss_a 0.332, loss_b 0.949, un_loss_b 0.306, accuracy_a 0.750, accuracy_b 0.688
2022-05-29 21:24:15 - INFO - Epoch 1 step 4440 eta 10:16:07: loss_a 1.921, un_loss_a 0.540, loss_b 1.901, un_loss_b 0.524, accuracy_a 0.562, accuracy_b 0.531
2022-05-29 21:24:39 - INFO - Epoch 1 step 4460 eta 10:15:56: loss_a 1.833, un_loss_a 0.716, loss_b 1.811, un_loss_b 0.508, accuracy_a 0.562, accuracy_b 0.688
2022-05-29 21:25:00 - INFO - Epoch 1 step 4480 eta 10:15:00: loss_a 1.208, un_loss_a 0.613, loss_b 1.101, un_loss_b 0.590, accuracy_a 0.625, accuracy_b 0.719
2022-05-29 21:25:22 - INFO - Epoch 1 step 4500 eta 10:14:05: loss_a 0.847, un_loss_a 0.421, loss_b 0.825, un_loss_b 0.290, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 21:25:45 - INFO - Epoch 1 step 4520 eta 10:13:54: loss_a 1.544, un_loss_a 0.508, loss_b 1.368, un_loss_b 0.464, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 21:26:06 - INFO - Epoch 1 step 4540 eta 10:12:59: loss_a 1.411, un_loss_a 0.477, loss_b 1.598, un_loss_b 0.445, accuracy_a 0.594, accuracy_b 0.531
2022-05-29 21:26:28 - INFO - Epoch 1 step 4560 eta 10:12:03: loss_a 1.257, un_loss_a 0.786, loss_b 1.452, un_loss_b 0.573, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 21:26:51 - INFO - Epoch 1 step 4580 eta 10:11:53: loss_a 0.619, un_loss_a 0.299, loss_b 0.565, un_loss_b 0.383, accuracy_a 0.844, accuracy_b 0.781
2022-05-29 21:27:13 - INFO - Epoch 1 step 4600 eta 10:10:58: loss_a 1.797, un_loss_a 0.457, loss_b 1.597, un_loss_b 0.459, accuracy_a 0.594, accuracy_b 0.750
2022-05-29 21:27:34 - INFO - Epoch 1 step 4620 eta 10:10:04: loss_a 0.953, un_loss_a 0.529, loss_b 1.010, un_loss_b 0.438, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 21:27:57 - INFO - Epoch 1 step 4640 eta 10:09:53: loss_a 1.193, un_loss_a 0.594, loss_b 1.480, un_loss_b 0.641, accuracy_a 0.625, accuracy_b 0.625
2022-05-29 21:28:19 - INFO - Epoch 1 step 4660 eta 10:08:59: loss_a 1.429, un_loss_a 0.522, loss_b 1.638, un_loss_b 0.573, accuracy_a 0.656, accuracy_b 0.625
2022-05-29 21:28:42 - INFO - Epoch 1 step 4680 eta 10:08:47: loss_a 1.195, un_loss_a 0.669, loss_b 1.184, un_loss_b 0.710, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 21:29:04 - INFO - Epoch 1 step 4700 eta 10:07:54: loss_a 0.612, un_loss_a 0.593, loss_b 0.723, un_loss_b 0.474, accuracy_a 0.812, accuracy_b 0.781
2022-05-29 21:29:25 - INFO - Epoch 1 step 4720 eta 10:07:01: loss_a 1.256, un_loss_a 0.455, loss_b 1.013, un_loss_b 0.453, accuracy_a 0.719, accuracy_b 0.719
2022-05-29 21:29:48 - INFO - Epoch 1 step 4740 eta 10:06:49: loss_a 0.696, un_loss_a 0.490, loss_b 0.742, un_loss_b 0.636, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 21:30:10 - INFO - Epoch 1 step 4760 eta 10:05:56: loss_a 1.092, un_loss_a 0.416, loss_b 1.117, un_loss_b 0.329, accuracy_a 0.656, accuracy_b 0.656
2022-05-29 21:30:33 - INFO - Epoch 1 step 4780 eta 10:05:46: loss_a 1.666, un_loss_a 0.497, loss_b 1.671, un_loss_b 0.394, accuracy_a 0.500, accuracy_b 0.562
2022-05-29 21:30:55 - INFO - Epoch 1 step 4800 eta 10:04:53: loss_a 1.240, un_loss_a 0.560, loss_b 1.023, un_loss_b 0.609, accuracy_a 0.562, accuracy_b 0.750
2022-05-29 21:31:16 - INFO - Epoch 1 step 4820 eta 10:04:01: loss_a 1.164, un_loss_a 0.470, loss_b 0.974, un_loss_b 0.474, accuracy_a 0.719, accuracy_b 0.750
2022-05-29 21:31:39 - INFO - Epoch 1 step 4840 eta 10:03:50: loss_a 1.198, un_loss_a 0.353, loss_b 1.226, un_loss_b 0.352, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 21:32:01 - INFO - Epoch 1 step 4860 eta 10:02:58: loss_a 1.050, un_loss_a 0.513, loss_b 1.186, un_loss_b 0.652, accuracy_a 0.656, accuracy_b 0.625
2022-05-29 21:32:24 - INFO - Epoch 1 step 4880 eta 10:02:45: loss_a 1.468, un_loss_a 0.546, loss_b 1.462, un_loss_b 0.540, accuracy_a 0.562, accuracy_b 0.531
2022-05-29 21:32:46 - INFO - Epoch 1 step 4900 eta 10:01:53: loss_a 1.472, un_loss_a 0.336, loss_b 1.641, un_loss_b 0.588, accuracy_a 0.625, accuracy_b 0.562
2022-05-29 21:33:09 - INFO - Epoch 1 step 4920 eta 10:01:42: loss_a 1.226, un_loss_a 0.496, loss_b 1.181, un_loss_b 0.390, accuracy_a 0.625, accuracy_b 0.688
2022-05-29 21:33:30 - INFO - Epoch 1 step 4940 eta 10:00:51: loss_a 0.738, un_loss_a 0.632, loss_b 0.833, un_loss_b 0.746, accuracy_a 0.656, accuracy_b 0.656
2022-05-29 21:33:52 - INFO - Epoch 1 step 4960 eta 10:00:00: loss_a 1.231, un_loss_a 0.442, loss_b 1.294, un_loss_b 0.470, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 21:34:15 - INFO - Epoch 1 step 4980 eta 09:59:50: loss_a 0.922, un_loss_a 0.450, loss_b 1.087, un_loss_b 0.442, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 21:34:37 - INFO - Epoch 1 step 5000 eta 09:58:59: loss_a 0.744, un_loss_a 0.581, loss_b 0.928, un_loss_b 0.456, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 21:35:00 - INFO - Epoch 1 step 5020 eta 09:58:56: loss_a 1.162, un_loss_a 0.698, loss_b 1.244, un_loss_b 0.623, accuracy_a 0.656, accuracy_b 0.656
2022-05-29 21:35:22 - INFO - Epoch 1 step 5040 eta 09:58:06: loss_a 0.708, un_loss_a 0.392, loss_b 0.708, un_loss_b 0.452, accuracy_a 0.750, accuracy_b 0.812
2022-05-29 21:35:43 - INFO - Epoch 1 step 5060 eta 09:57:16: loss_a 1.248, un_loss_a 0.903, loss_b 1.329, un_loss_b 0.582, accuracy_a 0.656, accuracy_b 0.625
2022-05-29 21:36:07 - INFO - Epoch 1 step 5080 eta 09:57:09: loss_a 1.135, un_loss_a 0.494, loss_b 1.203, un_loss_b 0.429, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 21:36:28 - INFO - Epoch 1 step 5100 eta 09:56:19: loss_a 1.128, un_loss_a 0.451, loss_b 0.996, un_loss_b 0.465, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 21:36:52 - INFO - Epoch 1 step 5120 eta 09:56:08: loss_a 0.784, un_loss_a 0.424, loss_b 0.673, un_loss_b 0.523, accuracy_a 0.781, accuracy_b 0.844
2022-05-29 21:37:13 - INFO - Epoch 1 step 5140 eta 09:55:19: loss_a 1.049, un_loss_a 0.308, loss_b 0.905, un_loss_b 0.342, accuracy_a 0.688, accuracy_b 0.781
2022-05-29 21:37:35 - INFO - Epoch 1 step 5160 eta 09:54:29: loss_a 1.367, un_loss_a 0.427, loss_b 1.291, un_loss_b 0.356, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 21:37:58 - INFO - Epoch 1 step 5180 eta 09:54:18: loss_a 1.074, un_loss_a 0.575, loss_b 1.133, un_loss_b 0.452, accuracy_a 0.719, accuracy_b 0.656
2022-05-29 21:38:19 - INFO - Epoch 1 step 5200 eta 09:53:30: loss_a 1.313, un_loss_a 0.437, loss_b 1.339, un_loss_b 0.636, accuracy_a 0.719, accuracy_b 0.688
2022-05-29 21:38:41 - INFO - Epoch 1 step 5220 eta 09:52:41: loss_a 1.605, un_loss_a 0.492, loss_b 1.501, un_loss_b 0.456, accuracy_a 0.625, accuracy_b 0.688
2022-05-29 21:39:04 - INFO - Epoch 1 step 5240 eta 09:52:31: loss_a 1.200, un_loss_a 0.582, loss_b 1.429, un_loss_b 0.463, accuracy_a 0.656, accuracy_b 0.594
2022-05-29 21:39:26 - INFO - Epoch 1 step 5260 eta 09:51:42: loss_a 1.218, un_loss_a 0.556, loss_b 1.090, un_loss_b 0.477, accuracy_a 0.656, accuracy_b 0.625
2022-05-29 21:39:49 - INFO - Epoch 1 step 5280 eta 09:51:40: loss_a 1.437, un_loss_a 0.501, loss_b 1.584, un_loss_b 0.465, accuracy_a 0.625, accuracy_b 0.594
2022-05-29 21:40:11 - INFO - Epoch 1 step 5300 eta 09:50:52: loss_a 1.242, un_loss_a 0.484, loss_b 1.306, un_loss_b 0.523, accuracy_a 0.594, accuracy_b 0.594
2022-05-29 21:40:32 - INFO - Epoch 1 step 5320 eta 09:50:03: loss_a 1.073, un_loss_a 0.401, loss_b 1.165, un_loss_b 0.418, accuracy_a 0.719, accuracy_b 0.719
2022-05-29 21:40:56 - INFO - Epoch 1 step 5340 eta 09:49:56: loss_a 1.245, un_loss_a 0.598, loss_b 1.229, un_loss_b 0.600, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 21:41:17 - INFO - Epoch 1 step 5360 eta 09:49:08: loss_a 1.198, un_loss_a 0.417, loss_b 1.223, un_loss_b 0.549, accuracy_a 0.688, accuracy_b 0.719
2022-05-29 21:41:41 - INFO - Epoch 1 step 5380 eta 09:48:57: loss_a 1.513, un_loss_a 0.490, loss_b 1.432, un_loss_b 0.396, accuracy_a 0.656, accuracy_b 0.625
2022-05-29 21:42:02 - INFO - Epoch 1 step 5400 eta 09:48:09: loss_a 1.383, un_loss_a 0.512, loss_b 1.129, un_loss_b 0.487, accuracy_a 0.594, accuracy_b 0.719
2022-05-29 21:42:24 - INFO - Epoch 1 step 5420 eta 09:47:21: loss_a 1.096, un_loss_a 0.675, loss_b 1.028, un_loss_b 0.627, accuracy_a 0.719, accuracy_b 0.750
2022-05-29 21:42:47 - INFO - Epoch 1 step 5440 eta 09:47:08: loss_a 1.065, un_loss_a 0.676, loss_b 0.912, un_loss_b 0.616, accuracy_a 0.750, accuracy_b 0.812
2022-05-29 21:43:08 - INFO - Epoch 1 step 5460 eta 09:46:20: loss_a 1.223, un_loss_a 0.599, loss_b 1.197, un_loss_b 0.532, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 21:43:32 - INFO - Epoch 1 step 5480 eta 09:46:09: loss_a 0.918, un_loss_a 0.466, loss_b 0.757, un_loss_b 0.412, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 21:43:53 - INFO - Epoch 1 step 5500 eta 09:45:21: loss_a 0.981, un_loss_a 0.664, loss_b 0.827, un_loss_b 0.633, accuracy_a 0.781, accuracy_b 0.781
2022-05-29 21:44:14 - INFO - Epoch 1 step 5520 eta 09:44:34: loss_a 2.019, un_loss_a 0.579, loss_b 2.086, un_loss_b 0.556, accuracy_a 0.500, accuracy_b 0.531
2022-05-29 21:44:38 - INFO - Epoch 1 step 5540 eta 09:44:21: loss_a 1.765, un_loss_a 0.502, loss_b 1.998, un_loss_b 0.380, accuracy_a 0.531, accuracy_b 0.469
2022-05-29 21:44:59 - INFO - Epoch 1 step 5560 eta 09:43:34: loss_a 0.979, un_loss_a 0.463, loss_b 0.947, un_loss_b 0.566, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 21:45:22 - INFO - Epoch 1 step 5580 eta 09:43:23: loss_a 1.409, un_loss_a 0.427, loss_b 1.376, un_loss_b 0.480, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 21:45:44 - INFO - Epoch 1 step 5600 eta 09:42:37: loss_a 1.086, un_loss_a 0.636, loss_b 1.034, un_loss_b 0.519, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 21:46:07 - INFO - Epoch 1 step 5620 eta 09:42:24: loss_a 1.391, un_loss_a 0.346, loss_b 1.501, un_loss_b 0.463, accuracy_a 0.719, accuracy_b 0.625
Begin Validation
2022-05-29 21:48:14 - INFO - Epoch 1 step 5624:, {'lv1_acc': 0.7599, 'lv2_acc': 0.6511, 'lv1_f1_micro': 0.7599, 'lv1_f1_macro': 0.722, 'lv2_f1_micro': 0.6511, 'lv2_f1_macro': 0.4623, 'mean_f1': 0.6488}, {'lv1_acc': 0.7672, 'lv2_acc': 0.6538, 'lv1_f1_micro': 0.7672, 'lv1_f1_macro': 0.7338, 'lv2_f1_micro': 0.6538, 'lv2_f1_macro': 0.4753, 'mean_f1': 0.6575}
/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-05-29 21:48:35 - INFO - Epoch 2 step 5640 eta 10:21:36: loss_a 0.582, un_loss_a 0.451, loss_b 0.686, un_loss_b 0.400, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 21:48:57 - INFO - Epoch 2 step 5660 eta 10:20:41: loss_a 0.900, un_loss_a 0.557, loss_b 1.036, un_loss_b 0.631, accuracy_a 0.812, accuracy_b 0.719
2022-05-29 21:49:20 - INFO - Epoch 2 step 5680 eta 10:20:24: loss_a 1.053, un_loss_a 0.460, loss_b 1.124, un_loss_b 0.485, accuracy_a 0.625, accuracy_b 0.625
2022-05-29 21:49:42 - INFO - Epoch 2 step 5700 eta 10:19:30: loss_a 1.109, un_loss_a 0.500, loss_b 1.158, un_loss_b 0.412, accuracy_a 0.625, accuracy_b 0.594
2022-05-29 21:50:03 - INFO - Epoch 2 step 5720 eta 10:18:35: loss_a 1.148, un_loss_a 0.382, loss_b 1.254, un_loss_b 0.296, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 21:50:26 - INFO - Epoch 2 step 5740 eta 10:18:15: loss_a 0.655, un_loss_a 0.423, loss_b 0.836, un_loss_b 0.530, accuracy_a 0.781, accuracy_b 0.688
2022-05-29 21:50:48 - INFO - Epoch 2 step 5760 eta 10:17:21: loss_a 0.990, un_loss_a 0.406, loss_b 1.015, un_loss_b 0.625, accuracy_a 0.625, accuracy_b 0.656
2022-05-29 21:51:12 - INFO - Epoch 2 step 5780 eta 10:17:10: loss_a 0.647, un_loss_a 0.532, loss_b 0.805, un_loss_b 0.429, accuracy_a 0.875, accuracy_b 0.812
2022-05-29 21:51:33 - INFO - Epoch 2 step 5800 eta 10:16:17: loss_a 1.166, un_loss_a 0.717, loss_b 1.249, un_loss_b 0.529, accuracy_a 0.656, accuracy_b 0.719
2022-05-29 21:51:55 - INFO - Epoch 2 step 5820 eta 10:15:23: loss_a 0.817, un_loss_a 0.593, loss_b 0.929, un_loss_b 0.713, accuracy_a 0.812, accuracy_b 0.688
2022-05-29 21:52:18 - INFO - Epoch 2 step 5840 eta 10:15:09: loss_a 0.979, un_loss_a 0.375, loss_b 1.155, un_loss_b 0.363, accuracy_a 0.719, accuracy_b 0.688
2022-05-29 21:52:40 - INFO - Epoch 2 step 5860 eta 10:14:16: loss_a 1.044, un_loss_a 0.738, loss_b 0.990, un_loss_b 0.895, accuracy_a 0.656, accuracy_b 0.656
2022-05-29 21:53:03 - INFO - Epoch 2 step 5880 eta 10:14:04: loss_a 0.706, un_loss_a 0.488, loss_b 0.886, un_loss_b 0.540, accuracy_a 0.812, accuracy_b 0.688
2022-05-29 21:53:25 - INFO - Epoch 2 step 5900 eta 10:13:11: loss_a 0.915, un_loss_a 0.609, loss_b 0.759, un_loss_b 0.541, accuracy_a 0.750, accuracy_b 0.781
2022-05-29 21:53:46 - INFO - Epoch 2 step 5920 eta 10:12:19: loss_a 0.732, un_loss_a 0.609, loss_b 0.748, un_loss_b 0.463, accuracy_a 0.812, accuracy_b 0.750
2022-05-29 21:54:10 - INFO - Epoch 2 step 5940 eta 10:12:03: loss_a 1.514, un_loss_a 0.651, loss_b 1.491, un_loss_b 0.570, accuracy_a 0.562, accuracy_b 0.625
2022-05-29 21:54:31 - INFO - Epoch 2 step 5960 eta 10:11:10: loss_a 0.729, un_loss_a 0.519, loss_b 0.642, un_loss_b 0.389, accuracy_a 0.844, accuracy_b 0.812
2022-05-29 21:54:55 - INFO - Epoch 2 step 5980 eta 10:10:47: loss_a 0.936, un_loss_a 0.425, loss_b 1.307, un_loss_b 0.529, accuracy_a 0.750, accuracy_b 0.562
2022-05-29 21:55:16 - INFO - Epoch 2 step 6000 eta 10:09:55: loss_a 0.656, un_loss_a 0.606, loss_b 0.665, un_loss_b 0.490, accuracy_a 0.719, accuracy_b 0.750
2022-05-29 21:55:38 - INFO - Epoch 2 step 6020 eta 10:09:04: loss_a 1.036, un_loss_a 0.336, loss_b 1.005, un_loss_b 0.339, accuracy_a 0.719, accuracy_b 0.750
2022-05-29 21:56:01 - INFO - Epoch 2 step 6040 eta 10:08:40: loss_a 0.662, un_loss_a 0.544, loss_b 0.696, un_loss_b 0.590, accuracy_a 0.844, accuracy_b 0.781
2022-05-29 21:56:22 - INFO - Epoch 2 step 6060 eta 10:07:48: loss_a 0.510, un_loss_a 0.496, loss_b 0.541, un_loss_b 0.394, accuracy_a 0.875, accuracy_b 0.781
2022-05-29 21:56:45 - INFO - Epoch 2 step 6080 eta 10:07:26: loss_a 1.196, un_loss_a 0.609, loss_b 1.297, un_loss_b 0.613, accuracy_a 0.656, accuracy_b 0.625
2022-05-29 21:57:07 - INFO - Epoch 2 step 6100 eta 10:06:34: loss_a 0.553, un_loss_a 0.889, loss_b 0.562, un_loss_b 0.737, accuracy_a 0.781, accuracy_b 0.844
2022-05-29 21:57:30 - INFO - Epoch 2 step 6120 eta 10:06:11: loss_a 0.828, un_loss_a 0.366, loss_b 0.991, un_loss_b 0.368, accuracy_a 0.781, accuracy_b 0.781
2022-05-29 21:57:51 - INFO - Epoch 2 step 6140 eta 10:05:20: loss_a 1.277, un_loss_a 0.545, loss_b 1.416, un_loss_b 0.493, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 21:58:13 - INFO - Epoch 2 step 6160 eta 10:04:29: loss_a 1.383, un_loss_a 0.492, loss_b 1.222, un_loss_b 0.927, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 21:58:36 - INFO - Epoch 2 step 6180 eta 10:04:18: loss_a 0.858, un_loss_a 0.406, loss_b 0.818, un_loss_b 0.358, accuracy_a 0.688, accuracy_b 0.750
2022-05-29 21:58:58 - INFO - Epoch 2 step 6200 eta 10:03:27: loss_a 1.059, un_loss_a 0.649, loss_b 1.054, un_loss_b 0.520, accuracy_a 0.625, accuracy_b 0.656
2022-05-29 21:59:21 - INFO - Epoch 2 step 6220 eta 10:03:11: loss_a 0.899, un_loss_a 0.517, loss_b 1.306, un_loss_b 0.567, accuracy_a 0.719, accuracy_b 0.625
2022-05-29 21:59:43 - INFO - Epoch 2 step 6240 eta 10:02:20: loss_a 0.673, un_loss_a 0.743, loss_b 0.878, un_loss_b 0.583, accuracy_a 0.875, accuracy_b 0.719
2022-05-29 22:00:04 - INFO - Epoch 2 step 6260 eta 10:01:30: loss_a 0.474, un_loss_a 0.639, loss_b 0.555, un_loss_b 0.440, accuracy_a 0.750, accuracy_b 0.781
2022-05-29 22:00:27 - INFO - Epoch 2 step 6280 eta 10:01:08: loss_a 0.813, un_loss_a 0.631, loss_b 1.094, un_loss_b 0.571, accuracy_a 0.719, accuracy_b 0.656
2022-05-29 22:00:49 - INFO - Epoch 2 step 6300 eta 10:00:18: loss_a 1.036, un_loss_a 0.872, loss_b 0.978, un_loss_b 0.713, accuracy_a 0.750, accuracy_b 0.688
2022-05-29 22:01:10 - INFO - Epoch 2 step 6320 eta 09:59:28: loss_a 1.023, un_loss_a 0.468, loss_b 1.068, un_loss_b 0.555, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 22:01:33 - INFO - Epoch 2 step 6340 eta 09:59:05: loss_a 0.743, un_loss_a 0.549, loss_b 1.032, un_loss_b 0.583, accuracy_a 0.781, accuracy_b 0.781
2022-05-29 22:01:55 - INFO - Epoch 2 step 6360 eta 09:58:15: loss_a 0.896, un_loss_a 0.402, loss_b 1.103, un_loss_b 0.611, accuracy_a 0.844, accuracy_b 0.719
2022-05-29 22:02:19 - INFO - Epoch 2 step 6380 eta 09:58:04: loss_a 0.662, un_loss_a 0.331, loss_b 0.802, un_loss_b 0.473, accuracy_a 0.750, accuracy_b 0.688
2022-05-29 22:02:40 - INFO - Epoch 2 step 6400 eta 09:57:14: loss_a 0.368, un_loss_a 0.585, loss_b 0.580, un_loss_b 0.708, accuracy_a 0.875, accuracy_b 0.844
2022-05-29 22:03:03 - INFO - Epoch 2 step 6420 eta 09:56:57: loss_a 0.743, un_loss_a 0.387, loss_b 0.684, un_loss_b 0.390, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 22:03:25 - INFO - Epoch 2 step 6440 eta 09:56:08: loss_a 0.701, un_loss_a 0.571, loss_b 0.720, un_loss_b 0.451, accuracy_a 0.812, accuracy_b 0.812
2022-05-29 22:03:46 - INFO - Epoch 2 step 6460 eta 09:55:19: loss_a 0.801, un_loss_a 0.589, loss_b 0.694, un_loss_b 0.568, accuracy_a 0.688, accuracy_b 0.781
2022-05-29 22:04:09 - INFO - Epoch 2 step 6480 eta 09:54:56: loss_a 1.373, un_loss_a 0.634, loss_b 1.073, un_loss_b 0.620, accuracy_a 0.719, accuracy_b 0.750
2022-05-29 22:04:31 - INFO - Epoch 2 step 6500 eta 09:54:07: loss_a 0.994, un_loss_a 0.528, loss_b 0.975, un_loss_b 0.668, accuracy_a 0.750, accuracy_b 0.781
2022-05-29 22:04:54 - INFO - Epoch 2 step 6520 eta 09:53:45: loss_a 1.137, un_loss_a 0.264, loss_b 1.241, un_loss_b 0.184, accuracy_a 0.688, accuracy_b 0.719
2022-05-29 22:05:15 - INFO - Epoch 2 step 6540 eta 09:52:56: loss_a 0.379, un_loss_a 0.474, loss_b 0.427, un_loss_b 0.508, accuracy_a 0.844, accuracy_b 0.844
2022-05-29 22:05:37 - INFO - Epoch 2 step 6560 eta 09:52:08: loss_a 0.930, un_loss_a 0.594, loss_b 1.182, un_loss_b 0.430, accuracy_a 0.688, accuracy_b 0.656
2022-05-29 22:06:00 - INFO - Epoch 2 step 6580 eta 09:51:47: loss_a 0.665, un_loss_a 0.513, loss_b 0.768, un_loss_b 0.655, accuracy_a 0.750, accuracy_b 0.688
2022-05-29 22:06:21 - INFO - Epoch 2 step 6600 eta 09:50:58: loss_a 0.670, un_loss_a 0.189, loss_b 0.557, un_loss_b 0.210, accuracy_a 0.812, accuracy_b 0.781
2022-05-29 22:06:45 - INFO - Epoch 2 step 6620 eta 09:50:36: loss_a 0.994, un_loss_a 0.668, loss_b 0.879, un_loss_b 0.706, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 22:07:06 - INFO - Epoch 2 step 6640 eta 09:49:49: loss_a 0.721, un_loss_a 0.590, loss_b 0.666, un_loss_b 0.699, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 22:07:27 - INFO - Epoch 2 step 6660 eta 09:49:01: loss_a 0.705, un_loss_a 0.487, loss_b 0.645, un_loss_b 0.329, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 22:07:51 - INFO - Epoch 2 step 6680 eta 09:48:39: loss_a 0.905, un_loss_a 0.511, loss_b 0.697, un_loss_b 0.364, accuracy_a 0.812, accuracy_b 0.781
2022-05-29 22:08:12 - INFO - Epoch 2 step 6700 eta 09:47:52: loss_a 0.946, un_loss_a 0.417, loss_b 1.209, un_loss_b 0.429, accuracy_a 0.781, accuracy_b 0.688
2022-05-29 22:08:33 - INFO - Epoch 2 step 6720 eta 09:47:05: loss_a 0.614, un_loss_a 0.531, loss_b 0.858, un_loss_b 0.472, accuracy_a 0.812, accuracy_b 0.688
2022-05-29 22:08:57 - INFO - Epoch 2 step 6740 eta 09:46:43: loss_a 0.617, un_loss_a 0.455, loss_b 0.717, un_loss_b 0.412, accuracy_a 0.781, accuracy_b 0.719
2022-05-29 22:09:18 - INFO - Epoch 2 step 6760 eta 09:45:56: loss_a 0.944, un_loss_a 0.504, loss_b 0.782, un_loss_b 0.657, accuracy_a 0.750, accuracy_b 0.781
2022-05-29 22:09:40 - INFO - Epoch 2 step 6780 eta 09:45:09: loss_a 1.541, un_loss_a 0.493, loss_b 1.345, un_loss_b 0.617, accuracy_a 0.656, accuracy_b 0.656
2022-05-29 22:10:03 - INFO - Epoch 2 step 6800 eta 09:44:48: loss_a 0.979, un_loss_a 0.532, loss_b 1.132, un_loss_b 0.415, accuracy_a 0.656, accuracy_b 0.688
2022-05-29 22:10:24 - INFO - Epoch 2 step 6820 eta 09:44:01: loss_a 0.832, un_loss_a 0.595, loss_b 0.887, un_loss_b 0.711, accuracy_a 0.750, accuracy_b 0.688
2022-05-29 22:10:47 - INFO - Epoch 2 step 6840 eta 09:43:40: loss_a 0.768, un_loss_a 0.533, loss_b 0.731, un_loss_b 0.472, accuracy_a 0.719, accuracy_b 0.750
2022-05-29 22:11:09 - INFO - Epoch 2 step 6860 eta 09:42:53: loss_a 0.846, un_loss_a 0.705, loss_b 0.946, un_loss_b 0.757, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 22:11:30 - INFO - Epoch 2 step 6880 eta 09:42:07: loss_a 0.447, un_loss_a 0.486, loss_b 0.609, un_loss_b 0.585, accuracy_a 0.875, accuracy_b 0.781
2022-05-29 22:11:53 - INFO - Epoch 2 step 6900 eta 09:41:46: loss_a 0.764, un_loss_a 0.460, loss_b 0.762, un_loss_b 0.368, accuracy_a 0.719, accuracy_b 0.750
2022-05-29 22:12:15 - INFO - Epoch 2 step 6920 eta 09:41:00: loss_a 0.785, un_loss_a 0.572, loss_b 0.593, un_loss_b 0.681, accuracy_a 0.719, accuracy_b 0.750
2022-05-29 22:12:38 - INFO - Epoch 2 step 6940 eta 09:40:39: loss_a 1.560, un_loss_a 0.743, loss_b 1.503, un_loss_b 0.661, accuracy_a 0.562, accuracy_b 0.594
2022-05-29 22:12:59 - INFO - Epoch 2 step 6960 eta 09:39:53: loss_a 0.734, un_loss_a 0.570, loss_b 0.779, un_loss_b 0.668, accuracy_a 0.750, accuracy_b 0.750
2022-05-29 22:13:21 - INFO - Epoch 2 step 6980 eta 09:39:07: loss_a 0.829, un_loss_a 0.639, loss_b 1.162, un_loss_b 0.692, accuracy_a 0.750, accuracy_b 0.688
2022-05-29 22:13:44 - INFO - Epoch 2 step 7000 eta 09:38:44: loss_a 1.576, un_loss_a 0.326, loss_b 1.702, un_loss_b 0.342, accuracy_a 0.562, accuracy_b 0.531
2022-05-29 22:14:05 - INFO - Epoch 2 step 7020 eta 09:37:58: loss_a 0.603, un_loss_a 0.590, loss_b 0.601, un_loss_b 0.468, accuracy_a 0.750, accuracy_b 0.812
2022-05-29 22:14:28 - INFO - Epoch 2 step 7040 eta 09:37:37: loss_a 0.909, un_loss_a 0.293, loss_b 1.128, un_loss_b 0.434, accuracy_a 0.750, accuracy_b 0.656
2022-05-29 22:14:50 - INFO - Epoch 2 step 7060 eta 09:36:51: loss_a 1.003, un_loss_a 0.607, loss_b 0.934, un_loss_b 0.593, accuracy_a 0.781, accuracy_b 0.656
2022-05-29 22:15:13 - INFO - Epoch 2 step 7080 eta 09:36:28: loss_a 0.689, un_loss_a 0.476, loss_b 0.850, un_loss_b 0.577, accuracy_a 0.781, accuracy_b 0.719
2022-05-29 22:15:34 - INFO - Epoch 2 step 7100 eta 09:35:43: loss_a 1.277, un_loss_a 0.544, loss_b 1.372, un_loss_b 0.683, accuracy_a 0.625, accuracy_b 0.656
2022-05-29 22:15:55 - INFO - Epoch 2 step 7120 eta 09:34:58: loss_a 1.006, un_loss_a 0.384, loss_b 1.008, un_loss_b 0.402, accuracy_a 0.750, accuracy_b 0.750
2022-05-29 22:16:19 - INFO - Epoch 2 step 7140 eta 09:34:37: loss_a 0.532, un_loss_a 0.462, loss_b 0.653, un_loss_b 0.441, accuracy_a 0.812, accuracy_b 0.688
2022-05-29 22:16:40 - INFO - Epoch 2 step 7160 eta 09:33:52: loss_a 1.002, un_loss_a 0.215, loss_b 1.168, un_loss_b 0.254, accuracy_a 0.719, accuracy_b 0.656
2022-05-29 22:17:03 - INFO - Epoch 2 step 7180 eta 09:33:30: loss_a 0.621, un_loss_a 0.487, loss_b 0.783, un_loss_b 0.644, accuracy_a 0.812, accuracy_b 0.719
2022-05-29 22:17:24 - INFO - Epoch 2 step 7200 eta 09:32:45: loss_a 0.544, un_loss_a 0.303, loss_b 0.474, un_loss_b 0.485, accuracy_a 0.812, accuracy_b 0.844
2022-05-29 22:17:46 - INFO - Epoch 2 step 7220 eta 09:32:01: loss_a 1.368, un_loss_a 0.715, loss_b 1.408, un_loss_b 0.560, accuracy_a 0.625, accuracy_b 0.625
2022-05-29 22:18:09 - INFO - Epoch 2 step 7240 eta 09:31:40: loss_a 0.739, un_loss_a 0.878, loss_b 0.665, un_loss_b 0.858, accuracy_a 0.750, accuracy_b 0.812
2022-05-29 22:18:30 - INFO - Epoch 2 step 7260 eta 09:30:55: loss_a 0.787, un_loss_a 0.688, loss_b 1.060, un_loss_b 0.791, accuracy_a 0.750, accuracy_b 0.656
2022-05-29 22:18:54 - INFO - Epoch 2 step 7280 eta 09:30:35: loss_a 0.563, un_loss_a 0.663, loss_b 0.803, un_loss_b 0.627, accuracy_a 0.844, accuracy_b 0.719
2022-05-29 22:19:15 - INFO - Epoch 2 step 7300 eta 09:29:50: loss_a 0.565, un_loss_a 0.409, loss_b 0.748, un_loss_b 0.626, accuracy_a 0.812, accuracy_b 0.781
2022-05-29 22:19:36 - INFO - Epoch 2 step 7320 eta 09:29:06: loss_a 0.815, un_loss_a 0.699, loss_b 0.882, un_loss_b 0.645, accuracy_a 0.688, accuracy_b 0.750
2022-05-29 22:20:00 - INFO - Epoch 2 step 7340 eta 09:28:46: loss_a 0.360, un_loss_a 0.283, loss_b 0.354, un_loss_b 0.326, accuracy_a 0.906, accuracy_b 0.906
2022-05-29 22:20:21 - INFO - Epoch 2 step 7360 eta 09:28:01: loss_a 0.749, un_loss_a 0.659, loss_b 0.739, un_loss_b 0.607, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 22:20:42 - INFO - Epoch 2 step 7380 eta 09:27:17: loss_a 0.833, un_loss_a 0.608, loss_b 0.923, un_loss_b 0.733, accuracy_a 0.688, accuracy_b 0.719
2022-05-29 22:21:06 - INFO - Epoch 2 step 7400 eta 09:26:58: loss_a 1.390, un_loss_a 0.396, loss_b 1.598, un_loss_b 0.404, accuracy_a 0.625, accuracy_b 0.562
2022-05-29 22:21:27 - INFO - Epoch 2 step 7420 eta 09:26:14: loss_a 1.428, un_loss_a 0.741, loss_b 1.457, un_loss_b 0.646, accuracy_a 0.562, accuracy_b 0.531
2022-05-29 22:21:50 - INFO - Epoch 2 step 7440 eta 09:25:53: loss_a 0.679, un_loss_a 0.357, loss_b 0.951, un_loss_b 0.358, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 22:22:12 - INFO - Epoch 2 step 7460 eta 09:25:09: loss_a 0.674, un_loss_a 0.447, loss_b 0.818, un_loss_b 0.346, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 22:22:33 - INFO - Epoch 2 step 7480 eta 09:24:26: loss_a 0.718, un_loss_a 0.359, loss_b 0.783, un_loss_b 0.297, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 22:22:56 - INFO - Epoch 2 step 7500 eta 09:24:06: loss_a 1.154, un_loss_a 0.542, loss_b 1.412, un_loss_b 0.522, accuracy_a 0.719, accuracy_b 0.594
2022-05-29 22:23:18 - INFO - Epoch 2 step 7520 eta 09:23:23: loss_a 1.098, un_loss_a 0.372, loss_b 1.162, un_loss_b 0.456, accuracy_a 0.750, accuracy_b 0.688
2022-05-29 22:23:41 - INFO - Epoch 2 step 7540 eta 09:23:03: loss_a 0.459, un_loss_a 0.629, loss_b 0.571, un_loss_b 0.631, accuracy_a 0.781, accuracy_b 0.875
2022-05-29 22:24:02 - INFO - Epoch 2 step 7560 eta 09:22:19: loss_a 0.609, un_loss_a 0.629, loss_b 0.629, un_loss_b 0.682, accuracy_a 0.812, accuracy_b 0.750
2022-05-29 22:24:24 - INFO - Epoch 2 step 7580 eta 09:21:36: loss_a 0.711, un_loss_a 0.372, loss_b 0.889, un_loss_b 0.397, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 22:24:46 - INFO - Epoch 2 step 7600 eta 09:21:14: loss_a 1.082, un_loss_a 0.748, loss_b 1.307, un_loss_b 0.746, accuracy_a 0.719, accuracy_b 0.719
2022-05-29 22:25:08 - INFO - Epoch 2 step 7620 eta 09:20:31: loss_a 0.572, un_loss_a 0.670, loss_b 0.466, un_loss_b 0.631, accuracy_a 0.812, accuracy_b 0.812
2022-05-29 22:25:31 - INFO - Epoch 2 step 7640 eta 09:20:13: loss_a 1.175, un_loss_a 0.279, loss_b 1.298, un_loss_b 0.436, accuracy_a 0.656, accuracy_b 0.625
2022-05-29 22:25:53 - INFO - Epoch 2 step 7660 eta 09:19:30: loss_a 1.046, un_loss_a 0.649, loss_b 0.991, un_loss_b 0.551, accuracy_a 0.719, accuracy_b 0.656
2022-05-29 22:26:14 - INFO - Epoch 2 step 7680 eta 09:18:48: loss_a 1.573, un_loss_a 0.341, loss_b 1.437, un_loss_b 0.375, accuracy_a 0.594, accuracy_b 0.656
2022-05-29 22:26:38 - INFO - Epoch 2 step 7700 eta 09:18:36: loss_a 0.884, un_loss_a 0.331, loss_b 0.846, un_loss_b 0.366, accuracy_a 0.812, accuracy_b 0.812
2022-05-29 22:26:59 - INFO - Epoch 2 step 7720 eta 09:17:54: loss_a 0.950, un_loss_a 0.484, loss_b 1.067, un_loss_b 0.533, accuracy_a 0.781, accuracy_b 0.688
2022-05-29 22:27:23 - INFO - Epoch 2 step 7740 eta 09:17:39: loss_a 1.210, un_loss_a 0.553, loss_b 1.432, un_loss_b 0.523, accuracy_a 0.656, accuracy_b 0.625
2022-05-29 22:27:44 - INFO - Epoch 2 step 7760 eta 09:16:56: loss_a 0.599, un_loss_a 0.744, loss_b 0.719, un_loss_b 0.700, accuracy_a 0.875, accuracy_b 0.781
2022-05-29 22:28:07 - INFO - Epoch 2 step 7780 eta 09:16:36: loss_a 0.653, un_loss_a 0.522, loss_b 0.864, un_loss_b 0.507, accuracy_a 0.812, accuracy_b 0.844
2022-05-29 22:28:29 - INFO - Epoch 2 step 7800 eta 09:15:54: loss_a 0.693, un_loss_a 0.382, loss_b 0.674, un_loss_b 0.408, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 22:28:50 - INFO - Epoch 2 step 7820 eta 09:15:12: loss_a 1.105, un_loss_a 0.673, loss_b 1.395, un_loss_b 0.539, accuracy_a 0.719, accuracy_b 0.625
2022-05-29 22:29:13 - INFO - Epoch 2 step 7840 eta 09:14:50: loss_a 0.427, un_loss_a 0.799, loss_b 0.566, un_loss_b 0.807, accuracy_a 0.875, accuracy_b 0.875
2022-05-29 22:29:34 - INFO - Epoch 2 step 7860 eta 09:14:08: loss_a 0.694, un_loss_a 0.161, loss_b 0.943, un_loss_b 0.231, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 22:29:58 - INFO - Epoch 2 step 7880 eta 09:13:48: loss_a 0.947, un_loss_a 0.439, loss_b 0.880, un_loss_b 0.541, accuracy_a 0.781, accuracy_b 0.719
2022-05-29 22:30:19 - INFO - Epoch 2 step 7900 eta 09:13:06: loss_a 0.867, un_loss_a 0.405, loss_b 0.881, un_loss_b 0.479, accuracy_a 0.719, accuracy_b 0.719
2022-05-29 22:30:40 - INFO - Epoch 2 step 7920 eta 09:12:25: loss_a 0.622, un_loss_a 0.316, loss_b 0.840, un_loss_b 0.273, accuracy_a 0.781, accuracy_b 0.719
2022-05-29 22:31:04 - INFO - Epoch 2 step 7940 eta 09:12:05: loss_a 0.536, un_loss_a 0.410, loss_b 0.478, un_loss_b 0.509, accuracy_a 0.906, accuracy_b 0.938
2022-05-29 22:31:25 - INFO - Epoch 2 step 7960 eta 09:11:23: loss_a 0.937, un_loss_a 0.781, loss_b 0.856, un_loss_b 0.823, accuracy_a 0.812, accuracy_b 0.750
2022-05-29 22:31:46 - INFO - Epoch 2 step 7980 eta 09:10:42: loss_a 0.702, un_loss_a 0.517, loss_b 0.738, un_loss_b 0.538, accuracy_a 0.781, accuracy_b 0.781
2022-05-29 22:32:10 - INFO - Epoch 2 step 8000 eta 09:10:22: loss_a 1.334, un_loss_a 0.380, loss_b 1.272, un_loss_b 0.393, accuracy_a 0.688, accuracy_b 0.719
2022-05-29 22:32:31 - INFO - Epoch 2 step 8020 eta 09:09:40: loss_a 1.244, un_loss_a 0.448, loss_b 1.225, un_loss_b 0.435, accuracy_a 0.625, accuracy_b 0.719
2022-05-29 22:32:52 - INFO - Epoch 2 step 8040 eta 09:08:59: loss_a 1.421, un_loss_a 0.424, loss_b 1.209, un_loss_b 0.660, accuracy_a 0.562, accuracy_b 0.625
2022-05-29 22:33:15 - INFO - Epoch 2 step 8060 eta 09:08:38: loss_a 0.710, un_loss_a 0.358, loss_b 0.620, un_loss_b 0.376, accuracy_a 0.875, accuracy_b 0.812
2022-05-29 22:33:37 - INFO - Epoch 2 step 8080 eta 09:07:57: loss_a 0.783, un_loss_a 0.724, loss_b 0.547, un_loss_b 0.514, accuracy_a 0.781, accuracy_b 0.844
2022-05-29 22:34:00 - INFO - Epoch 2 step 8100 eta 09:07:37: loss_a 0.780, un_loss_a 0.520, loss_b 0.688, un_loss_b 0.602, accuracy_a 0.719, accuracy_b 0.781
2022-05-29 22:34:21 - INFO - Epoch 2 step 8120 eta 09:06:56: loss_a 0.684, un_loss_a 0.471, loss_b 0.755, un_loss_b 0.325, accuracy_a 0.812, accuracy_b 0.750
2022-05-29 22:34:43 - INFO - Epoch 2 step 8140 eta 09:06:15: loss_a 0.808, un_loss_a 0.508, loss_b 0.788, un_loss_b 0.440, accuracy_a 0.844, accuracy_b 0.719
2022-05-29 22:35:06 - INFO - Epoch 2 step 8160 eta 09:05:55: loss_a 1.187, un_loss_a 0.671, loss_b 1.293, un_loss_b 0.662, accuracy_a 0.656, accuracy_b 0.531
2022-05-29 22:35:27 - INFO - Epoch 2 step 8180 eta 09:05:14: loss_a 0.371, un_loss_a 0.628, loss_b 0.395, un_loss_b 0.714, accuracy_a 0.875, accuracy_b 0.906
2022-05-29 22:35:50 - INFO - Epoch 2 step 8200 eta 09:04:55: loss_a 1.060, un_loss_a 0.319, loss_b 1.311, un_loss_b 0.391, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 22:36:12 - INFO - Epoch 2 step 8220 eta 09:04:14: loss_a 0.925, un_loss_a 0.655, loss_b 0.930, un_loss_b 0.847, accuracy_a 0.750, accuracy_b 0.688
2022-05-29 22:36:33 - INFO - Epoch 2 step 8240 eta 09:03:34: loss_a 0.579, un_loss_a 0.486, loss_b 0.439, un_loss_b 0.614, accuracy_a 0.844, accuracy_b 0.844
2022-05-29 22:36:56 - INFO - Epoch 2 step 8260 eta 09:03:15: loss_a 0.613, un_loss_a 0.373, loss_b 0.727, un_loss_b 0.569, accuracy_a 0.812, accuracy_b 0.812
2022-05-29 22:37:18 - INFO - Epoch 2 step 8280 eta 09:02:34: loss_a 0.953, un_loss_a 0.667, loss_b 0.865, un_loss_b 0.507, accuracy_a 0.812, accuracy_b 0.812
2022-05-29 22:37:41 - INFO - Epoch 2 step 8300 eta 09:02:14: loss_a 1.220, un_loss_a 0.210, loss_b 1.071, un_loss_b 0.422, accuracy_a 0.719, accuracy_b 0.688
2022-05-29 22:38:02 - INFO - Epoch 2 step 8320 eta 09:01:34: loss_a 1.091, un_loss_a 0.466, loss_b 1.004, un_loss_b 0.862, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 22:38:24 - INFO - Epoch 2 step 8340 eta 09:00:54: loss_a 1.297, un_loss_a 0.533, loss_b 1.074, un_loss_b 0.423, accuracy_a 0.625, accuracy_b 0.688
2022-05-29 22:38:47 - INFO - Epoch 2 step 8360 eta 09:00:33: loss_a 0.794, un_loss_a 0.338, loss_b 0.750, un_loss_b 0.383, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 22:39:08 - INFO - Epoch 2 step 8380 eta 08:59:53: loss_a 1.154, un_loss_a 0.803, loss_b 1.105, un_loss_b 0.883, accuracy_a 0.625, accuracy_b 0.625
2022-05-29 22:39:31 - INFO - Epoch 2 step 8400 eta 08:59:34: loss_a 0.914, un_loss_a 0.467, loss_b 0.923, un_loss_b 0.463, accuracy_a 0.719, accuracy_b 0.750
2022-05-29 22:39:53 - INFO - Epoch 2 step 8420 eta 08:58:54: loss_a 0.752, un_loss_a 0.503, loss_b 0.873, un_loss_b 0.482, accuracy_a 0.719, accuracy_b 0.688
Begin Validation
2022-05-29 22:42:14 - INFO - Epoch 2 step 8436:, {'lv1_acc': 0.7684, 'lv2_acc': 0.6562, 'lv1_f1_micro': 0.7684, 'lv1_f1_macro': 0.7345, 'lv2_f1_micro': 0.6562, 'lv2_f1_macro': 0.4937, 'mean_f1': 0.6632}, {'lv1_acc': 0.7712, 'lv2_acc': 0.6622, 'lv1_f1_micro': 0.7712, 'lv1_f1_macro': 0.7373, 'lv2_f1_micro': 0.6622, 'lv2_f1_macro': 0.5047, 'mean_f1': 0.6688}
/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-05-29 22:42:22 - INFO - Epoch 3 step 8440 eta 09:24:35: loss_a 0.458, un_loss_a 0.318, loss_b 0.627, un_loss_b 0.429, accuracy_a 0.875, accuracy_b 0.719
2022-05-29 22:42:44 - INFO - Epoch 3 step 8460 eta 09:23:51: loss_a 0.313, un_loss_a 0.613, loss_b 0.394, un_loss_b 0.637, accuracy_a 0.906, accuracy_b 0.906
2022-05-29 22:43:05 - INFO - Epoch 3 step 8480 eta 09:23:08: loss_a 1.415, un_loss_a 0.520, loss_b 1.210, un_loss_b 0.447, accuracy_a 0.594, accuracy_b 0.594
2022-05-29 22:43:29 - INFO - Epoch 3 step 8500 eta 09:22:50: loss_a 0.608, un_loss_a 0.502, loss_b 0.668, un_loss_b 0.329, accuracy_a 0.812, accuracy_b 0.781
2022-05-29 22:43:50 - INFO - Epoch 3 step 8520 eta 09:22:07: loss_a 0.668, un_loss_a 0.420, loss_b 0.641, un_loss_b 0.420, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 22:44:14 - INFO - Epoch 3 step 8540 eta 09:21:52: loss_a 0.773, un_loss_a 0.239, loss_b 0.784, un_loss_b 0.312, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 22:44:36 - INFO - Epoch 3 step 8560 eta 09:21:09: loss_a 0.912, un_loss_a 0.551, loss_b 0.982, un_loss_b 0.653, accuracy_a 0.719, accuracy_b 0.656
2022-05-29 22:44:57 - INFO - Epoch 3 step 8580 eta 09:20:26: loss_a 0.293, un_loss_a 0.491, loss_b 0.386, un_loss_b 0.655, accuracy_a 0.938, accuracy_b 0.938
2022-05-29 22:45:21 - INFO - Epoch 3 step 8600 eta 09:20:09: loss_a 1.058, un_loss_a 0.456, loss_b 1.185, un_loss_b 0.630, accuracy_a 0.656, accuracy_b 0.625
2022-05-29 22:45:42 - INFO - Epoch 3 step 8620 eta 09:19:27: loss_a 0.776, un_loss_a 0.302, loss_b 0.666, un_loss_b 0.423, accuracy_a 0.750, accuracy_b 0.812
2022-05-29 22:46:06 - INFO - Epoch 3 step 8640 eta 09:19:10: loss_a 0.639, un_loss_a 0.446, loss_b 0.708, un_loss_b 0.429, accuracy_a 0.781, accuracy_b 0.875
2022-05-29 22:46:27 - INFO - Epoch 3 step 8660 eta 09:18:27: loss_a 0.327, un_loss_a 0.408, loss_b 0.455, un_loss_b 0.449, accuracy_a 0.844, accuracy_b 0.812
2022-05-29 22:46:49 - INFO - Epoch 3 step 8680 eta 09:17:45: loss_a 0.663, un_loss_a 0.394, loss_b 0.572, un_loss_b 0.311, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 22:47:12 - INFO - Epoch 3 step 8700 eta 09:17:25: loss_a 0.408, un_loss_a 0.474, loss_b 0.429, un_loss_b 0.344, accuracy_a 0.844, accuracy_b 0.844
2022-05-29 22:47:34 - INFO - Epoch 3 step 8720 eta 09:16:42: loss_a 1.063, un_loss_a 0.577, loss_b 1.108, un_loss_b 0.530, accuracy_a 0.781, accuracy_b 0.719
2022-05-29 22:47:55 - INFO - Epoch 3 step 8740 eta 09:16:00: loss_a 0.621, un_loss_a 0.385, loss_b 0.605, un_loss_b 0.288, accuracy_a 0.844, accuracy_b 0.812
2022-05-29 22:48:18 - INFO - Epoch 3 step 8760 eta 09:15:40: loss_a 0.631, un_loss_a 0.222, loss_b 0.539, un_loss_b 0.335, accuracy_a 0.812, accuracy_b 0.844
2022-05-29 22:48:40 - INFO - Epoch 3 step 8780 eta 09:14:58: loss_a 0.889, un_loss_a 0.559, loss_b 0.868, un_loss_b 0.462, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 22:49:03 - INFO - Epoch 3 step 8800 eta 09:14:38: loss_a 0.536, un_loss_a 0.422, loss_b 0.693, un_loss_b 0.583, accuracy_a 0.750, accuracy_b 0.750
2022-05-29 22:49:25 - INFO - Epoch 3 step 8820 eta 09:13:55: loss_a 0.554, un_loss_a 0.424, loss_b 0.874, un_loss_b 0.527, accuracy_a 0.812, accuracy_b 0.750
2022-05-29 22:49:46 - INFO - Epoch 3 step 8840 eta 09:13:13: loss_a 0.337, un_loss_a 0.509, loss_b 0.305, un_loss_b 0.504, accuracy_a 0.844, accuracy_b 0.906
2022-05-29 22:50:10 - INFO - Epoch 3 step 8860 eta 09:12:54: loss_a 0.942, un_loss_a 0.288, loss_b 1.027, un_loss_b 0.555, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 22:50:31 - INFO - Epoch 3 step 8880 eta 09:12:12: loss_a 0.413, un_loss_a 0.452, loss_b 0.635, un_loss_b 0.366, accuracy_a 0.875, accuracy_b 0.750
2022-05-29 22:50:54 - INFO - Epoch 3 step 8900 eta 09:11:53: loss_a 0.623, un_loss_a 0.388, loss_b 0.592, un_loss_b 0.412, accuracy_a 0.781, accuracy_b 0.781
2022-05-29 22:51:16 - INFO - Epoch 3 step 8920 eta 09:11:11: loss_a 0.923, un_loss_a 0.506, loss_b 1.095, un_loss_b 0.377, accuracy_a 0.750, accuracy_b 0.625
2022-05-29 22:51:37 - INFO - Epoch 3 step 8940 eta 09:10:29: loss_a 0.883, un_loss_a 0.429, loss_b 0.857, un_loss_b 0.413, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 22:52:01 - INFO - Epoch 3 step 8960 eta 09:10:09: loss_a 0.567, un_loss_a 0.720, loss_b 0.725, un_loss_b 0.714, accuracy_a 0.844, accuracy_b 0.719
2022-05-29 22:52:22 - INFO - Epoch 3 step 8980 eta 09:09:28: loss_a 0.506, un_loss_a 0.272, loss_b 0.439, un_loss_b 0.308, accuracy_a 0.781, accuracy_b 0.844
2022-05-29 22:52:46 - INFO - Epoch 3 step 9000 eta 09:09:08: loss_a 0.555, un_loss_a 0.457, loss_b 0.800, un_loss_b 0.366, accuracy_a 0.781, accuracy_b 0.781
2022-05-29 22:53:07 - INFO - Epoch 3 step 9020 eta 09:08:26: loss_a 0.977, un_loss_a 0.655, loss_b 0.881, un_loss_b 0.575, accuracy_a 0.719, accuracy_b 0.750
2022-05-29 22:53:28 - INFO - Epoch 3 step 9040 eta 09:07:45: loss_a 0.785, un_loss_a 0.955, loss_b 0.953, un_loss_b 0.962, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 22:53:52 - INFO - Epoch 3 step 9060 eta 09:07:24: loss_a 0.767, un_loss_a 0.536, loss_b 0.752, un_loss_b 0.631, accuracy_a 0.750, accuracy_b 0.688
2022-05-29 22:54:13 - INFO - Epoch 3 step 9080 eta 09:06:43: loss_a 0.659, un_loss_a 0.411, loss_b 0.892, un_loss_b 0.315, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 22:54:37 - INFO - Epoch 3 step 9100 eta 09:06:24: loss_a 0.558, un_loss_a 0.684, loss_b 0.557, un_loss_b 0.665, accuracy_a 0.812, accuracy_b 0.812
2022-05-29 22:54:58 - INFO - Epoch 3 step 9120 eta 09:05:43: loss_a 0.369, un_loss_a 0.434, loss_b 0.282, un_loss_b 0.463, accuracy_a 0.875, accuracy_b 0.906
2022-05-29 22:55:21 - INFO - Epoch 3 step 9140 eta 09:05:23: loss_a 1.020, un_loss_a 0.619, loss_b 1.042, un_loss_b 0.698, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 22:55:43 - INFO - Epoch 3 step 9160 eta 09:04:42: loss_a 0.907, un_loss_a 0.293, loss_b 1.017, un_loss_b 0.377, accuracy_a 0.812, accuracy_b 0.688
2022-05-29 22:56:04 - INFO - Epoch 3 step 9180 eta 09:04:01: loss_a 0.325, un_loss_a 0.919, loss_b 0.430, un_loss_b 0.824, accuracy_a 0.906, accuracy_b 0.875
2022-05-29 22:56:28 - INFO - Epoch 3 step 9200 eta 09:03:46: loss_a 0.449, un_loss_a 0.774, loss_b 0.385, un_loss_b 0.818, accuracy_a 0.812, accuracy_b 0.875
2022-05-29 22:56:50 - INFO - Epoch 3 step 9220 eta 09:03:05: loss_a 0.674, un_loss_a 0.390, loss_b 0.838, un_loss_b 0.473, accuracy_a 0.844, accuracy_b 0.781
2022-05-29 22:57:13 - INFO - Epoch 3 step 9240 eta 09:02:47: loss_a 0.719, un_loss_a 0.456, loss_b 0.734, un_loss_b 0.488, accuracy_a 0.719, accuracy_b 0.719
2022-05-29 22:57:34 - INFO - Epoch 3 step 9260 eta 09:02:07: loss_a 0.410, un_loss_a 0.682, loss_b 0.446, un_loss_b 0.511, accuracy_a 0.781, accuracy_b 0.844
2022-05-29 22:57:56 - INFO - Epoch 3 step 9280 eta 09:01:26: loss_a 0.814, un_loss_a 0.305, loss_b 0.765, un_loss_b 0.406, accuracy_a 0.750, accuracy_b 0.781
2022-05-29 22:58:19 - INFO - Epoch 3 step 9300 eta 09:01:06: loss_a 1.150, un_loss_a 0.703, loss_b 1.206, un_loss_b 0.610, accuracy_a 0.625, accuracy_b 0.625
2022-05-29 22:58:41 - INFO - Epoch 3 step 9320 eta 09:00:26: loss_a 0.642, un_loss_a 0.396, loss_b 0.691, un_loss_b 0.477, accuracy_a 0.812, accuracy_b 0.781
2022-05-29 22:59:02 - INFO - Epoch 3 step 9340 eta 08:59:45: loss_a 0.624, un_loss_a 0.703, loss_b 0.670, un_loss_b 0.343, accuracy_a 0.781, accuracy_b 0.781
2022-05-29 22:59:26 - INFO - Epoch 3 step 9360 eta 08:59:25: loss_a 0.480, un_loss_a 0.518, loss_b 0.545, un_loss_b 0.506, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 22:59:47 - INFO - Epoch 3 step 9380 eta 08:58:45: loss_a 0.598, un_loss_a 0.495, loss_b 0.577, un_loss_b 0.616, accuracy_a 0.844, accuracy_b 0.875
2022-05-29 23:00:08 - INFO - Epoch 3 step 9400 eta 08:58:05: loss_a 0.938, un_loss_a 0.530, loss_b 0.949, un_loss_b 0.820, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 23:00:32 - INFO - Epoch 3 step 9420 eta 08:57:45: loss_a 0.611, un_loss_a 0.573, loss_b 0.620, un_loss_b 0.562, accuracy_a 0.812, accuracy_b 0.781
2022-05-29 23:00:53 - INFO - Epoch 3 step 9440 eta 08:57:05: loss_a 0.494, un_loss_a 0.416, loss_b 0.676, un_loss_b 0.380, accuracy_a 0.812, accuracy_b 0.781
2022-05-29 23:01:17 - INFO - Epoch 3 step 9460 eta 08:56:45: loss_a 1.218, un_loss_a 0.488, loss_b 1.004, un_loss_b 0.390, accuracy_a 0.688, accuracy_b 0.688
2022-05-29 23:01:38 - INFO - Epoch 3 step 9480 eta 08:56:05: loss_a 0.807, un_loss_a 0.722, loss_b 0.972, un_loss_b 0.602, accuracy_a 0.844, accuracy_b 0.812
2022-05-29 23:01:59 - INFO - Epoch 3 step 9500 eta 08:55:25: loss_a 0.735, un_loss_a 0.321, loss_b 0.728, un_loss_b 0.326, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 23:02:23 - INFO - Epoch 3 step 9520 eta 08:55:05: loss_a 0.943, un_loss_a 0.472, loss_b 0.998, un_loss_b 0.464, accuracy_a 0.719, accuracy_b 0.750
2022-05-29 23:02:44 - INFO - Epoch 3 step 9540 eta 08:54:25: loss_a 0.347, un_loss_a 0.468, loss_b 0.514, un_loss_b 0.368, accuracy_a 0.875, accuracy_b 0.812
2022-05-29 23:03:08 - INFO - Epoch 3 step 9560 eta 08:54:05: loss_a 0.657, un_loss_a 0.428, loss_b 0.622, un_loss_b 0.307, accuracy_a 0.750, accuracy_b 0.812
2022-05-29 23:03:29 - INFO - Epoch 3 step 9580 eta 08:53:26: loss_a 0.803, un_loss_a 0.395, loss_b 0.805, un_loss_b 0.536, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 23:03:50 - INFO - Epoch 3 step 9600 eta 08:52:46: loss_a 0.318, un_loss_a 0.571, loss_b 0.475, un_loss_b 0.562, accuracy_a 0.906, accuracy_b 0.875
2022-05-29 23:04:14 - INFO - Epoch 3 step 9620 eta 08:52:26: loss_a 0.747, un_loss_a 0.480, loss_b 0.743, un_loss_b 0.426, accuracy_a 0.719, accuracy_b 0.812
2022-05-29 23:04:35 - INFO - Epoch 3 step 9640 eta 08:51:47: loss_a 0.162, un_loss_a 0.426, loss_b 0.180, un_loss_b 0.604, accuracy_a 0.969, accuracy_b 0.938
2022-05-29 23:04:59 - INFO - Epoch 3 step 9660 eta 08:51:28: loss_a 0.793, un_loss_a 0.724, loss_b 1.198, un_loss_b 0.716, accuracy_a 0.688, accuracy_b 0.594
2022-05-29 23:05:20 - INFO - Epoch 3 step 9680 eta 08:50:49: loss_a 0.810, un_loss_a 0.497, loss_b 0.821, un_loss_b 0.669, accuracy_a 0.750, accuracy_b 0.781
2022-05-29 23:05:42 - INFO - Epoch 3 step 9700 eta 08:50:09: loss_a 0.884, un_loss_a 0.523, loss_b 0.990, un_loss_b 0.458, accuracy_a 0.750, accuracy_b 0.750
2022-05-29 23:06:05 - INFO - Epoch 3 step 9720 eta 08:49:50: loss_a 0.577, un_loss_a 0.445, loss_b 0.715, un_loss_b 0.366, accuracy_a 0.812, accuracy_b 0.812
2022-05-29 23:06:26 - INFO - Epoch 3 step 9740 eta 08:49:11: loss_a 0.676, un_loss_a 0.186, loss_b 0.692, un_loss_b 0.292, accuracy_a 0.844, accuracy_b 0.812
2022-05-29 23:06:50 - INFO - Epoch 3 step 9760 eta 08:48:52: loss_a 0.483, un_loss_a 0.461, loss_b 0.377, un_loss_b 0.519, accuracy_a 0.812, accuracy_b 0.875
2022-05-29 23:07:11 - INFO - Epoch 3 step 9780 eta 08:48:13: loss_a 0.742, un_loss_a 0.474, loss_b 1.265, un_loss_b 0.588, accuracy_a 0.656, accuracy_b 0.594
2022-05-29 23:07:35 - INFO - Epoch 3 step 9800 eta 08:47:54: loss_a 0.271, un_loss_a 0.338, loss_b 0.296, un_loss_b 0.366, accuracy_a 0.906, accuracy_b 0.906
2022-05-29 23:07:56 - INFO - Epoch 3 step 9820 eta 08:47:16: loss_a 0.897, un_loss_a 0.327, loss_b 0.999, un_loss_b 0.437, accuracy_a 0.781, accuracy_b 0.688
2022-05-29 23:08:20 - INFO - Epoch 3 step 9840 eta 08:46:56: loss_a 0.698, un_loss_a 0.274, loss_b 0.599, un_loss_b 0.335, accuracy_a 0.781, accuracy_b 0.844
2022-05-29 23:08:41 - INFO - Epoch 3 step 9860 eta 08:46:18: loss_a 0.756, un_loss_a 0.211, loss_b 0.882, un_loss_b 0.286, accuracy_a 0.781, accuracy_b 0.719
2022-05-29 23:09:03 - INFO - Epoch 3 step 9880 eta 08:45:39: loss_a 0.745, un_loss_a 0.397, loss_b 1.215, un_loss_b 0.366, accuracy_a 0.781, accuracy_b 0.719
2022-05-29 23:09:26 - INFO - Epoch 3 step 9900 eta 08:45:20: loss_a 0.580, un_loss_a 0.419, loss_b 0.785, un_loss_b 0.263, accuracy_a 0.812, accuracy_b 0.844
2022-05-29 23:09:47 - INFO - Epoch 3 step 9920 eta 08:44:41: loss_a 0.859, un_loss_a 0.571, loss_b 0.913, un_loss_b 0.632, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 23:10:09 - INFO - Epoch 3 step 9940 eta 08:44:03: loss_a 0.951, un_loss_a 0.423, loss_b 1.096, un_loss_b 0.330, accuracy_a 0.781, accuracy_b 0.781
2022-05-29 23:10:32 - INFO - Epoch 3 step 9960 eta 08:43:44: loss_a 1.020, un_loss_a 0.590, loss_b 1.003, un_loss_b 0.715, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 23:10:54 - INFO - Epoch 3 step 9980 eta 08:43:06: loss_a 0.356, un_loss_a 0.361, loss_b 0.568, un_loss_b 0.447, accuracy_a 0.906, accuracy_b 0.844
2022-05-29 23:11:15 - INFO - Epoch 3 step 10000 eta 08:42:27: loss_a 0.718, un_loss_a 0.400, loss_b 0.684, un_loss_b 0.418, accuracy_a 0.688, accuracy_b 0.812
2022-05-29 23:11:39 - INFO - Epoch 3 step 10020 eta 08:42:08: loss_a 0.470, un_loss_a 0.301, loss_b 0.703, un_loss_b 0.285, accuracy_a 0.875, accuracy_b 0.844
2022-05-29 23:12:00 - INFO - Epoch 3 step 10040 eta 08:41:29: loss_a 0.194, un_loss_a 0.285, loss_b 0.288, un_loss_b 0.536, accuracy_a 0.969, accuracy_b 0.938
2022-05-29 23:12:23 - INFO - Epoch 3 step 10060 eta 08:41:10: loss_a 1.038, un_loss_a 0.531, loss_b 0.991, un_loss_b 0.378, accuracy_a 0.812, accuracy_b 0.844
2022-05-29 23:12:45 - INFO - Epoch 3 step 10080 eta 08:40:32: loss_a 0.441, un_loss_a 0.518, loss_b 0.402, un_loss_b 0.604, accuracy_a 0.844, accuracy_b 0.844
2022-05-29 23:13:06 - INFO - Epoch 3 step 10100 eta 08:39:54: loss_a 0.548, un_loss_a 0.701, loss_b 0.510, un_loss_b 0.469, accuracy_a 0.812, accuracy_b 0.875
2022-05-29 23:13:30 - INFO - Epoch 3 step 10120 eta 08:39:35: loss_a 0.794, un_loss_a 0.710, loss_b 0.844, un_loss_b 0.595, accuracy_a 0.812, accuracy_b 0.688
2022-05-29 23:13:51 - INFO - Epoch 3 step 10140 eta 08:38:57: loss_a 0.786, un_loss_a 0.498, loss_b 0.634, un_loss_b 0.401, accuracy_a 0.750, accuracy_b 0.812
2022-05-29 23:14:13 - INFO - Epoch 3 step 10160 eta 08:38:19: loss_a 0.474, un_loss_a 0.245, loss_b 0.590, un_loss_b 0.172, accuracy_a 0.812, accuracy_b 0.812
2022-05-29 23:14:36 - INFO - Epoch 3 step 10180 eta 08:38:00: loss_a 0.476, un_loss_a 0.442, loss_b 0.828, un_loss_b 0.446, accuracy_a 0.906, accuracy_b 0.844
2022-05-29 23:14:58 - INFO - Epoch 3 step 10200 eta 08:37:22: loss_a 0.767, un_loss_a 0.839, loss_b 0.773, un_loss_b 0.669, accuracy_a 0.812, accuracy_b 0.750
2022-05-29 23:15:21 - INFO - Epoch 3 step 10220 eta 08:37:03: loss_a 0.703, un_loss_a 0.651, loss_b 0.539, un_loss_b 0.903, accuracy_a 0.781, accuracy_b 0.844
2022-05-29 23:15:42 - INFO - Epoch 3 step 10240 eta 08:36:25: loss_a 0.702, un_loss_a 0.405, loss_b 0.745, un_loss_b 0.426, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 23:16:04 - INFO - Epoch 3 step 10260 eta 08:35:47: loss_a 0.749, un_loss_a 0.436, loss_b 0.654, un_loss_b 0.605, accuracy_a 0.688, accuracy_b 0.750
2022-05-29 23:16:27 - INFO - Epoch 3 step 10280 eta 08:35:28: loss_a 0.311, un_loss_a 0.541, loss_b 0.518, un_loss_b 0.426, accuracy_a 0.906, accuracy_b 0.906
2022-05-29 23:16:49 - INFO - Epoch 3 step 10300 eta 08:34:51: loss_a 1.119, un_loss_a 0.899, loss_b 1.010, un_loss_b 0.796, accuracy_a 0.594, accuracy_b 0.656
2022-05-29 23:17:12 - INFO - Epoch 3 step 10320 eta 08:34:32: loss_a 0.430, un_loss_a 0.663, loss_b 0.357, un_loss_b 0.611, accuracy_a 0.875, accuracy_b 0.781
2022-05-29 23:17:33 - INFO - Epoch 3 step 10340 eta 08:33:54: loss_a 0.953, un_loss_a 0.245, loss_b 0.805, un_loss_b 0.375, accuracy_a 0.688, accuracy_b 0.812
2022-05-29 23:17:57 - INFO - Epoch 3 step 10360 eta 08:33:35: loss_a 0.767, un_loss_a 0.556, loss_b 1.004, un_loss_b 0.528, accuracy_a 0.781, accuracy_b 0.719
2022-05-29 23:18:18 - INFO - Epoch 3 step 10380 eta 08:32:58: loss_a 0.668, un_loss_a 0.222, loss_b 0.739, un_loss_b 0.326, accuracy_a 0.844, accuracy_b 0.719
2022-05-29 23:18:40 - INFO - Epoch 3 step 10400 eta 08:32:21: loss_a 0.670, un_loss_a 0.626, loss_b 0.786, un_loss_b 0.559, accuracy_a 0.812, accuracy_b 0.719
2022-05-29 23:19:03 - INFO - Epoch 3 step 10420 eta 08:32:00: loss_a 0.560, un_loss_a 0.352, loss_b 0.885, un_loss_b 0.300, accuracy_a 0.844, accuracy_b 0.812
2022-05-29 23:19:25 - INFO - Epoch 3 step 10440 eta 08:31:23: loss_a 0.401, un_loss_a 0.283, loss_b 0.437, un_loss_b 0.292, accuracy_a 0.875, accuracy_b 0.781
2022-05-29 23:19:48 - INFO - Epoch 3 step 10460 eta 08:31:05: loss_a 0.714, un_loss_a 0.293, loss_b 0.656, un_loss_b 0.346, accuracy_a 0.781, accuracy_b 0.781
2022-05-29 23:20:10 - INFO - Epoch 3 step 10480 eta 08:30:28: loss_a 0.604, un_loss_a 0.338, loss_b 0.598, un_loss_b 0.570, accuracy_a 0.750, accuracy_b 0.781
2022-05-29 23:20:33 - INFO - Epoch 3 step 10500 eta 08:30:08: loss_a 0.589, un_loss_a 0.869, loss_b 0.557, un_loss_b 0.413, accuracy_a 0.844, accuracy_b 0.844
2022-05-29 23:20:54 - INFO - Epoch 3 step 10520 eta 08:29:31: loss_a 0.836, un_loss_a 0.726, loss_b 1.056, un_loss_b 0.957, accuracy_a 0.812, accuracy_b 0.750
2022-05-29 23:21:16 - INFO - Epoch 3 step 10540 eta 08:28:54: loss_a 0.477, un_loss_a 0.425, loss_b 0.692, un_loss_b 0.359, accuracy_a 0.812, accuracy_b 0.750
2022-05-29 23:21:39 - INFO - Epoch 3 step 10560 eta 08:28:35: loss_a 0.494, un_loss_a 0.315, loss_b 0.499, un_loss_b 0.467, accuracy_a 0.812, accuracy_b 0.844
2022-05-29 23:22:01 - INFO - Epoch 3 step 10580 eta 08:27:58: loss_a 0.670, un_loss_a 0.356, loss_b 0.829, un_loss_b 0.321, accuracy_a 0.844, accuracy_b 0.812
2022-05-29 23:22:22 - INFO - Epoch 3 step 10600 eta 08:27:21: loss_a 0.627, un_loss_a 0.703, loss_b 0.740, un_loss_b 0.720, accuracy_a 0.812, accuracy_b 0.844
2022-05-29 23:22:45 - INFO - Epoch 3 step 10620 eta 08:27:02: loss_a 0.691, un_loss_a 0.267, loss_b 0.735, un_loss_b 0.299, accuracy_a 0.812, accuracy_b 0.781
2022-05-29 23:23:07 - INFO - Epoch 3 step 10640 eta 08:26:25: loss_a 0.635, un_loss_a 0.552, loss_b 0.594, un_loss_b 0.677, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 23:23:28 - INFO - Epoch 3 step 10660 eta 08:25:48: loss_a 0.805, un_loss_a 0.580, loss_b 0.864, un_loss_b 0.406, accuracy_a 0.781, accuracy_b 0.750
2022-05-29 23:23:52 - INFO - Epoch 3 step 10680 eta 08:25:29: loss_a 0.674, un_loss_a 0.532, loss_b 0.910, un_loss_b 0.410, accuracy_a 0.812, accuracy_b 0.719
2022-05-29 23:24:13 - INFO - Epoch 3 step 10700 eta 08:24:52: loss_a 0.571, un_loss_a 0.666, loss_b 0.816, un_loss_b 0.952, accuracy_a 0.812, accuracy_b 0.719
2022-05-29 23:24:37 - INFO - Epoch 3 step 10720 eta 08:24:34: loss_a 0.963, un_loss_a 0.724, loss_b 0.952, un_loss_b 0.556, accuracy_a 0.750, accuracy_b 0.719
2022-05-29 23:24:58 - INFO - Epoch 3 step 10740 eta 08:23:57: loss_a 1.030, un_loss_a 0.630, loss_b 0.993, un_loss_b 0.566, accuracy_a 0.719, accuracy_b 0.781
2022-05-29 23:25:19 - INFO - Epoch 3 step 10760 eta 08:23:20: loss_a 0.918, un_loss_a 0.982, loss_b 1.079, un_loss_b 0.722, accuracy_a 0.688, accuracy_b 0.750
2022-05-29 23:25:43 - INFO - Epoch 3 step 10780 eta 08:23:01: loss_a 0.835, un_loss_a 0.617, loss_b 1.075, un_loss_b 0.792, accuracy_a 0.812, accuracy_b 0.750
2022-05-29 23:26:04 - INFO - Epoch 3 step 10800 eta 08:22:25: loss_a 0.819, un_loss_a 0.284, loss_b 0.884, un_loss_b 0.238, accuracy_a 0.781, accuracy_b 0.844
2022-05-29 23:26:28 - INFO - Epoch 3 step 10820 eta 08:22:06: loss_a 0.467, un_loss_a 0.803, loss_b 0.480, un_loss_b 0.680, accuracy_a 0.844, accuracy_b 0.812
2022-05-29 23:26:49 - INFO - Epoch 3 step 10840 eta 08:21:30: loss_a 1.086, un_loss_a 0.348, loss_b 1.151, un_loss_b 0.408, accuracy_a 0.656, accuracy_b 0.719
2022-05-29 23:27:11 - INFO - Epoch 3 step 10860 eta 08:20:53: loss_a 1.161, un_loss_a 0.513, loss_b 1.412, un_loss_b 0.801, accuracy_a 0.688, accuracy_b 0.625
2022-05-29 23:27:34 - INFO - Epoch 3 step 10880 eta 08:20:34: loss_a 0.468, un_loss_a 0.357, loss_b 0.779, un_loss_b 0.456, accuracy_a 0.844, accuracy_b 0.750
2022-05-29 23:27:55 - INFO - Epoch 3 step 10900 eta 08:19:58: loss_a 0.535, un_loss_a 0.433, loss_b 0.695, un_loss_b 0.474, accuracy_a 0.781, accuracy_b 0.781
2022-05-29 23:28:19 - INFO - Epoch 3 step 10920 eta 08:19:39: loss_a 0.416, un_loss_a 0.539, loss_b 0.517, un_loss_b 0.749, accuracy_a 0.938, accuracy_b 0.844
2022-05-29 23:28:40 - INFO - Epoch 3 step 10940 eta 08:19:02: loss_a 0.446, un_loss_a 0.713, loss_b 0.534, un_loss_b 0.641, accuracy_a 0.812, accuracy_b 0.812
2022-05-29 23:29:02 - INFO - Epoch 3 step 10960 eta 08:18:26: loss_a 0.738, un_loss_a 0.547, loss_b 0.809, un_loss_b 0.456, accuracy_a 0.719, accuracy_b 0.781
2022-05-29 23:29:25 - INFO - Epoch 3 step 10980 eta 08:18:06: loss_a 0.530, un_loss_a 0.589, loss_b 0.419, un_loss_b 0.571, accuracy_a 0.844, accuracy_b 0.938
2022-05-29 23:29:46 - INFO - Epoch 3 step 11000 eta 08:17:30: loss_a 0.946, un_loss_a 0.427, loss_b 1.195, un_loss_b 0.398, accuracy_a 0.719, accuracy_b 0.625
2022-05-29 23:30:10 - INFO - Epoch 3 step 11020 eta 08:17:14: loss_a 0.446, un_loss_a 0.342, loss_b 0.638, un_loss_b 0.355, accuracy_a 0.906, accuracy_b 0.875
2022-05-29 23:30:32 - INFO - Epoch 3 step 11040 eta 08:16:38: loss_a 0.695, un_loss_a 0.570, loss_b 0.609, un_loss_b 0.382, accuracy_a 0.719, accuracy_b 0.781
2022-05-29 23:30:53 - INFO - Epoch 3 step 11060 eta 08:16:02: loss_a 0.530, un_loss_a 0.503, loss_b 0.408, un_loss_b 0.489, accuracy_a 0.844, accuracy_b 0.875
2022-05-29 23:31:17 - INFO - Epoch 3 step 11080 eta 08:15:46: loss_a 0.725, un_loss_a 0.708, loss_b 0.723, un_loss_b 0.644, accuracy_a 0.781, accuracy_b 0.719
2022-05-29 23:31:38 - INFO - Epoch 3 step 11100 eta 08:15:10: loss_a 0.490, un_loss_a 0.690, loss_b 0.471, un_loss_b 0.742, accuracy_a 0.906, accuracy_b 0.844
2022-05-29 23:32:02 - INFO - Epoch 3 step 11120 eta 08:14:51: loss_a 0.630, un_loss_a 0.201, loss_b 0.588, un_loss_b 0.169, accuracy_a 0.844, accuracy_b 0.844
2022-05-29 23:32:23 - INFO - Epoch 3 step 11140 eta 08:14:15: loss_a 0.784, un_loss_a 0.349, loss_b 0.795, un_loss_b 0.386, accuracy_a 0.688, accuracy_b 0.719
2022-05-29 23:32:46 - INFO - Epoch 3 step 11160 eta 08:13:56: loss_a 0.760, un_loss_a 0.564, loss_b 0.794, un_loss_b 0.630, accuracy_a 0.812, accuracy_b 0.812
2022-05-29 23:33:08 - INFO - Epoch 3 step 11180 eta 08:13:20: loss_a 0.807, un_loss_a 0.597, loss_b 0.823, un_loss_b 0.762, accuracy_a 0.812, accuracy_b 0.781
2022-05-29 23:33:29 - INFO - Epoch 3 step 11200 eta 08:12:44: loss_a 0.583, un_loss_a 0.935, loss_b 0.874, un_loss_b 0.659, accuracy_a 0.781, accuracy_b 0.844
2022-05-29 23:33:53 - INFO - Epoch 3 step 11220 eta 08:12:26: loss_a 0.830, un_loss_a 0.420, loss_b 0.898, un_loss_b 0.327, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 23:34:14 - INFO - Epoch 3 step 11240 eta 08:11:50: loss_a 0.269, un_loss_a 0.576, loss_b 0.393, un_loss_b 0.459, accuracy_a 0.875, accuracy_b 0.938
Begin Validation
2022-05-29 23:36:26 - INFO - Epoch 3 step 11248:, {'lv1_acc': 0.7707, 'lv2_acc': 0.6627, 'lv1_f1_micro': 0.7707, 'lv1_f1_macro': 0.7416, 'lv2_f1_micro': 0.6627, 'lv2_f1_macro': 0.5327, 'mean_f1': 0.6769}, {'lv1_acc': 0.7693, 'lv2_acc': 0.663, 'lv1_f1_micro': 0.7693, 'lv1_f1_macro': 0.7372, 'lv2_f1_micro': 0.663, 'lv2_f1_macro': 0.5238, 'mean_f1': 0.6733}
/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-05-29 23:36:42 - INFO - Epoch 4 step 11260 eta 08:30:14: loss_a 0.507, un_loss_a 0.892, loss_b 0.644, un_loss_b 0.779, accuracy_a 0.812, accuracy_b 0.750
2022-05-29 23:37:06 - INFO - Epoch 4 step 11280 eta 08:29:56: loss_a 0.624, un_loss_a 0.657, loss_b 0.625, un_loss_b 0.453, accuracy_a 0.812, accuracy_b 0.844
2022-05-29 23:37:28 - INFO - Epoch 4 step 11300 eta 08:29:18: loss_a 0.449, un_loss_a 0.507, loss_b 0.602, un_loss_b 0.386, accuracy_a 0.906, accuracy_b 0.844
2022-05-29 23:37:51 - INFO - Epoch 4 step 11320 eta 08:29:00: loss_a 0.298, un_loss_a 0.590, loss_b 0.460, un_loss_b 0.532, accuracy_a 0.875, accuracy_b 0.844
2022-05-29 23:38:13 - INFO - Epoch 4 step 11340 eta 08:28:23: loss_a 0.368, un_loss_a 0.492, loss_b 0.376, un_loss_b 0.507, accuracy_a 0.875, accuracy_b 0.906
2022-05-29 23:38:36 - INFO - Epoch 4 step 11360 eta 08:28:04: loss_a 0.351, un_loss_a 0.616, loss_b 0.531, un_loss_b 0.762, accuracy_a 0.875, accuracy_b 0.875
2022-05-29 23:38:58 - INFO - Epoch 4 step 11380 eta 08:27:26: loss_a 0.423, un_loss_a 0.413, loss_b 0.551, un_loss_b 0.422, accuracy_a 0.906, accuracy_b 0.844
2022-05-29 23:39:21 - INFO - Epoch 4 step 11400 eta 08:27:07: loss_a 0.362, un_loss_a 0.480, loss_b 0.543, un_loss_b 0.522, accuracy_a 0.875, accuracy_b 0.750
2022-05-29 23:39:43 - INFO - Epoch 4 step 11420 eta 08:26:29: loss_a 0.371, un_loss_a 0.536, loss_b 0.389, un_loss_b 0.523, accuracy_a 0.906, accuracy_b 0.875
2022-05-29 23:40:04 - INFO - Epoch 4 step 11440 eta 08:25:51: loss_a 0.231, un_loss_a 0.322, loss_b 0.208, un_loss_b 0.331, accuracy_a 0.906, accuracy_b 0.938
2022-05-29 23:40:27 - INFO - Epoch 4 step 11460 eta 08:25:28: loss_a 0.361, un_loss_a 0.248, loss_b 0.400, un_loss_b 0.212, accuracy_a 0.906, accuracy_b 0.844
2022-05-29 23:40:49 - INFO - Epoch 4 step 11480 eta 08:24:50: loss_a 0.172, un_loss_a 0.612, loss_b 0.325, un_loss_b 0.633, accuracy_a 0.938, accuracy_b 0.875
2022-05-29 23:41:12 - INFO - Epoch 4 step 11500 eta 08:24:28: loss_a 0.227, un_loss_a 0.381, loss_b 0.253, un_loss_b 0.474, accuracy_a 0.938, accuracy_b 0.906
2022-05-29 23:41:33 - INFO - Epoch 4 step 11520 eta 08:23:50: loss_a 0.315, un_loss_a 0.448, loss_b 0.360, un_loss_b 0.366, accuracy_a 0.844, accuracy_b 0.875
2022-05-29 23:41:55 - INFO - Epoch 4 step 11540 eta 08:23:13: loss_a 0.420, un_loss_a 0.603, loss_b 0.553, un_loss_b 0.784, accuracy_a 0.875, accuracy_b 0.812
2022-05-29 23:42:18 - INFO - Epoch 4 step 11560 eta 08:22:49: loss_a 0.517, un_loss_a 0.431, loss_b 0.856, un_loss_b 0.623, accuracy_a 0.844, accuracy_b 0.812
2022-05-29 23:42:39 - INFO - Epoch 4 step 11580 eta 08:22:12: loss_a 0.903, un_loss_a 0.256, loss_b 1.126, un_loss_b 0.292, accuracy_a 0.750, accuracy_b 0.750
2022-05-29 23:43:01 - INFO - Epoch 4 step 11600 eta 08:21:34: loss_a 0.240, un_loss_a 0.321, loss_b 0.421, un_loss_b 0.282, accuracy_a 0.906, accuracy_b 0.875
2022-05-29 23:43:24 - INFO - Epoch 4 step 11620 eta 08:21:11: loss_a 0.433, un_loss_a 0.578, loss_b 0.525, un_loss_b 0.626, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 23:43:45 - INFO - Epoch 4 step 11640 eta 08:20:33: loss_a 0.617, un_loss_a 0.662, loss_b 0.685, un_loss_b 0.677, accuracy_a 0.812, accuracy_b 0.844
2022-05-29 23:44:07 - INFO - Epoch 4 step 11660 eta 08:19:56: loss_a 0.438, un_loss_a 0.350, loss_b 0.345, un_loss_b 0.363, accuracy_a 0.875, accuracy_b 0.875
2022-05-29 23:44:30 - INFO - Epoch 4 step 11680 eta 08:19:34: loss_a 0.482, un_loss_a 0.311, loss_b 0.648, un_loss_b 0.245, accuracy_a 0.875, accuracy_b 0.844
2022-05-29 23:44:51 - INFO - Epoch 4 step 11700 eta 08:18:57: loss_a 0.368, un_loss_a 0.377, loss_b 0.339, un_loss_b 0.427, accuracy_a 0.906, accuracy_b 0.875
2022-05-29 23:45:15 - INFO - Epoch 4 step 11720 eta 08:18:41: loss_a 0.309, un_loss_a 0.764, loss_b 0.319, un_loss_b 0.633, accuracy_a 0.906, accuracy_b 0.875
2022-05-29 23:45:37 - INFO - Epoch 4 step 11740 eta 08:18:04: loss_a 0.270, un_loss_a 0.947, loss_b 0.182, un_loss_b 1.071, accuracy_a 0.906, accuracy_b 0.906
2022-05-29 23:45:58 - INFO - Epoch 4 step 11760 eta 08:17:27: loss_a 0.440, un_loss_a 0.508, loss_b 0.743, un_loss_b 0.444, accuracy_a 0.844, accuracy_b 0.781
2022-05-29 23:46:22 - INFO - Epoch 4 step 11780 eta 08:17:08: loss_a 0.381, un_loss_a 0.361, loss_b 0.428, un_loss_b 0.441, accuracy_a 0.875, accuracy_b 0.875
2022-05-29 23:46:43 - INFO - Epoch 4 step 11800 eta 08:16:31: loss_a 0.433, un_loss_a 0.291, loss_b 0.498, un_loss_b 0.407, accuracy_a 0.875, accuracy_b 0.875
2022-05-29 23:47:06 - INFO - Epoch 4 step 11820 eta 08:16:08: loss_a 0.382, un_loss_a 0.582, loss_b 0.553, un_loss_b 0.517, accuracy_a 0.875, accuracy_b 0.781
2022-05-29 23:47:28 - INFO - Epoch 4 step 11840 eta 08:15:31: loss_a 0.415, un_loss_a 0.788, loss_b 0.802, un_loss_b 0.574, accuracy_a 0.875, accuracy_b 0.750
2022-05-29 23:47:49 - INFO - Epoch 4 step 11860 eta 08:14:54: loss_a 0.440, un_loss_a 0.680, loss_b 0.519, un_loss_b 0.480, accuracy_a 0.875, accuracy_b 0.844
2022-05-29 23:48:13 - INFO - Epoch 4 step 11880 eta 08:14:32: loss_a 0.747, un_loss_a 0.632, loss_b 0.813, un_loss_b 0.637, accuracy_a 0.750, accuracy_b 0.781
2022-05-29 23:48:34 - INFO - Epoch 4 step 11900 eta 08:13:55: loss_a 0.521, un_loss_a 0.770, loss_b 0.668, un_loss_b 0.702, accuracy_a 0.938, accuracy_b 0.875
2022-05-29 23:48:57 - INFO - Epoch 4 step 11920 eta 08:13:33: loss_a 0.550, un_loss_a 0.588, loss_b 0.663, un_loss_b 0.477, accuracy_a 0.781, accuracy_b 0.781
2022-05-29 23:49:19 - INFO - Epoch 4 step 11940 eta 08:12:56: loss_a 0.532, un_loss_a 0.438, loss_b 0.646, un_loss_b 0.428, accuracy_a 0.844, accuracy_b 0.844
2022-05-29 23:49:40 - INFO - Epoch 4 step 11960 eta 08:12:20: loss_a 0.294, un_loss_a 0.535, loss_b 0.383, un_loss_b 0.649, accuracy_a 0.906, accuracy_b 0.906
2022-05-29 23:50:03 - INFO - Epoch 4 step 11980 eta 08:11:57: loss_a 0.602, un_loss_a 0.396, loss_b 0.544, un_loss_b 0.425, accuracy_a 0.875, accuracy_b 0.844
2022-05-29 23:50:25 - INFO - Epoch 4 step 12000 eta 08:11:20: loss_a 0.446, un_loss_a 0.962, loss_b 0.396, un_loss_b 0.835, accuracy_a 0.812, accuracy_b 0.844
2022-05-29 23:50:48 - INFO - Epoch 4 step 12020 eta 08:10:58: loss_a 0.358, un_loss_a 0.645, loss_b 0.346, un_loss_b 0.461, accuracy_a 0.906, accuracy_b 0.875
2022-05-29 23:51:09 - INFO - Epoch 4 step 12040 eta 08:10:22: loss_a 0.456, un_loss_a 0.309, loss_b 0.528, un_loss_b 0.359, accuracy_a 0.875, accuracy_b 0.844
2022-05-29 23:51:32 - INFO - Epoch 4 step 12060 eta 08:09:59: loss_a 0.453, un_loss_a 0.349, loss_b 0.457, un_loss_b 0.476, accuracy_a 0.875, accuracy_b 0.906
2022-05-29 23:51:54 - INFO - Epoch 4 step 12080 eta 08:09:22: loss_a 0.256, un_loss_a 0.835, loss_b 0.495, un_loss_b 0.662, accuracy_a 0.938, accuracy_b 0.812
2022-05-29 23:52:18 - INFO - Epoch 4 step 12100 eta 08:09:06: loss_a 0.762, un_loss_a 0.500, loss_b 0.900, un_loss_b 0.682, accuracy_a 0.781, accuracy_b 0.625
2022-05-29 23:52:39 - INFO - Epoch 4 step 12120 eta 08:08:30: loss_a 0.408, un_loss_a 0.489, loss_b 0.678, un_loss_b 0.610, accuracy_a 0.875, accuracy_b 0.781
2022-05-29 23:53:01 - INFO - Epoch 4 step 12140 eta 08:07:53: loss_a 0.506, un_loss_a 0.616, loss_b 0.523, un_loss_b 0.413, accuracy_a 0.844, accuracy_b 0.875
2022-05-29 23:53:24 - INFO - Epoch 4 step 12160 eta 08:07:33: loss_a 0.548, un_loss_a 0.541, loss_b 0.636, un_loss_b 0.431, accuracy_a 0.844, accuracy_b 0.812
2022-05-29 23:53:45 - INFO - Epoch 4 step 12180 eta 08:06:57: loss_a 0.537, un_loss_a 0.726, loss_b 0.586, un_loss_b 0.997, accuracy_a 0.781, accuracy_b 0.812
2022-05-29 23:54:07 - INFO - Epoch 4 step 12200 eta 08:06:21: loss_a 0.452, un_loss_a 0.629, loss_b 0.619, un_loss_b 0.517, accuracy_a 0.844, accuracy_b 0.812
2022-05-29 23:54:30 - INFO - Epoch 4 step 12220 eta 08:05:58: loss_a 0.256, un_loss_a 0.428, loss_b 0.445, un_loss_b 0.501, accuracy_a 0.906, accuracy_b 0.844
2022-05-29 23:54:52 - INFO - Epoch 4 step 12240 eta 08:05:22: loss_a 0.323, un_loss_a 0.344, loss_b 0.362, un_loss_b 0.541, accuracy_a 0.906, accuracy_b 0.875
2022-05-29 23:55:13 - INFO - Epoch 4 step 12260 eta 08:04:46: loss_a 0.378, un_loss_a 0.790, loss_b 0.441, un_loss_b 0.568, accuracy_a 0.938, accuracy_b 0.906
2022-05-29 23:55:36 - INFO - Epoch 4 step 12280 eta 08:04:23: loss_a 0.391, un_loss_a 0.513, loss_b 0.566, un_loss_b 0.418, accuracy_a 0.906, accuracy_b 0.812
2022-05-29 23:55:57 - INFO - Epoch 4 step 12300 eta 08:03:47: loss_a 0.811, un_loss_a 0.392, loss_b 0.778, un_loss_b 0.541, accuracy_a 0.688, accuracy_b 0.750
2022-05-29 23:56:21 - INFO - Epoch 4 step 12320 eta 08:03:24: loss_a 0.318, un_loss_a 0.666, loss_b 0.326, un_loss_b 0.408, accuracy_a 0.875, accuracy_b 0.875
2022-05-29 23:56:42 - INFO - Epoch 4 step 12340 eta 08:02:48: loss_a 0.382, un_loss_a 0.490, loss_b 0.495, un_loss_b 0.437, accuracy_a 0.875, accuracy_b 0.875
2022-05-29 23:57:03 - INFO - Epoch 4 step 12360 eta 08:02:12: loss_a 0.474, un_loss_a 0.419, loss_b 0.577, un_loss_b 0.605, accuracy_a 0.875, accuracy_b 0.812
2022-05-29 23:57:26 - INFO - Epoch 4 step 12380 eta 08:01:49: loss_a 0.733, un_loss_a 0.507, loss_b 0.755, un_loss_b 0.439, accuracy_a 0.812, accuracy_b 0.812
2022-05-29 23:57:48 - INFO - Epoch 4 step 12400 eta 08:01:13: loss_a 0.495, un_loss_a 0.528, loss_b 0.605, un_loss_b 0.619, accuracy_a 0.812, accuracy_b 0.812
2022-05-29 23:58:09 - INFO - Epoch 4 step 12420 eta 08:00:37: loss_a 0.314, un_loss_a 0.750, loss_b 0.560, un_loss_b 0.737, accuracy_a 0.875, accuracy_b 0.781
2022-05-29 23:58:32 - INFO - Epoch 4 step 12440 eta 08:00:14: loss_a 0.503, un_loss_a 0.423, loss_b 0.515, un_loss_b 0.347, accuracy_a 0.812, accuracy_b 0.875
2022-05-29 23:58:54 - INFO - Epoch 4 step 12460 eta 07:59:39: loss_a 0.460, un_loss_a 0.382, loss_b 0.575, un_loss_b 0.553, accuracy_a 0.844, accuracy_b 0.812
2022-05-29 23:59:17 - INFO - Epoch 4 step 12480 eta 07:59:16: loss_a 0.434, un_loss_a 0.454, loss_b 0.552, un_loss_b 0.606, accuracy_a 0.844, accuracy_b 0.844
2022-05-29 23:59:38 - INFO - Epoch 4 step 12500 eta 07:58:40: loss_a 0.455, un_loss_a 0.496, loss_b 0.543, un_loss_b 0.476, accuracy_a 0.844, accuracy_b 0.812
2022-05-30 00:00:00 - INFO - Epoch 4 step 12520 eta 07:58:04: loss_a 0.439, un_loss_a 0.478, loss_b 0.767, un_loss_b 0.512, accuracy_a 0.812, accuracy_b 0.750
2022-05-30 00:00:23 - INFO - Epoch 4 step 12540 eta 07:57:42: loss_a 0.353, un_loss_a 0.483, loss_b 0.490, un_loss_b 0.318, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 00:00:44 - INFO - Epoch 4 step 12560 eta 07:57:06: loss_a 0.690, un_loss_a 0.429, loss_b 0.930, un_loss_b 0.427, accuracy_a 0.719, accuracy_b 0.719
2022-05-30 00:01:07 - INFO - Epoch 4 step 12580 eta 07:56:43: loss_a 0.143, un_loss_a 0.421, loss_b 0.227, un_loss_b 0.724, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 00:01:29 - INFO - Epoch 4 step 12600 eta 07:56:07: loss_a 0.758, un_loss_a 1.014, loss_b 1.156, un_loss_b 0.709, accuracy_a 0.750, accuracy_b 0.688
2022-05-30 00:01:52 - INFO - Epoch 4 step 12620 eta 07:55:45: loss_a 0.563, un_loss_a 0.365, loss_b 0.503, un_loss_b 0.501, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 00:02:13 - INFO - Epoch 4 step 12640 eta 07:55:09: loss_a 0.881, un_loss_a 0.865, loss_b 0.857, un_loss_b 1.128, accuracy_a 0.719, accuracy_b 0.719
2022-05-30 00:02:35 - INFO - Epoch 4 step 12660 eta 07:54:34: loss_a 0.252, un_loss_a 0.422, loss_b 0.303, un_loss_b 0.400, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 00:02:58 - INFO - Epoch 4 step 12680 eta 07:54:10: loss_a 0.498, un_loss_a 0.933, loss_b 0.547, un_loss_b 0.602, accuracy_a 0.844, accuracy_b 0.781
2022-05-30 00:03:19 - INFO - Epoch 4 step 12700 eta 07:53:35: loss_a 0.479, un_loss_a 0.658, loss_b 0.730, un_loss_b 0.451, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 00:03:42 - INFO - Epoch 4 step 12720 eta 07:53:12: loss_a 0.416, un_loss_a 0.894, loss_b 0.476, un_loss_b 0.560, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 00:04:04 - INFO - Epoch 4 step 12740 eta 07:52:37: loss_a 0.402, un_loss_a 0.954, loss_b 0.459, un_loss_b 1.014, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 00:04:27 - INFO - Epoch 4 step 12760 eta 07:52:15: loss_a 0.297, un_loss_a 0.593, loss_b 0.479, un_loss_b 0.623, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 00:04:48 - INFO - Epoch 4 step 12780 eta 07:51:40: loss_a 0.652, un_loss_a 0.625, loss_b 0.935, un_loss_b 0.820, accuracy_a 0.750, accuracy_b 0.719
2022-05-30 00:05:10 - INFO - Epoch 4 step 12800 eta 07:51:05: loss_a 0.337, un_loss_a 0.435, loss_b 0.420, un_loss_b 0.362, accuracy_a 0.875, accuracy_b 0.844
2022-05-30 00:05:33 - INFO - Epoch 4 step 12820 eta 07:50:43: loss_a 0.483, un_loss_a 0.348, loss_b 0.515, un_loss_b 0.423, accuracy_a 0.875, accuracy_b 0.812
2022-05-30 00:05:54 - INFO - Epoch 4 step 12840 eta 07:50:08: loss_a 0.211, un_loss_a 0.585, loss_b 0.246, un_loss_b 0.583, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 00:06:16 - INFO - Epoch 4 step 12860 eta 07:49:33: loss_a 0.614, un_loss_a 0.590, loss_b 0.662, un_loss_b 0.565, accuracy_a 0.812, accuracy_b 0.719
2022-05-30 00:06:39 - INFO - Epoch 4 step 12880 eta 07:49:10: loss_a 0.523, un_loss_a 0.422, loss_b 0.403, un_loss_b 0.456, accuracy_a 0.844, accuracy_b 0.781
2022-05-30 00:07:00 - INFO - Epoch 4 step 12900 eta 07:48:35: loss_a 0.653, un_loss_a 0.334, loss_b 0.711, un_loss_b 0.423, accuracy_a 0.750, accuracy_b 0.719
2022-05-30 00:07:22 - INFO - Epoch 4 step 12920 eta 07:48:00: loss_a 0.214, un_loss_a 0.585, loss_b 0.223, un_loss_b 0.741, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 00:07:45 - INFO - Epoch 4 step 12940 eta 07:47:37: loss_a 0.318, un_loss_a 0.678, loss_b 0.594, un_loss_b 0.590, accuracy_a 0.875, accuracy_b 0.844
2022-05-30 00:08:06 - INFO - Epoch 4 step 12960 eta 07:47:02: loss_a 0.709, un_loss_a 0.530, loss_b 0.758, un_loss_b 0.634, accuracy_a 0.812, accuracy_b 0.781
2022-05-30 00:08:29 - INFO - Epoch 4 step 12980 eta 07:46:40: loss_a 0.194, un_loss_a 0.958, loss_b 0.264, un_loss_b 0.901, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 00:08:51 - INFO - Epoch 4 step 13000 eta 07:46:05: loss_a 0.582, un_loss_a 0.220, loss_b 0.591, un_loss_b 0.257, accuracy_a 0.750, accuracy_b 0.781
2022-05-30 00:09:12 - INFO - Epoch 4 step 13020 eta 07:45:31: loss_a 0.421, un_loss_a 0.672, loss_b 0.374, un_loss_b 0.522, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 00:09:35 - INFO - Epoch 4 step 13040 eta 07:45:07: loss_a 0.639, un_loss_a 0.463, loss_b 0.584, un_loss_b 0.488, accuracy_a 0.875, accuracy_b 0.906
2022-05-30 00:09:57 - INFO - Epoch 4 step 13060 eta 07:44:33: loss_a 0.483, un_loss_a 0.443, loss_b 0.600, un_loss_b 0.341, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 00:10:20 - INFO - Epoch 4 step 13080 eta 07:44:11: loss_a 0.292, un_loss_a 0.541, loss_b 0.434, un_loss_b 0.421, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 00:10:41 - INFO - Epoch 4 step 13100 eta 07:43:36: loss_a 0.346, un_loss_a 0.364, loss_b 0.535, un_loss_b 0.287, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 00:11:03 - INFO - Epoch 4 step 13120 eta 07:43:01: loss_a 0.330, un_loss_a 0.418, loss_b 0.245, un_loss_b 0.353, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 00:11:26 - INFO - Epoch 4 step 13140 eta 07:42:39: loss_a 0.194, un_loss_a 0.332, loss_b 0.449, un_loss_b 0.460, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 00:11:47 - INFO - Epoch 4 step 13160 eta 07:42:04: loss_a 0.482, un_loss_a 0.815, loss_b 0.454, un_loss_b 0.978, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 00:12:10 - INFO - Epoch 4 step 13180 eta 07:41:42: loss_a 0.856, un_loss_a 0.564, loss_b 0.853, un_loss_b 0.476, accuracy_a 0.750, accuracy_b 0.688
2022-05-30 00:12:32 - INFO - Epoch 4 step 13200 eta 07:41:08: loss_a 0.321, un_loss_a 0.516, loss_b 0.494, un_loss_b 0.789, accuracy_a 0.844, accuracy_b 0.875
2022-05-30 00:12:53 - INFO - Epoch 4 step 13220 eta 07:40:33: loss_a 0.444, un_loss_a 0.448, loss_b 0.471, un_loss_b 0.361, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 00:13:16 - INFO - Epoch 4 step 13240 eta 07:40:12: loss_a 0.983, un_loss_a 0.281, loss_b 0.952, un_loss_b 0.234, accuracy_a 0.688, accuracy_b 0.656
2022-05-30 00:13:38 - INFO - Epoch 4 step 13260 eta 07:39:37: loss_a 0.417, un_loss_a 0.442, loss_b 0.556, un_loss_b 0.461, accuracy_a 0.781, accuracy_b 0.812
2022-05-30 00:14:01 - INFO - Epoch 4 step 13280 eta 07:39:15: loss_a 0.519, un_loss_a 0.792, loss_b 0.474, un_loss_b 0.571, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 00:14:22 - INFO - Epoch 4 step 13300 eta 07:38:41: loss_a 0.200, un_loss_a 0.458, loss_b 0.432, un_loss_b 0.516, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 00:14:44 - INFO - Epoch 4 step 13320 eta 07:38:06: loss_a 0.516, un_loss_a 0.486, loss_b 0.439, un_loss_b 0.660, accuracy_a 0.844, accuracy_b 0.875
2022-05-30 00:15:07 - INFO - Epoch 4 step 13340 eta 07:37:45: loss_a 0.995, un_loss_a 0.513, loss_b 1.266, un_loss_b 0.387, accuracy_a 0.688, accuracy_b 0.688
2022-05-30 00:15:28 - INFO - Epoch 4 step 13360 eta 07:37:10: loss_a 0.490, un_loss_a 0.575, loss_b 0.583, un_loss_b 0.620, accuracy_a 0.812, accuracy_b 0.812
2022-05-30 00:15:51 - INFO - Epoch 4 step 13380 eta 07:36:48: loss_a 0.289, un_loss_a 0.353, loss_b 0.606, un_loss_b 0.467, accuracy_a 0.938, accuracy_b 0.781
2022-05-30 00:16:13 - INFO - Epoch 4 step 13400 eta 07:36:13: loss_a 0.437, un_loss_a 0.382, loss_b 0.507, un_loss_b 0.450, accuracy_a 0.844, accuracy_b 0.875
2022-05-30 00:16:36 - INFO - Epoch 4 step 13420 eta 07:35:51: loss_a 0.510, un_loss_a 0.244, loss_b 0.573, un_loss_b 0.313, accuracy_a 0.906, accuracy_b 0.812
2022-05-30 00:16:57 - INFO - Epoch 4 step 13440 eta 07:35:17: loss_a 0.688, un_loss_a 0.785, loss_b 0.686, un_loss_b 0.764, accuracy_a 0.844, accuracy_b 0.781
2022-05-30 00:17:19 - INFO - Epoch 4 step 13460 eta 07:34:43: loss_a 0.278, un_loss_a 0.307, loss_b 0.344, un_loss_b 0.631, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 00:17:42 - INFO - Epoch 4 step 13480 eta 07:34:20: loss_a 0.581, un_loss_a 0.506, loss_b 0.694, un_loss_b 0.494, accuracy_a 0.844, accuracy_b 0.781
2022-05-30 00:18:03 - INFO - Epoch 4 step 13500 eta 07:33:46: loss_a 0.380, un_loss_a 0.521, loss_b 0.519, un_loss_b 0.429, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 00:18:25 - INFO - Epoch 4 step 13520 eta 07:33:12: loss_a 0.439, un_loss_a 0.190, loss_b 0.728, un_loss_b 0.241, accuracy_a 0.906, accuracy_b 0.781
2022-05-30 00:18:48 - INFO - Epoch 4 step 13540 eta 07:32:50: loss_a 0.342, un_loss_a 0.808, loss_b 0.336, un_loss_b 0.623, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 00:19:09 - INFO - Epoch 4 step 13560 eta 07:32:16: loss_a 0.732, un_loss_a 0.907, loss_b 0.656, un_loss_b 0.697, accuracy_a 0.844, accuracy_b 0.781
2022-05-30 00:19:32 - INFO - Epoch 4 step 13580 eta 07:31:54: loss_a 0.486, un_loss_a 0.640, loss_b 0.434, un_loss_b 0.490, accuracy_a 0.812, accuracy_b 0.781
2022-05-30 00:19:54 - INFO - Epoch 4 step 13600 eta 07:31:20: loss_a 0.357, un_loss_a 0.533, loss_b 0.414, un_loss_b 0.803, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 00:20:15 - INFO - Epoch 4 step 13620 eta 07:30:46: loss_a 0.691, un_loss_a 0.474, loss_b 0.676, un_loss_b 0.415, accuracy_a 0.750, accuracy_b 0.781
2022-05-30 00:20:38 - INFO - Epoch 4 step 13640 eta 07:30:24: loss_a 0.578, un_loss_a 0.642, loss_b 0.796, un_loss_b 0.752, accuracy_a 0.844, accuracy_b 0.750
2022-05-30 00:20:59 - INFO - Epoch 4 step 13660 eta 07:29:50: loss_a 0.481, un_loss_a 0.418, loss_b 0.325, un_loss_b 0.515, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 00:21:21 - INFO - Epoch 4 step 13680 eta 07:29:16: loss_a 0.963, un_loss_a 0.249, loss_b 0.851, un_loss_b 0.353, accuracy_a 0.781, accuracy_b 0.781
2022-05-30 00:21:44 - INFO - Epoch 4 step 13700 eta 07:28:54: loss_a 0.412, un_loss_a 0.752, loss_b 0.801, un_loss_b 0.816, accuracy_a 0.875, accuracy_b 0.781
2022-05-30 00:22:05 - INFO - Epoch 4 step 13720 eta 07:28:20: loss_a 0.256, un_loss_a 0.217, loss_b 0.207, un_loss_b 0.323, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 00:22:28 - INFO - Epoch 4 step 13740 eta 07:27:58: loss_a 0.493, un_loss_a 0.507, loss_b 0.321, un_loss_b 0.416, accuracy_a 0.844, accuracy_b 0.906
2022-05-30 00:22:50 - INFO - Epoch 4 step 13760 eta 07:27:24: loss_a 0.392, un_loss_a 0.350, loss_b 0.521, un_loss_b 0.404, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 00:23:11 - INFO - Epoch 4 step 13780 eta 07:26:51: loss_a 0.934, un_loss_a 0.481, loss_b 0.939, un_loss_b 0.461, accuracy_a 0.750, accuracy_b 0.750
2022-05-30 00:23:34 - INFO - Epoch 4 step 13800 eta 07:26:29: loss_a 0.522, un_loss_a 0.377, loss_b 0.701, un_loss_b 0.354, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 00:23:56 - INFO - Epoch 4 step 13820 eta 07:25:55: loss_a 0.450, un_loss_a 0.391, loss_b 0.765, un_loss_b 0.399, accuracy_a 0.812, accuracy_b 0.844
2022-05-30 00:24:19 - INFO - Epoch 4 step 13840 eta 07:25:33: loss_a 0.506, un_loss_a 0.443, loss_b 0.803, un_loss_b 0.418, accuracy_a 0.844, accuracy_b 0.719
2022-05-30 00:24:40 - INFO - Epoch 4 step 13860 eta 07:24:59: loss_a 0.487, un_loss_a 0.689, loss_b 0.553, un_loss_b 0.869, accuracy_a 0.781, accuracy_b 0.781
2022-05-30 00:25:02 - INFO - Epoch 4 step 13880 eta 07:24:26: loss_a 0.731, un_loss_a 0.624, loss_b 0.931, un_loss_b 0.494, accuracy_a 0.812, accuracy_b 0.719
2022-05-30 00:25:25 - INFO - Epoch 4 step 13900 eta 07:24:04: loss_a 0.682, un_loss_a 0.678, loss_b 0.504, un_loss_b 0.627, accuracy_a 0.750, accuracy_b 0.812
2022-05-30 00:25:46 - INFO - Epoch 4 step 13920 eta 07:23:31: loss_a 0.195, un_loss_a 0.542, loss_b 0.315, un_loss_b 0.569, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 00:26:09 - INFO - Epoch 4 step 13940 eta 07:23:09: loss_a 0.392, un_loss_a 0.607, loss_b 0.546, un_loss_b 0.498, accuracy_a 0.875, accuracy_b 0.844
2022-05-30 00:26:31 - INFO - Epoch 4 step 13960 eta 07:22:36: loss_a 0.501, un_loss_a 0.149, loss_b 0.538, un_loss_b 0.327, accuracy_a 0.875, accuracy_b 0.844
2022-05-30 00:26:54 - INFO - Epoch 4 step 13980 eta 07:22:14: loss_a 0.368, un_loss_a 0.857, loss_b 0.555, un_loss_b 0.780, accuracy_a 0.906, accuracy_b 0.812
2022-05-30 00:27:16 - INFO - Epoch 4 step 14000 eta 07:21:41: loss_a 0.721, un_loss_a 0.641, loss_b 0.603, un_loss_b 0.442, accuracy_a 0.750, accuracy_b 0.781
2022-05-30 00:27:37 - INFO - Epoch 4 step 14020 eta 07:21:08: loss_a 0.420, un_loss_a 0.633, loss_b 0.540, un_loss_b 0.664, accuracy_a 0.812, accuracy_b 0.844
2022-05-30 00:28:00 - INFO - Epoch 4 step 14040 eta 07:20:46: loss_a 0.685, un_loss_a 0.582, loss_b 0.796, un_loss_b 0.540, accuracy_a 0.719, accuracy_b 0.812
2022-05-30 00:28:22 - INFO - Epoch 4 step 14060 eta 07:20:13: loss_a 0.516, un_loss_a 0.355, loss_b 0.526, un_loss_b 0.721, accuracy_a 0.875, accuracy_b 0.875
Begin Validation
2022-05-30 00:30:25 - INFO - Epoch 4 step 14060:, {'lv1_acc': 0.7712, 'lv2_acc': 0.6653, 'lv1_f1_micro': 0.7712, 'lv1_f1_macro': 0.7352, 'lv2_f1_micro': 0.6653, 'lv2_f1_macro': 0.5304, 'mean_f1': 0.6755}, {'lv1_acc': 0.7742, 'lv2_acc': 0.668, 'lv1_f1_micro': 0.7742, 'lv1_f1_macro': 0.7427, 'lv2_f1_micro': 0.668, 'lv2_f1_macro': 0.5376, 'mean_f1': 0.6806}
/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-05-30 00:30:51 - INFO - Epoch 5 step 14080 eta 07:34:31: loss_a 0.295, un_loss_a 0.462, loss_b 0.455, un_loss_b 0.514, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 00:31:12 - INFO - Epoch 5 step 14100 eta 07:33:57: loss_a 0.378, un_loss_a 0.297, loss_b 0.636, un_loss_b 0.427, accuracy_a 0.844, accuracy_b 0.750
2022-05-30 00:31:35 - INFO - Epoch 5 step 14120 eta 07:33:35: loss_a 0.092, un_loss_a 0.701, loss_b 0.245, un_loss_b 0.348, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 00:31:57 - INFO - Epoch 5 step 14140 eta 07:33:01: loss_a 0.124, un_loss_a 0.361, loss_b 0.152, un_loss_b 0.515, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 00:32:18 - INFO - Epoch 5 step 14160 eta 07:32:26: loss_a 0.193, un_loss_a 0.616, loss_b 0.399, un_loss_b 0.955, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 00:32:42 - INFO - Epoch 5 step 14180 eta 07:32:05: loss_a 0.342, un_loss_a 0.766, loss_b 0.463, un_loss_b 0.809, accuracy_a 0.875, accuracy_b 0.844
2022-05-30 00:33:03 - INFO - Epoch 5 step 14200 eta 07:31:31: loss_a 0.366, un_loss_a 0.719, loss_b 0.277, un_loss_b 0.628, accuracy_a 0.875, accuracy_b 0.938
2022-05-30 00:33:27 - INFO - Epoch 5 step 14220 eta 07:31:09: loss_a 0.239, un_loss_a 0.388, loss_b 0.377, un_loss_b 0.467, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 00:33:48 - INFO - Epoch 5 step 14240 eta 07:30:35: loss_a 0.308, un_loss_a 0.420, loss_b 0.631, un_loss_b 0.511, accuracy_a 0.875, accuracy_b 0.781
2022-05-30 00:34:11 - INFO - Epoch 5 step 14260 eta 07:30:13: loss_a 0.290, un_loss_a 0.388, loss_b 0.291, un_loss_b 0.372, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 00:34:33 - INFO - Epoch 5 step 14280 eta 07:29:39: loss_a 0.460, un_loss_a 0.501, loss_b 0.709, un_loss_b 0.479, accuracy_a 0.906, accuracy_b 0.812
2022-05-30 00:34:54 - INFO - Epoch 5 step 14300 eta 07:29:04: loss_a 0.403, un_loss_a 0.166, loss_b 0.613, un_loss_b 0.266, accuracy_a 0.875, accuracy_b 0.781
2022-05-30 00:35:18 - INFO - Epoch 5 step 14320 eta 07:28:43: loss_a 0.404, un_loss_a 0.434, loss_b 0.787, un_loss_b 0.279, accuracy_a 0.938, accuracy_b 0.750
2022-05-30 00:35:39 - INFO - Epoch 5 step 14340 eta 07:28:09: loss_a 0.552, un_loss_a 0.426, loss_b 0.710, un_loss_b 0.319, accuracy_a 0.812, accuracy_b 0.750
2022-05-30 00:36:00 - INFO - Epoch 5 step 14360 eta 07:27:35: loss_a 0.196, un_loss_a 0.507, loss_b 0.324, un_loss_b 0.538, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 00:36:24 - INFO - Epoch 5 step 14380 eta 07:27:13: loss_a 0.488, un_loss_a 0.675, loss_b 0.555, un_loss_b 0.586, accuracy_a 0.812, accuracy_b 0.844
2022-05-30 00:36:45 - INFO - Epoch 5 step 14400 eta 07:26:39: loss_a 0.253, un_loss_a 0.355, loss_b 0.385, un_loss_b 0.287, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 00:37:09 - INFO - Epoch 5 step 14420 eta 07:26:18: loss_a 0.242, un_loss_a 0.362, loss_b 0.298, un_loss_b 0.396, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 00:37:30 - INFO - Epoch 5 step 14440 eta 07:25:44: loss_a 0.206, un_loss_a 0.173, loss_b 0.272, un_loss_b 0.295, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 00:37:52 - INFO - Epoch 5 step 14460 eta 07:25:10: loss_a 0.299, un_loss_a 0.340, loss_b 0.516, un_loss_b 0.435, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 00:38:15 - INFO - Epoch 5 step 14480 eta 07:24:49: loss_a 0.390, un_loss_a 0.744, loss_b 0.537, un_loss_b 0.919, accuracy_a 0.875, accuracy_b 0.812
2022-05-30 00:38:36 - INFO - Epoch 5 step 14500 eta 07:24:15: loss_a 0.313, un_loss_a 0.349, loss_b 0.473, un_loss_b 0.442, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 00:38:58 - INFO - Epoch 5 step 14520 eta 07:23:41: loss_a 0.185, un_loss_a 0.464, loss_b 0.347, un_loss_b 0.460, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 00:39:21 - INFO - Epoch 5 step 14540 eta 07:23:20: loss_a 0.508, un_loss_a 0.521, loss_b 0.646, un_loss_b 0.592, accuracy_a 0.844, accuracy_b 0.812
2022-05-30 00:39:43 - INFO - Epoch 5 step 14560 eta 07:22:46: loss_a 0.232, un_loss_a 0.773, loss_b 0.335, un_loss_b 0.684, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 00:40:06 - INFO - Epoch 5 step 14580 eta 07:22:25: loss_a 0.306, un_loss_a 0.702, loss_b 0.310, un_loss_b 0.638, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 00:40:28 - INFO - Epoch 5 step 14600 eta 07:21:51: loss_a 0.451, un_loss_a 0.287, loss_b 0.452, un_loss_b 0.375, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 00:40:49 - INFO - Epoch 5 step 14620 eta 07:21:17: loss_a 0.483, un_loss_a 0.617, loss_b 0.633, un_loss_b 0.585, accuracy_a 0.844, accuracy_b 0.875
2022-05-30 00:41:12 - INFO - Epoch 5 step 14640 eta 07:20:56: loss_a 0.348, un_loss_a 0.401, loss_b 0.526, un_loss_b 0.543, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 00:41:34 - INFO - Epoch 5 step 14660 eta 07:20:22: loss_a 0.196, un_loss_a 0.520, loss_b 0.213, un_loss_b 0.488, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 00:41:57 - INFO - Epoch 5 step 14680 eta 07:20:00: loss_a 0.210, un_loss_a 0.541, loss_b 0.397, un_loss_b 0.553, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 00:42:19 - INFO - Epoch 5 step 14700 eta 07:19:27: loss_a 0.478, un_loss_a 0.496, loss_b 0.678, un_loss_b 0.675, accuracy_a 0.875, accuracy_b 0.781
2022-05-30 00:42:40 - INFO - Epoch 5 step 14720 eta 07:18:53: loss_a 0.294, un_loss_a 0.475, loss_b 0.489, un_loss_b 0.534, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 00:43:03 - INFO - Epoch 5 step 14740 eta 07:18:31: loss_a 0.256, un_loss_a 0.417, loss_b 0.368, un_loss_b 0.336, accuracy_a 0.906, accuracy_b 0.812
2022-05-30 00:43:25 - INFO - Epoch 5 step 14760 eta 07:17:58: loss_a 0.475, un_loss_a 0.699, loss_b 0.591, un_loss_b 0.536, accuracy_a 0.875, accuracy_b 0.844
2022-05-30 00:43:48 - INFO - Epoch 5 step 14780 eta 07:17:37: loss_a 0.217, un_loss_a 0.413, loss_b 0.406, un_loss_b 0.409, accuracy_a 0.875, accuracy_b 0.812
2022-05-30 00:44:10 - INFO - Epoch 5 step 14800 eta 07:17:03: loss_a 0.164, un_loss_a 0.584, loss_b 0.170, un_loss_b 0.555, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 00:44:33 - INFO - Epoch 5 step 14820 eta 07:16:42: loss_a 0.278, un_loss_a 0.518, loss_b 0.492, un_loss_b 0.408, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 00:44:54 - INFO - Epoch 5 step 14840 eta 07:16:08: loss_a 0.778, un_loss_a 0.604, loss_b 0.703, un_loss_b 0.749, accuracy_a 0.812, accuracy_b 0.844
2022-05-30 00:45:16 - INFO - Epoch 5 step 14860 eta 07:15:35: loss_a 0.181, un_loss_a 0.653, loss_b 0.283, un_loss_b 0.697, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 00:45:39 - INFO - Epoch 5 step 14880 eta 07:15:13: loss_a 0.363, un_loss_a 0.761, loss_b 0.504, un_loss_b 0.613, accuracy_a 0.812, accuracy_b 0.812
2022-05-30 00:46:01 - INFO - Epoch 5 step 14900 eta 07:14:40: loss_a 0.300, un_loss_a 0.607, loss_b 0.318, un_loss_b 0.523, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 00:46:24 - INFO - Epoch 5 step 14920 eta 07:14:21: loss_a 0.695, un_loss_a 0.331, loss_b 0.486, un_loss_b 0.362, accuracy_a 0.812, accuracy_b 0.875
2022-05-30 00:46:46 - INFO - Epoch 5 step 14940 eta 07:13:48: loss_a 0.680, un_loss_a 0.701, loss_b 0.369, un_loss_b 0.450, accuracy_a 0.781, accuracy_b 0.938
2022-05-30 00:47:07 - INFO - Epoch 5 step 14960 eta 07:13:14: loss_a 0.513, un_loss_a 0.216, loss_b 0.482, un_loss_b 0.186, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 00:47:31 - INFO - Epoch 5 step 14980 eta 07:12:54: loss_a 0.131, un_loss_a 1.130, loss_b 0.218, un_loss_b 1.082, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 00:47:52 - INFO - Epoch 5 step 15000 eta 07:12:21: loss_a 0.406, un_loss_a 0.321, loss_b 0.420, un_loss_b 0.407, accuracy_a 0.812, accuracy_b 0.844
2022-05-30 00:48:16 - INFO - Epoch 5 step 15020 eta 07:11:59: loss_a 0.631, un_loss_a 0.900, loss_b 0.528, un_loss_b 0.628, accuracy_a 0.781, accuracy_b 0.875
2022-05-30 00:48:37 - INFO - Epoch 5 step 15040 eta 07:11:26: loss_a 0.467, un_loss_a 0.652, loss_b 0.608, un_loss_b 0.571, accuracy_a 0.812, accuracy_b 0.750
2022-05-30 00:48:58 - INFO - Epoch 5 step 15060 eta 07:10:53: loss_a 0.400, un_loss_a 0.468, loss_b 0.290, un_loss_b 0.580, accuracy_a 0.844, accuracy_b 0.938
2022-05-30 00:49:22 - INFO - Epoch 5 step 15080 eta 07:10:31: loss_a 0.602, un_loss_a 0.630, loss_b 0.763, un_loss_b 0.945, accuracy_a 0.781, accuracy_b 0.750
2022-05-30 00:49:43 - INFO - Epoch 5 step 15100 eta 07:09:58: loss_a 0.269, un_loss_a 0.581, loss_b 0.406, un_loss_b 0.709, accuracy_a 0.875, accuracy_b 0.906
2022-05-30 00:50:05 - INFO - Epoch 5 step 15120 eta 07:09:25: loss_a 0.213, un_loss_a 0.398, loss_b 0.158, un_loss_b 0.653, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 00:50:28 - INFO - Epoch 5 step 15140 eta 07:09:03: loss_a 0.229, un_loss_a 0.583, loss_b 0.293, un_loss_b 0.609, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 00:50:49 - INFO - Epoch 5 step 15160 eta 07:08:30: loss_a 0.313, un_loss_a 0.308, loss_b 0.329, un_loss_b 0.395, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 00:51:11 - INFO - Epoch 5 step 15180 eta 07:07:57: loss_a 0.348, un_loss_a 0.499, loss_b 0.354, un_loss_b 0.793, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 00:51:34 - INFO - Epoch 5 step 15200 eta 07:07:38: loss_a 0.236, un_loss_a 0.662, loss_b 0.264, un_loss_b 0.500, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 00:51:56 - INFO - Epoch 5 step 15220 eta 07:07:04: loss_a 0.251, un_loss_a 0.429, loss_b 0.642, un_loss_b 0.367, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 00:52:19 - INFO - Epoch 5 step 15240 eta 07:06:45: loss_a 0.288, un_loss_a 0.856, loss_b 0.430, un_loss_b 0.660, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 00:52:41 - INFO - Epoch 5 step 15260 eta 07:06:12: loss_a 0.268, un_loss_a 0.551, loss_b 0.318, un_loss_b 0.703, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 00:53:02 - INFO - Epoch 5 step 15280 eta 07:05:39: loss_a 0.279, un_loss_a 0.494, loss_b 0.418, un_loss_b 0.786, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 00:53:26 - INFO - Epoch 5 step 15300 eta 07:05:18: loss_a 0.226, un_loss_a 0.453, loss_b 0.229, un_loss_b 0.596, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 00:53:47 - INFO - Epoch 5 step 15320 eta 07:04:45: loss_a 0.538, un_loss_a 0.546, loss_b 0.644, un_loss_b 0.901, accuracy_a 0.781, accuracy_b 0.750
2022-05-30 00:54:11 - INFO - Epoch 5 step 15340 eta 07:04:27: loss_a 0.595, un_loss_a 0.900, loss_b 0.728, un_loss_b 1.081, accuracy_a 0.875, accuracy_b 0.844
2022-05-30 00:54:33 - INFO - Epoch 5 step 15360 eta 07:03:54: loss_a 0.383, un_loss_a 0.330, loss_b 0.668, un_loss_b 0.603, accuracy_a 0.875, accuracy_b 0.750
2022-05-30 00:54:54 - INFO - Epoch 5 step 15380 eta 07:03:21: loss_a 0.426, un_loss_a 0.441, loss_b 0.317, un_loss_b 0.450, accuracy_a 0.812, accuracy_b 0.875
2022-05-30 00:55:18 - INFO - Epoch 5 step 15400 eta 07:03:01: loss_a 0.219, un_loss_a 0.426, loss_b 0.411, un_loss_b 0.433, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 00:55:39 - INFO - Epoch 5 step 15420 eta 07:02:28: loss_a 0.365, un_loss_a 0.620, loss_b 0.391, un_loss_b 0.546, accuracy_a 0.906, accuracy_b 0.812
2022-05-30 00:56:02 - INFO - Epoch 5 step 15440 eta 07:02:07: loss_a 0.509, un_loss_a 0.611, loss_b 0.371, un_loss_b 0.984, accuracy_a 0.812, accuracy_b 0.875
2022-05-30 00:56:24 - INFO - Epoch 5 step 15460 eta 07:01:35: loss_a 0.459, un_loss_a 0.476, loss_b 0.933, un_loss_b 0.435, accuracy_a 0.812, accuracy_b 0.812
2022-05-30 00:56:47 - INFO - Epoch 5 step 15480 eta 07:01:13: loss_a 0.211, un_loss_a 0.728, loss_b 0.210, un_loss_b 0.630, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 00:57:09 - INFO - Epoch 5 step 15500 eta 07:00:40: loss_a 0.468, un_loss_a 0.505, loss_b 0.451, un_loss_b 0.728, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 00:57:30 - INFO - Epoch 5 step 15520 eta 07:00:08: loss_a 0.409, un_loss_a 0.659, loss_b 0.488, un_loss_b 0.540, accuracy_a 0.812, accuracy_b 0.781
2022-05-30 00:57:53 - INFO - Epoch 5 step 15540 eta 06:59:47: loss_a 0.480, un_loss_a 0.408, loss_b 0.620, un_loss_b 0.496, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 00:58:15 - INFO - Epoch 5 step 15560 eta 06:59:14: loss_a 0.410, un_loss_a 0.410, loss_b 0.407, un_loss_b 0.327, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 00:58:39 - INFO - Epoch 5 step 15580 eta 06:58:56: loss_a 0.241, un_loss_a 0.289, loss_b 0.321, un_loss_b 0.268, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 00:59:00 - INFO - Epoch 5 step 15600 eta 06:58:23: loss_a 0.406, un_loss_a 0.206, loss_b 0.757, un_loss_b 0.175, accuracy_a 0.875, accuracy_b 0.812
2022-05-30 00:59:22 - INFO - Epoch 5 step 15620 eta 06:57:50: loss_a 0.406, un_loss_a 0.323, loss_b 0.765, un_loss_b 0.261, accuracy_a 0.875, accuracy_b 0.719
2022-05-30 00:59:45 - INFO - Epoch 5 step 15640 eta 06:57:31: loss_a 0.424, un_loss_a 0.615, loss_b 0.628, un_loss_b 0.410, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 01:00:07 - INFO - Epoch 5 step 15660 eta 06:56:58: loss_a 0.126, un_loss_a 0.530, loss_b 0.194, un_loss_b 0.785, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 01:00:30 - INFO - Epoch 5 step 15680 eta 06:56:36: loss_a 0.322, un_loss_a 0.706, loss_b 0.372, un_loss_b 0.646, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 01:00:51 - INFO - Epoch 5 step 15700 eta 06:56:04: loss_a 0.478, un_loss_a 0.464, loss_b 0.816, un_loss_b 0.321, accuracy_a 0.875, accuracy_b 0.781
2022-05-30 01:01:13 - INFO - Epoch 5 step 15720 eta 06:55:32: loss_a 0.405, un_loss_a 0.450, loss_b 0.515, un_loss_b 0.545, accuracy_a 0.875, accuracy_b 0.812
2022-05-30 01:01:36 - INFO - Epoch 5 step 15740 eta 06:55:10: loss_a 0.215, un_loss_a 0.382, loss_b 0.218, un_loss_b 0.291, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 01:01:58 - INFO - Epoch 5 step 15760 eta 06:54:38: loss_a 0.211, un_loss_a 0.597, loss_b 0.292, un_loss_b 0.583, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:02:19 - INFO - Epoch 5 step 15780 eta 06:54:05: loss_a 0.240, un_loss_a 0.349, loss_b 0.181, un_loss_b 0.354, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 01:02:42 - INFO - Epoch 5 step 15800 eta 06:53:45: loss_a 0.284, un_loss_a 0.442, loss_b 0.465, un_loss_b 0.438, accuracy_a 0.844, accuracy_b 0.875
2022-05-30 01:03:04 - INFO - Epoch 5 step 15820 eta 06:53:12: loss_a 0.342, un_loss_a 0.624, loss_b 0.244, un_loss_b 0.495, accuracy_a 0.875, accuracy_b 0.938
2022-05-30 01:03:27 - INFO - Epoch 5 step 15840 eta 06:52:51: loss_a 0.292, un_loss_a 0.842, loss_b 0.352, un_loss_b 0.915, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:03:49 - INFO - Epoch 5 step 15860 eta 06:52:18: loss_a 0.228, un_loss_a 0.784, loss_b 0.290, un_loss_b 0.478, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 01:04:10 - INFO - Epoch 5 step 15880 eta 06:51:46: loss_a 0.220, un_loss_a 0.551, loss_b 0.164, un_loss_b 0.466, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 01:04:33 - INFO - Epoch 5 step 15900 eta 06:51:25: loss_a 0.305, un_loss_a 0.338, loss_b 0.331, un_loss_b 0.450, accuracy_a 0.906, accuracy_b 0.812
2022-05-30 01:04:55 - INFO - Epoch 5 step 15920 eta 06:50:53: loss_a 0.338, un_loss_a 0.570, loss_b 0.486, un_loss_b 0.315, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 01:05:18 - INFO - Epoch 5 step 15940 eta 06:50:31: loss_a 0.127, un_loss_a 0.356, loss_b 0.538, un_loss_b 0.399, accuracy_a 1.000, accuracy_b 0.844
2022-05-30 01:05:40 - INFO - Epoch 5 step 15960 eta 06:49:59: loss_a 0.627, un_loss_a 0.343, loss_b 0.671, un_loss_b 0.428, accuracy_a 0.812, accuracy_b 0.812
2022-05-30 01:06:01 - INFO - Epoch 5 step 15980 eta 06:49:27: loss_a 0.420, un_loss_a 0.286, loss_b 0.517, un_loss_b 0.339, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 01:06:24 - INFO - Epoch 5 step 16000 eta 06:49:06: loss_a 0.349, un_loss_a 0.193, loss_b 0.529, un_loss_b 0.195, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 01:06:46 - INFO - Epoch 5 step 16020 eta 06:48:34: loss_a 0.319, un_loss_a 0.672, loss_b 0.490, un_loss_b 0.733, accuracy_a 0.812, accuracy_b 0.875
2022-05-30 01:07:09 - INFO - Epoch 5 step 16040 eta 06:48:13: loss_a 0.225, un_loss_a 0.704, loss_b 0.150, un_loss_b 0.651, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 01:07:31 - INFO - Epoch 5 step 16060 eta 06:47:41: loss_a 0.379, un_loss_a 0.712, loss_b 0.410, un_loss_b 1.232, accuracy_a 0.844, accuracy_b 0.781
2022-05-30 01:07:52 - INFO - Epoch 5 step 16080 eta 06:47:09: loss_a 0.150, un_loss_a 0.861, loss_b 0.304, un_loss_b 0.641, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 01:08:16 - INFO - Epoch 5 step 16100 eta 06:46:50: loss_a 0.309, un_loss_a 0.256, loss_b 0.472, un_loss_b 0.369, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 01:08:37 - INFO - Epoch 5 step 16120 eta 06:46:18: loss_a 0.206, un_loss_a 0.424, loss_b 0.278, un_loss_b 0.528, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 01:09:01 - INFO - Epoch 5 step 16140 eta 06:45:59: loss_a 0.364, un_loss_a 0.316, loss_b 0.379, un_loss_b 0.470, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 01:09:23 - INFO - Epoch 5 step 16160 eta 06:45:27: loss_a 0.374, un_loss_a 0.355, loss_b 0.342, un_loss_b 0.517, accuracy_a 0.844, accuracy_b 0.875
2022-05-30 01:09:46 - INFO - Epoch 5 step 16180 eta 06:45:06: loss_a 0.362, un_loss_a 0.572, loss_b 0.485, un_loss_b 0.444, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 01:10:07 - INFO - Epoch 5 step 16200 eta 06:44:34: loss_a 0.292, un_loss_a 0.667, loss_b 0.580, un_loss_b 0.619, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 01:10:29 - INFO - Epoch 5 step 16220 eta 06:44:02: loss_a 0.204, un_loss_a 0.772, loss_b 0.225, un_loss_b 0.635, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 01:10:52 - INFO - Epoch 5 step 16240 eta 06:43:41: loss_a 0.586, un_loss_a 0.487, loss_b 0.713, un_loss_b 0.557, accuracy_a 0.875, accuracy_b 0.781
2022-05-30 01:11:14 - INFO - Epoch 5 step 16260 eta 06:43:09: loss_a 0.533, un_loss_a 0.936, loss_b 0.670, un_loss_b 0.685, accuracy_a 0.781, accuracy_b 0.812
2022-05-30 01:11:37 - INFO - Epoch 5 step 16280 eta 06:42:48: loss_a 0.054, un_loss_a 0.494, loss_b 0.147, un_loss_b 0.426, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 01:11:59 - INFO - Epoch 5 step 16300 eta 06:42:16: loss_a 0.398, un_loss_a 0.428, loss_b 0.538, un_loss_b 0.423, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 01:12:20 - INFO - Epoch 5 step 16320 eta 06:41:45: loss_a 0.257, un_loss_a 0.426, loss_b 0.488, un_loss_b 0.582, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 01:12:43 - INFO - Epoch 5 step 16340 eta 06:41:24: loss_a 0.360, un_loss_a 0.477, loss_b 0.340, un_loss_b 0.291, accuracy_a 0.906, accuracy_b 0.812
2022-05-30 01:13:05 - INFO - Epoch 5 step 16360 eta 06:40:52: loss_a 0.425, un_loss_a 0.928, loss_b 0.478, un_loss_b 0.567, accuracy_a 0.812, accuracy_b 0.812
2022-05-30 01:13:26 - INFO - Epoch 5 step 16380 eta 06:40:20: loss_a 0.392, un_loss_a 0.438, loss_b 0.580, un_loss_b 0.446, accuracy_a 0.875, accuracy_b 0.812
2022-05-30 01:13:50 - INFO - Epoch 5 step 16400 eta 06:39:59: loss_a 0.821, un_loss_a 0.259, loss_b 0.681, un_loss_b 0.251, accuracy_a 0.781, accuracy_b 0.750
2022-05-30 01:14:11 - INFO - Epoch 5 step 16420 eta 06:39:27: loss_a 0.298, un_loss_a 0.529, loss_b 0.345, un_loss_b 0.515, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 01:14:33 - INFO - Epoch 5 step 16440 eta 06:38:56: loss_a 0.165, un_loss_a 0.659, loss_b 0.194, un_loss_b 0.677, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 01:14:56 - INFO - Epoch 5 step 16460 eta 06:38:34: loss_a 0.288, un_loss_a 0.485, loss_b 0.420, un_loss_b 0.415, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 01:15:17 - INFO - Epoch 5 step 16480 eta 06:38:03: loss_a 0.343, un_loss_a 0.411, loss_b 0.368, un_loss_b 0.460, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 01:15:41 - INFO - Epoch 5 step 16500 eta 06:37:42: loss_a 0.710, un_loss_a 0.499, loss_b 0.853, un_loss_b 0.486, accuracy_a 0.719, accuracy_b 0.719
2022-05-30 01:16:02 - INFO - Epoch 5 step 16520 eta 06:37:10: loss_a 0.526, un_loss_a 0.546, loss_b 0.556, un_loss_b 0.694, accuracy_a 0.844, accuracy_b 0.812
2022-05-30 01:16:24 - INFO - Epoch 5 step 16540 eta 06:36:38: loss_a 0.342, un_loss_a 0.321, loss_b 0.467, un_loss_b 0.290, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 01:16:47 - INFO - Epoch 5 step 16560 eta 06:36:18: loss_a 0.414, un_loss_a 0.718, loss_b 0.574, un_loss_b 0.409, accuracy_a 0.875, accuracy_b 0.906
2022-05-30 01:17:09 - INFO - Epoch 5 step 16580 eta 06:35:46: loss_a 0.295, un_loss_a 0.790, loss_b 0.436, un_loss_b 0.768, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 01:17:32 - INFO - Epoch 5 step 16600 eta 06:35:26: loss_a 0.327, un_loss_a 0.630, loss_b 0.455, un_loss_b 1.004, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 01:17:53 - INFO - Epoch 5 step 16620 eta 06:34:54: loss_a 0.409, un_loss_a 0.206, loss_b 0.436, un_loss_b 0.320, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 01:18:15 - INFO - Epoch 5 step 16640 eta 06:34:23: loss_a 0.449, un_loss_a 0.412, loss_b 0.794, un_loss_b 0.367, accuracy_a 0.906, accuracy_b 0.812
2022-05-30 01:18:38 - INFO - Epoch 5 step 16660 eta 06:34:02: loss_a 0.284, un_loss_a 0.411, loss_b 0.471, un_loss_b 0.404, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 01:19:00 - INFO - Epoch 5 step 16680 eta 06:33:30: loss_a 0.405, un_loss_a 0.505, loss_b 0.463, un_loss_b 0.512, accuracy_a 0.781, accuracy_b 0.844
2022-05-30 01:19:23 - INFO - Epoch 5 step 16700 eta 06:33:10: loss_a 0.083, un_loss_a 0.492, loss_b 0.280, un_loss_b 0.647, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 01:19:45 - INFO - Epoch 5 step 16720 eta 06:32:38: loss_a 0.507, un_loss_a 0.768, loss_b 0.471, un_loss_b 0.465, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 01:20:06 - INFO - Epoch 5 step 16740 eta 06:32:07: loss_a 0.417, un_loss_a 0.581, loss_b 0.395, un_loss_b 0.632, accuracy_a 0.844, accuracy_b 0.781
2022-05-30 01:20:29 - INFO - Epoch 5 step 16760 eta 06:31:45: loss_a 0.605, un_loss_a 0.476, loss_b 0.510, un_loss_b 0.495, accuracy_a 0.719, accuracy_b 0.812
2022-05-30 01:20:51 - INFO - Epoch 5 step 16780 eta 06:31:13: loss_a 0.396, un_loss_a 0.887, loss_b 0.545, un_loss_b 0.488, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 01:21:14 - INFO - Epoch 5 step 16800 eta 06:30:53: loss_a 0.633, un_loss_a 0.869, loss_b 0.728, un_loss_b 0.650, accuracy_a 0.844, accuracy_b 0.875
2022-05-30 01:21:35 - INFO - Epoch 5 step 16820 eta 06:30:21: loss_a 0.458, un_loss_a 0.331, loss_b 0.909, un_loss_b 0.281, accuracy_a 0.875, accuracy_b 0.781
2022-05-30 01:21:59 - INFO - Epoch 5 step 16840 eta 06:30:00: loss_a 0.122, un_loss_a 0.450, loss_b 0.247, un_loss_b 0.595, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 01:22:20 - INFO - Epoch 5 step 16860 eta 06:29:29: loss_a 0.486, un_loss_a 0.532, loss_b 0.592, un_loss_b 0.756, accuracy_a 0.875, accuracy_b 0.844
Begin Validation
2022-05-30 01:24:36 - INFO - Epoch 5 step 16872:, {'lv1_acc': 0.7739, 'lv2_acc': 0.6629, 'lv1_f1_micro': 0.7739, 'lv1_f1_macro': 0.7357, 'lv2_f1_micro': 0.6629, 'lv2_f1_macro': 0.5428, 'mean_f1': 0.6788}, {'lv1_acc': 0.7749, 'lv2_acc': 0.6697, 'lv1_f1_micro': 0.7749, 'lv1_f1_macro': 0.7423, 'lv2_f1_micro': 0.6697, 'lv2_f1_macro': 0.5484, 'mean_f1': 0.6838}
/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-05-30 01:24:48 - INFO - Epoch 6 step 16880 eta 06:40:55: loss_a 0.172, un_loss_a 0.717, loss_b 0.341, un_loss_b 0.742, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 01:25:12 - INFO - Epoch 6 step 16900 eta 06:40:34: loss_a 0.072, un_loss_a 0.345, loss_b 0.207, un_loss_b 0.310, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 01:25:33 - INFO - Epoch 6 step 16920 eta 06:40:02: loss_a 0.298, un_loss_a 0.383, loss_b 0.326, un_loss_b 0.427, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:25:57 - INFO - Epoch 6 step 16940 eta 06:39:40: loss_a 0.234, un_loss_a 0.298, loss_b 0.307, un_loss_b 0.288, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 01:26:18 - INFO - Epoch 6 step 16960 eta 06:39:08: loss_a 0.139, un_loss_a 0.634, loss_b 0.142, un_loss_b 0.666, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 01:26:40 - INFO - Epoch 6 step 16980 eta 06:38:36: loss_a 0.179, un_loss_a 0.344, loss_b 0.378, un_loss_b 0.281, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 01:27:03 - INFO - Epoch 6 step 17000 eta 06:38:14: loss_a 0.272, un_loss_a 0.552, loss_b 0.652, un_loss_b 0.577, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 01:27:25 - INFO - Epoch 6 step 17020 eta 06:37:42: loss_a 0.098, un_loss_a 0.901, loss_b 0.098, un_loss_b 0.795, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 01:27:48 - INFO - Epoch 6 step 17040 eta 06:37:20: loss_a 0.175, un_loss_a 0.799, loss_b 0.299, un_loss_b 0.723, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 01:28:09 - INFO - Epoch 6 step 17060 eta 06:36:48: loss_a 0.306, un_loss_a 0.445, loss_b 0.457, un_loss_b 0.435, accuracy_a 0.906, accuracy_b 0.781
2022-05-30 01:28:33 - INFO - Epoch 6 step 17080 eta 06:36:26: loss_a 0.232, un_loss_a 0.512, loss_b 0.229, un_loss_b 0.663, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 01:28:54 - INFO - Epoch 6 step 17100 eta 06:35:54: loss_a 0.471, un_loss_a 0.513, loss_b 0.706, un_loss_b 0.659, accuracy_a 0.875, accuracy_b 0.781
2022-05-30 01:29:16 - INFO - Epoch 6 step 17120 eta 06:35:22: loss_a 0.178, un_loss_a 0.634, loss_b 0.375, un_loss_b 0.531, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:29:39 - INFO - Epoch 6 step 17140 eta 06:35:00: loss_a 0.094, un_loss_a 0.519, loss_b 0.423, un_loss_b 0.544, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 01:30:00 - INFO - Epoch 6 step 17160 eta 06:34:27: loss_a 0.094, un_loss_a 0.589, loss_b 0.194, un_loss_b 0.530, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 01:30:24 - INFO - Epoch 6 step 17180 eta 06:34:06: loss_a 0.146, un_loss_a 0.600, loss_b 0.187, un_loss_b 0.695, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 01:30:45 - INFO - Epoch 6 step 17200 eta 06:33:34: loss_a 0.051, un_loss_a 0.271, loss_b 0.212, un_loss_b 0.254, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 01:31:07 - INFO - Epoch 6 step 17220 eta 06:33:02: loss_a 0.289, un_loss_a 0.355, loss_b 0.491, un_loss_b 0.476, accuracy_a 0.875, accuracy_b 0.812
2022-05-30 01:31:30 - INFO - Epoch 6 step 17240 eta 06:32:40: loss_a 0.058, un_loss_a 0.251, loss_b 0.094, un_loss_b 0.451, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 01:31:51 - INFO - Epoch 6 step 17260 eta 06:32:07: loss_a 0.179, un_loss_a 0.457, loss_b 0.200, un_loss_b 0.602, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 01:32:15 - INFO - Epoch 6 step 17280 eta 06:31:45: loss_a 0.325, un_loss_a 0.426, loss_b 0.550, un_loss_b 0.523, accuracy_a 0.875, accuracy_b 0.781
2022-05-30 01:32:36 - INFO - Epoch 6 step 17300 eta 06:31:13: loss_a 0.115, un_loss_a 0.262, loss_b 0.193, un_loss_b 0.377, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 01:32:58 - INFO - Epoch 6 step 17320 eta 06:30:41: loss_a 0.211, un_loss_a 0.725, loss_b 0.389, un_loss_b 0.549, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:33:21 - INFO - Epoch 6 step 17340 eta 06:30:19: loss_a 0.125, un_loss_a 0.257, loss_b 0.109, un_loss_b 0.494, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 01:33:42 - INFO - Epoch 6 step 17360 eta 06:29:47: loss_a 0.268, un_loss_a 0.464, loss_b 0.336, un_loss_b 0.410, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 01:34:06 - INFO - Epoch 6 step 17380 eta 06:29:25: loss_a 0.516, un_loss_a 0.404, loss_b 0.581, un_loss_b 0.236, accuracy_a 0.844, accuracy_b 0.781
2022-05-30 01:34:27 - INFO - Epoch 6 step 17400 eta 06:28:53: loss_a 0.196, un_loss_a 0.344, loss_b 0.316, un_loss_b 0.397, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 01:34:48 - INFO - Epoch 6 step 17420 eta 06:28:21: loss_a 0.215, un_loss_a 0.602, loss_b 0.182, un_loss_b 0.481, accuracy_a 0.875, accuracy_b 0.938
2022-05-30 01:35:12 - INFO - Epoch 6 step 17440 eta 06:27:59: loss_a 0.261, un_loss_a 0.328, loss_b 0.236, un_loss_b 0.329, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 01:35:33 - INFO - Epoch 6 step 17460 eta 06:27:27: loss_a 0.371, un_loss_a 0.513, loss_b 0.394, un_loss_b 0.451, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 01:35:55 - INFO - Epoch 6 step 17480 eta 06:26:55: loss_a 0.216, un_loss_a 0.826, loss_b 0.231, un_loss_b 0.843, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 01:36:18 - INFO - Epoch 6 step 17500 eta 06:26:33: loss_a 0.182, un_loss_a 0.810, loss_b 0.462, un_loss_b 0.658, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 01:36:39 - INFO - Epoch 6 step 17520 eta 06:26:01: loss_a 0.225, un_loss_a 0.207, loss_b 0.379, un_loss_b 0.285, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 01:37:03 - INFO - Epoch 6 step 17540 eta 06:25:41: loss_a 0.128, un_loss_a 0.609, loss_b 0.141, un_loss_b 0.393, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 01:37:25 - INFO - Epoch 6 step 17560 eta 06:25:10: loss_a 0.213, un_loss_a 0.573, loss_b 0.385, un_loss_b 0.453, accuracy_a 0.906, accuracy_b 0.812
2022-05-30 01:37:46 - INFO - Epoch 6 step 17580 eta 06:24:38: loss_a 0.261, un_loss_a 0.793, loss_b 0.346, un_loss_b 0.470, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:38:09 - INFO - Epoch 6 step 17600 eta 06:24:17: loss_a 0.223, un_loss_a 0.672, loss_b 0.293, un_loss_b 0.726, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 01:38:31 - INFO - Epoch 6 step 17620 eta 06:23:45: loss_a 0.190, un_loss_a 0.541, loss_b 0.214, un_loss_b 0.751, accuracy_a 0.906, accuracy_b 0.969
2022-05-30 01:38:54 - INFO - Epoch 6 step 17640 eta 06:23:23: loss_a 0.110, un_loss_a 0.670, loss_b 0.149, un_loss_b 0.528, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 01:39:16 - INFO - Epoch 6 step 17660 eta 06:22:51: loss_a 0.106, un_loss_a 0.352, loss_b 0.225, un_loss_b 0.524, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 01:39:37 - INFO - Epoch 6 step 17680 eta 06:22:20: loss_a 0.156, un_loss_a 0.259, loss_b 0.450, un_loss_b 0.304, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 01:40:00 - INFO - Epoch 6 step 17700 eta 06:21:57: loss_a 0.297, un_loss_a 0.765, loss_b 0.343, un_loss_b 0.648, accuracy_a 0.844, accuracy_b 0.906
2022-05-30 01:40:22 - INFO - Epoch 6 step 17720 eta 06:21:26: loss_a 0.233, un_loss_a 0.433, loss_b 0.288, un_loss_b 0.697, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 01:40:45 - INFO - Epoch 6 step 17740 eta 06:21:04: loss_a 0.393, un_loss_a 0.276, loss_b 0.322, un_loss_b 0.199, accuracy_a 0.844, accuracy_b 0.906
2022-05-30 01:41:07 - INFO - Epoch 6 step 17760 eta 06:20:32: loss_a 0.406, un_loss_a 0.730, loss_b 0.430, un_loss_b 0.644, accuracy_a 0.875, accuracy_b 0.906
2022-05-30 01:41:28 - INFO - Epoch 6 step 17780 eta 06:20:01: loss_a 0.251, un_loss_a 0.414, loss_b 0.354, un_loss_b 0.411, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 01:41:51 - INFO - Epoch 6 step 17800 eta 06:19:39: loss_a 0.095, un_loss_a 0.243, loss_b 0.238, un_loss_b 0.195, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 01:42:13 - INFO - Epoch 6 step 17820 eta 06:19:07: loss_a 0.127, un_loss_a 0.406, loss_b 0.208, un_loss_b 0.317, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 01:42:36 - INFO - Epoch 6 step 17840 eta 06:18:46: loss_a 0.344, un_loss_a 0.346, loss_b 0.514, un_loss_b 0.350, accuracy_a 0.906, accuracy_b 0.812
2022-05-30 01:42:58 - INFO - Epoch 6 step 17860 eta 06:18:14: loss_a 0.138, un_loss_a 0.367, loss_b 0.304, un_loss_b 0.367, accuracy_a 0.969, accuracy_b 0.844
2022-05-30 01:43:21 - INFO - Epoch 6 step 17880 eta 06:17:52: loss_a 0.158, un_loss_a 0.498, loss_b 0.158, un_loss_b 0.550, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 01:43:42 - INFO - Epoch 6 step 17900 eta 06:17:20: loss_a 0.300, un_loss_a 0.781, loss_b 0.505, un_loss_b 0.414, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 01:44:04 - INFO - Epoch 6 step 17920 eta 06:16:49: loss_a 0.193, un_loss_a 0.193, loss_b 0.583, un_loss_b 0.244, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 01:44:27 - INFO - Epoch 6 step 17940 eta 06:16:27: loss_a 0.200, un_loss_a 0.265, loss_b 0.328, un_loss_b 0.137, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 01:44:48 - INFO - Epoch 6 step 17960 eta 06:15:56: loss_a 0.167, un_loss_a 0.753, loss_b 0.406, un_loss_b 0.498, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 01:45:12 - INFO - Epoch 6 step 17980 eta 06:15:34: loss_a 0.157, un_loss_a 0.637, loss_b 0.126, un_loss_b 0.818, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 01:45:33 - INFO - Epoch 6 step 18000 eta 06:15:03: loss_a 0.431, un_loss_a 0.952, loss_b 0.497, un_loss_b 0.874, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 01:45:55 - INFO - Epoch 6 step 18020 eta 06:14:31: loss_a 0.430, un_loss_a 0.410, loss_b 0.658, un_loss_b 0.464, accuracy_a 0.938, accuracy_b 0.719
2022-05-30 01:46:18 - INFO - Epoch 6 step 18040 eta 06:14:09: loss_a 0.452, un_loss_a 0.719, loss_b 0.467, un_loss_b 0.689, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 01:46:39 - INFO - Epoch 6 step 18060 eta 06:13:38: loss_a 0.344, un_loss_a 0.276, loss_b 0.394, un_loss_b 0.471, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:47:01 - INFO - Epoch 6 step 18080 eta 06:13:07: loss_a 0.215, un_loss_a 0.510, loss_b 0.236, un_loss_b 0.521, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 01:47:24 - INFO - Epoch 6 step 18100 eta 06:12:45: loss_a 0.303, un_loss_a 0.539, loss_b 0.418, un_loss_b 0.593, accuracy_a 0.875, accuracy_b 0.844
2022-05-30 01:47:46 - INFO - Epoch 6 step 18120 eta 06:12:14: loss_a 0.223, un_loss_a 1.093, loss_b 0.284, un_loss_b 1.125, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:48:07 - INFO - Epoch 6 step 18140 eta 06:11:42: loss_a 0.398, un_loss_a 0.453, loss_b 0.519, un_loss_b 0.311, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 01:48:30 - INFO - Epoch 6 step 18160 eta 06:11:21: loss_a 0.323, un_loss_a 0.332, loss_b 0.426, un_loss_b 0.375, accuracy_a 0.906, accuracy_b 0.781
2022-05-30 01:48:52 - INFO - Epoch 6 step 18180 eta 06:10:50: loss_a 0.355, un_loss_a 0.482, loss_b 0.292, un_loss_b 0.470, accuracy_a 0.875, accuracy_b 0.906
2022-05-30 01:49:16 - INFO - Epoch 6 step 18200 eta 06:10:30: loss_a 0.178, un_loss_a 0.412, loss_b 0.254, un_loss_b 0.378, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 01:49:37 - INFO - Epoch 6 step 18220 eta 06:09:59: loss_a 0.123, un_loss_a 0.749, loss_b 0.191, un_loss_b 0.741, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 01:49:59 - INFO - Epoch 6 step 18240 eta 06:09:28: loss_a 0.407, un_loss_a 0.497, loss_b 0.436, un_loss_b 0.506, accuracy_a 0.875, accuracy_b 0.906
2022-05-30 01:50:22 - INFO - Epoch 6 step 18260 eta 06:09:06: loss_a 0.104, un_loss_a 0.715, loss_b 0.233, un_loss_b 1.025, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 01:50:43 - INFO - Epoch 6 step 18280 eta 06:08:35: loss_a 0.138, un_loss_a 0.569, loss_b 0.176, un_loss_b 0.385, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:51:07 - INFO - Epoch 6 step 18300 eta 06:08:13: loss_a 0.542, un_loss_a 0.744, loss_b 0.628, un_loss_b 0.441, accuracy_a 0.906, accuracy_b 0.781
2022-05-30 01:51:28 - INFO - Epoch 6 step 18320 eta 06:07:42: loss_a 0.368, un_loss_a 0.946, loss_b 0.321, un_loss_b 0.623, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 01:51:50 - INFO - Epoch 6 step 18340 eta 06:07:11: loss_a 0.328, un_loss_a 0.545, loss_b 0.493, un_loss_b 0.815, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 01:52:13 - INFO - Epoch 6 step 18360 eta 06:06:50: loss_a 0.307, un_loss_a 0.533, loss_b 0.343, un_loss_b 0.485, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:52:34 - INFO - Epoch 6 step 18380 eta 06:06:18: loss_a 0.207, un_loss_a 0.406, loss_b 0.252, un_loss_b 0.394, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:52:58 - INFO - Epoch 6 step 18400 eta 06:05:57: loss_a 0.259, un_loss_a 0.145, loss_b 0.433, un_loss_b 0.206, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:53:19 - INFO - Epoch 6 step 18420 eta 06:05:26: loss_a 0.194, un_loss_a 0.635, loss_b 0.262, un_loss_b 0.502, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:53:41 - INFO - Epoch 6 step 18440 eta 06:04:54: loss_a 0.350, un_loss_a 0.427, loss_b 0.491, un_loss_b 0.586, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 01:54:04 - INFO - Epoch 6 step 18460 eta 06:04:32: loss_a 0.182, un_loss_a 0.373, loss_b 0.432, un_loss_b 0.324, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 01:54:25 - INFO - Epoch 6 step 18480 eta 06:04:01: loss_a 0.387, un_loss_a 0.435, loss_b 0.550, un_loss_b 0.365, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 01:54:49 - INFO - Epoch 6 step 18500 eta 06:03:40: loss_a 0.332, un_loss_a 0.292, loss_b 0.312, un_loss_b 0.597, accuracy_a 0.875, accuracy_b 0.938
2022-05-30 01:55:10 - INFO - Epoch 6 step 18520 eta 06:03:08: loss_a 0.329, un_loss_a 0.431, loss_b 0.563, un_loss_b 0.599, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 01:55:33 - INFO - Epoch 6 step 18540 eta 06:02:46: loss_a 0.178, un_loss_a 0.595, loss_b 0.454, un_loss_b 0.373, accuracy_a 0.969, accuracy_b 0.844
2022-05-30 01:55:55 - INFO - Epoch 6 step 18560 eta 06:02:15: loss_a 0.168, un_loss_a 0.557, loss_b 0.374, un_loss_b 0.465, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 01:56:18 - INFO - Epoch 6 step 18580 eta 06:01:56: loss_a 0.172, un_loss_a 0.518, loss_b 0.265, un_loss_b 0.298, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 01:56:40 - INFO - Epoch 6 step 18600 eta 06:01:25: loss_a 0.288, un_loss_a 1.288, loss_b 0.434, un_loss_b 0.713, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 01:57:01 - INFO - Epoch 6 step 18620 eta 06:00:54: loss_a 0.298, un_loss_a 0.443, loss_b 0.273, un_loss_b 0.528, accuracy_a 0.906, accuracy_b 0.969
2022-05-30 01:57:25 - INFO - Epoch 6 step 18640 eta 06:00:34: loss_a 0.446, un_loss_a 0.329, loss_b 0.434, un_loss_b 0.374, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 01:57:46 - INFO - Epoch 6 step 18660 eta 06:00:03: loss_a 0.141, un_loss_a 0.455, loss_b 0.399, un_loss_b 0.207, accuracy_a 0.969, accuracy_b 0.844
2022-05-30 01:58:08 - INFO - Epoch 6 step 18680 eta 05:59:32: loss_a 0.284, un_loss_a 0.624, loss_b 0.328, un_loss_b 0.694, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 01:58:31 - INFO - Epoch 6 step 18700 eta 05:59:10: loss_a 0.280, un_loss_a 0.469, loss_b 0.337, un_loss_b 0.757, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 01:58:52 - INFO - Epoch 6 step 18720 eta 05:58:39: loss_a 0.172, un_loss_a 0.558, loss_b 0.141, un_loss_b 0.521, accuracy_a 0.938, accuracy_b 1.000
2022-05-30 01:59:14 - INFO - Epoch 6 step 18740 eta 05:58:08: loss_a 0.191, un_loss_a 0.418, loss_b 0.262, un_loss_b 0.507, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 01:59:37 - INFO - Epoch 6 step 18760 eta 05:57:47: loss_a 0.172, un_loss_a 0.563, loss_b 0.149, un_loss_b 0.432, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 01:59:59 - INFO - Epoch 6 step 18780 eta 05:57:16: loss_a 0.185, un_loss_a 0.519, loss_b 0.230, un_loss_b 0.244, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 02:00:22 - INFO - Epoch 6 step 18800 eta 05:56:55: loss_a 0.418, un_loss_a 0.750, loss_b 0.348, un_loss_b 0.678, accuracy_a 0.844, accuracy_b 0.938
2022-05-30 02:00:44 - INFO - Epoch 6 step 18820 eta 05:56:24: loss_a 0.107, un_loss_a 0.500, loss_b 0.144, un_loss_b 0.762, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:01:05 - INFO - Epoch 6 step 18840 eta 05:55:54: loss_a 0.123, un_loss_a 0.388, loss_b 0.221, un_loss_b 0.917, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:01:28 - INFO - Epoch 6 step 18860 eta 05:55:32: loss_a 0.297, un_loss_a 0.540, loss_b 0.384, un_loss_b 0.623, accuracy_a 0.875, accuracy_b 0.906
2022-05-30 02:01:50 - INFO - Epoch 6 step 18880 eta 05:55:01: loss_a 0.348, un_loss_a 0.178, loss_b 0.350, un_loss_b 0.335, accuracy_a 0.875, accuracy_b 0.938
2022-05-30 02:02:11 - INFO - Epoch 6 step 18900 eta 05:54:31: loss_a 0.315, un_loss_a 0.318, loss_b 0.656, un_loss_b 0.266, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 02:02:35 - INFO - Epoch 6 step 18920 eta 05:54:09: loss_a 0.411, un_loss_a 0.261, loss_b 0.449, un_loss_b 0.334, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 02:02:56 - INFO - Epoch 6 step 18940 eta 05:53:38: loss_a 0.137, un_loss_a 0.520, loss_b 0.106, un_loss_b 0.454, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 02:03:19 - INFO - Epoch 6 step 18960 eta 05:53:16: loss_a 0.255, un_loss_a 0.634, loss_b 0.323, un_loss_b 0.475, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 02:03:41 - INFO - Epoch 6 step 18980 eta 05:52:46: loss_a 0.239, un_loss_a 0.363, loss_b 0.498, un_loss_b 0.458, accuracy_a 0.875, accuracy_b 0.938
2022-05-30 02:04:02 - INFO - Epoch 6 step 19000 eta 05:52:15: loss_a 0.210, un_loss_a 0.478, loss_b 0.189, un_loss_b 0.658, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 02:04:25 - INFO - Epoch 6 step 19020 eta 05:51:53: loss_a 0.282, un_loss_a 0.578, loss_b 0.201, un_loss_b 0.670, accuracy_a 0.875, accuracy_b 0.969
2022-05-30 02:04:47 - INFO - Epoch 6 step 19040 eta 05:51:23: loss_a 0.287, un_loss_a 0.643, loss_b 0.462, un_loss_b 0.622, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 02:05:10 - INFO - Epoch 6 step 19060 eta 05:51:01: loss_a 0.296, un_loss_a 0.365, loss_b 0.481, un_loss_b 0.401, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 02:05:32 - INFO - Epoch 6 step 19080 eta 05:50:30: loss_a 0.366, un_loss_a 0.486, loss_b 0.654, un_loss_b 0.512, accuracy_a 0.812, accuracy_b 0.844
2022-05-30 02:05:55 - INFO - Epoch 6 step 19100 eta 05:50:08: loss_a 0.295, un_loss_a 0.422, loss_b 0.235, un_loss_b 0.604, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 02:06:16 - INFO - Epoch 6 step 19120 eta 05:49:38: loss_a 0.169, un_loss_a 0.377, loss_b 0.075, un_loss_b 0.555, accuracy_a 0.938, accuracy_b 1.000
2022-05-30 02:06:38 - INFO - Epoch 6 step 19140 eta 05:49:07: loss_a 0.126, un_loss_a 0.704, loss_b 0.204, un_loss_b 0.808, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 02:07:01 - INFO - Epoch 6 step 19160 eta 05:48:45: loss_a 0.259, un_loss_a 0.499, loss_b 0.285, un_loss_b 0.557, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 02:07:22 - INFO - Epoch 6 step 19180 eta 05:48:15: loss_a 0.278, un_loss_a 0.612, loss_b 0.281, un_loss_b 0.573, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 02:07:46 - INFO - Epoch 6 step 19200 eta 05:47:52: loss_a 0.134, un_loss_a 0.409, loss_b 0.190, un_loss_b 0.417, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 02:08:07 - INFO - Epoch 6 step 19220 eta 05:47:22: loss_a 0.345, un_loss_a 0.419, loss_b 0.303, un_loss_b 0.444, accuracy_a 0.844, accuracy_b 0.875
2022-05-30 02:08:30 - INFO - Epoch 6 step 19240 eta 05:47:00: loss_a 0.385, un_loss_a 0.716, loss_b 0.365, un_loss_b 0.401, accuracy_a 0.844, accuracy_b 0.906
2022-05-30 02:08:52 - INFO - Epoch 6 step 19260 eta 05:46:30: loss_a 0.294, un_loss_a 1.072, loss_b 0.311, un_loss_b 0.658, accuracy_a 0.844, accuracy_b 0.906
2022-05-30 02:09:13 - INFO - Epoch 6 step 19280 eta 05:45:59: loss_a 0.346, un_loss_a 0.337, loss_b 0.349, un_loss_b 0.326, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 02:09:36 - INFO - Epoch 6 step 19300 eta 05:45:37: loss_a 0.137, un_loss_a 0.490, loss_b 0.387, un_loss_b 0.230, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 02:09:58 - INFO - Epoch 6 step 19320 eta 05:45:07: loss_a 0.440, un_loss_a 0.215, loss_b 0.528, un_loss_b 0.490, accuracy_a 0.844, accuracy_b 0.781
2022-05-30 02:10:19 - INFO - Epoch 6 step 19340 eta 05:44:36: loss_a 0.224, un_loss_a 0.653, loss_b 0.326, un_loss_b 0.609, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 02:10:42 - INFO - Epoch 6 step 19360 eta 05:44:14: loss_a 0.301, un_loss_a 0.698, loss_b 0.279, un_loss_b 0.390, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 02:11:04 - INFO - Epoch 6 step 19380 eta 05:43:44: loss_a 0.436, un_loss_a 0.582, loss_b 0.447, un_loss_b 0.628, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 02:11:25 - INFO - Epoch 6 step 19400 eta 05:43:14: loss_a 0.162, un_loss_a 0.597, loss_b 0.177, un_loss_b 0.453, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 02:11:49 - INFO - Epoch 6 step 19420 eta 05:42:52: loss_a 0.142, un_loss_a 0.531, loss_b 0.119, un_loss_b 0.521, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 02:12:10 - INFO - Epoch 6 step 19440 eta 05:42:22: loss_a 0.246, un_loss_a 0.326, loss_b 0.301, un_loss_b 0.464, accuracy_a 0.844, accuracy_b 0.938
2022-05-30 02:12:33 - INFO - Epoch 6 step 19460 eta 05:41:59: loss_a 0.246, un_loss_a 0.586, loss_b 0.229, un_loss_b 0.718, accuracy_a 0.906, accuracy_b 0.969
2022-05-30 02:12:55 - INFO - Epoch 6 step 19480 eta 05:41:29: loss_a 0.252, un_loss_a 0.696, loss_b 0.436, un_loss_b 1.002, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 02:13:16 - INFO - Epoch 6 step 19500 eta 05:40:59: loss_a 0.179, un_loss_a 0.538, loss_b 0.450, un_loss_b 0.257, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 02:13:40 - INFO - Epoch 6 step 19520 eta 05:40:39: loss_a 0.235, un_loss_a 0.551, loss_b 0.434, un_loss_b 0.350, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 02:14:01 - INFO - Epoch 6 step 19540 eta 05:40:09: loss_a 0.143, un_loss_a 0.424, loss_b 0.368, un_loss_b 0.500, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 02:14:25 - INFO - Epoch 6 step 19560 eta 05:39:49: loss_a 0.189, un_loss_a 0.529, loss_b 0.282, un_loss_b 0.718, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 02:14:46 - INFO - Epoch 6 step 19580 eta 05:39:19: loss_a 0.231, un_loss_a 0.271, loss_b 0.449, un_loss_b 0.347, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 02:15:08 - INFO - Epoch 6 step 19600 eta 05:38:49: loss_a 0.194, un_loss_a 0.354, loss_b 0.233, un_loss_b 0.533, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:15:31 - INFO - Epoch 6 step 19620 eta 05:38:27: loss_a 0.524, un_loss_a 0.248, loss_b 0.327, un_loss_b 0.232, accuracy_a 0.781, accuracy_b 0.906
2022-05-30 02:15:53 - INFO - Epoch 6 step 19640 eta 05:37:57: loss_a 0.297, un_loss_a 0.658, loss_b 0.367, un_loss_b 0.402, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 02:16:16 - INFO - Epoch 6 step 19660 eta 05:37:36: loss_a 0.471, un_loss_a 0.563, loss_b 0.468, un_loss_b 0.467, accuracy_a 0.812, accuracy_b 0.844
2022-05-30 02:16:37 - INFO - Epoch 6 step 19680 eta 05:37:06: loss_a 0.182, un_loss_a 0.461, loss_b 0.167, un_loss_b 0.544, accuracy_a 0.969, accuracy_b 0.938
Begin Validation
2022-05-30 02:18:45 - INFO - Epoch 6 step 19684:, {'lv1_acc': 0.7747, 'lv2_acc': 0.6657, 'lv1_f1_micro': 0.7747, 'lv1_f1_macro': 0.7392, 'lv2_f1_micro': 0.6657, 'lv2_f1_macro': 0.5387, 'mean_f1': 0.6796}, {'lv1_acc': 0.7754, 'lv2_acc': 0.6688, 'lv1_f1_micro': 0.7754, 'lv1_f1_macro': 0.7462, 'lv2_f1_micro': 0.6688, 'lv2_f1_macro': 0.5515, 'mean_f1': 0.6855}
/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-05-30 02:19:06 - INFO - Epoch 7 step 19700 eta 05:46:32: loss_a 0.127, un_loss_a 0.265, loss_b 0.152, un_loss_b 0.279, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 02:19:29 - INFO - Epoch 7 step 19720 eta 05:46:11: loss_a 0.227, un_loss_a 0.583, loss_b 0.395, un_loss_b 0.383, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 02:19:51 - INFO - Epoch 7 step 19740 eta 05:45:41: loss_a 0.295, un_loss_a 0.602, loss_b 0.238, un_loss_b 0.750, accuracy_a 0.875, accuracy_b 0.938
2022-05-30 02:20:14 - INFO - Epoch 7 step 19760 eta 05:45:18: loss_a 0.217, un_loss_a 0.629, loss_b 0.353, un_loss_b 0.748, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 02:20:35 - INFO - Epoch 7 step 19780 eta 05:44:48: loss_a 0.133, un_loss_a 0.415, loss_b 0.171, un_loss_b 0.281, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 02:20:57 - INFO - Epoch 7 step 19800 eta 05:44:17: loss_a 0.054, un_loss_a 0.411, loss_b 0.049, un_loss_b 0.351, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 02:21:20 - INFO - Epoch 7 step 19820 eta 05:43:55: loss_a 0.149, un_loss_a 0.479, loss_b 0.350, un_loss_b 0.712, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 02:21:42 - INFO - Epoch 7 step 19840 eta 05:43:24: loss_a 0.209, un_loss_a 0.589, loss_b 0.356, un_loss_b 0.564, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 02:22:05 - INFO - Epoch 7 step 19860 eta 05:43:02: loss_a 0.268, un_loss_a 0.556, loss_b 0.199, un_loss_b 0.688, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 02:22:27 - INFO - Epoch 7 step 19880 eta 05:42:32: loss_a 0.246, un_loss_a 0.354, loss_b 0.161, un_loss_b 0.421, accuracy_a 0.875, accuracy_b 0.938
2022-05-30 02:22:48 - INFO - Epoch 7 step 19900 eta 05:42:01: loss_a 0.106, un_loss_a 0.442, loss_b 0.084, un_loss_b 0.387, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 02:23:11 - INFO - Epoch 7 step 19920 eta 05:41:39: loss_a 0.247, un_loss_a 0.640, loss_b 0.189, un_loss_b 0.661, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 02:23:33 - INFO - Epoch 7 step 19940 eta 05:41:08: loss_a 0.048, un_loss_a 0.539, loss_b 0.037, un_loss_b 0.473, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 02:23:56 - INFO - Epoch 7 step 19960 eta 05:40:46: loss_a 0.376, un_loss_a 0.589, loss_b 0.297, un_loss_b 0.586, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 02:24:18 - INFO - Epoch 7 step 19980 eta 05:40:15: loss_a 0.238, un_loss_a 0.846, loss_b 0.216, un_loss_b 0.701, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 02:24:41 - INFO - Epoch 7 step 20000 eta 05:39:53: loss_a 0.115, un_loss_a 0.144, loss_b 0.266, un_loss_b 0.106, accuracy_a 0.969, accuracy_b 0.844
2022-05-30 02:25:02 - INFO - Epoch 7 step 20020 eta 05:39:23: loss_a 0.083, un_loss_a 0.687, loss_b 0.143, un_loss_b 0.647, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 02:25:24 - INFO - Epoch 7 step 20040 eta 05:38:52: loss_a 0.028, un_loss_a 0.514, loss_b 0.110, un_loss_b 0.760, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 02:25:47 - INFO - Epoch 7 step 20060 eta 05:38:30: loss_a 0.252, un_loss_a 0.392, loss_b 0.231, un_loss_b 0.395, accuracy_a 0.875, accuracy_b 0.906
2022-05-30 02:26:09 - INFO - Epoch 7 step 20080 eta 05:37:59: loss_a 0.202, un_loss_a 0.552, loss_b 0.175, un_loss_b 0.543, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 02:26:32 - INFO - Epoch 7 step 20100 eta 05:37:38: loss_a 0.141, un_loss_a 0.355, loss_b 0.204, un_loss_b 0.607, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:26:53 - INFO - Epoch 7 step 20120 eta 05:37:07: loss_a 0.057, un_loss_a 0.584, loss_b 0.182, un_loss_b 0.307, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 02:27:15 - INFO - Epoch 7 step 20140 eta 05:36:37: loss_a 0.101, un_loss_a 0.518, loss_b 0.138, un_loss_b 0.627, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 02:27:38 - INFO - Epoch 7 step 20160 eta 05:36:15: loss_a 0.182, un_loss_a 0.744, loss_b 0.313, un_loss_b 0.699, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 02:28:00 - INFO - Epoch 7 step 20180 eta 05:35:44: loss_a 0.225, un_loss_a 0.505, loss_b 0.384, un_loss_b 0.526, accuracy_a 0.969, accuracy_b 0.812
2022-05-30 02:28:21 - INFO - Epoch 7 step 20200 eta 05:35:14: loss_a 0.261, un_loss_a 0.522, loss_b 0.387, un_loss_b 0.480, accuracy_a 0.844, accuracy_b 0.906
2022-05-30 02:28:45 - INFO - Epoch 7 step 20220 eta 05:34:51: loss_a 0.330, un_loss_a 0.488, loss_b 0.211, un_loss_b 0.801, accuracy_a 0.844, accuracy_b 0.938
2022-05-30 02:29:06 - INFO - Epoch 7 step 20240 eta 05:34:21: loss_a 0.280, un_loss_a 0.607, loss_b 0.202, un_loss_b 0.594, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 02:29:27 - INFO - Epoch 7 step 20260 eta 05:33:51: loss_a 0.206, un_loss_a 0.536, loss_b 0.233, un_loss_b 0.405, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 02:29:51 - INFO - Epoch 7 step 20280 eta 05:33:29: loss_a 0.143, un_loss_a 0.250, loss_b 0.143, un_loss_b 0.290, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 02:30:12 - INFO - Epoch 7 step 20300 eta 05:32:58: loss_a 0.212, un_loss_a 0.687, loss_b 0.314, un_loss_b 0.833, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 02:30:36 - INFO - Epoch 7 step 20320 eta 05:32:36: loss_a 0.137, un_loss_a 0.707, loss_b 0.114, un_loss_b 0.406, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 02:30:57 - INFO - Epoch 7 step 20340 eta 05:32:06: loss_a 0.090, un_loss_a 0.413, loss_b 0.265, un_loss_b 0.813, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 02:31:19 - INFO - Epoch 7 step 20360 eta 05:31:36: loss_a 0.213, un_loss_a 0.565, loss_b 0.348, un_loss_b 0.654, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 02:31:42 - INFO - Epoch 7 step 20380 eta 05:31:13: loss_a 0.148, un_loss_a 0.382, loss_b 0.362, un_loss_b 0.578, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 02:32:03 - INFO - Epoch 7 step 20400 eta 05:30:43: loss_a 0.308, un_loss_a 0.549, loss_b 0.406, un_loss_b 0.277, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 02:32:27 - INFO - Epoch 7 step 20420 eta 05:30:21: loss_a 0.184, un_loss_a 0.420, loss_b 0.200, un_loss_b 0.443, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 02:32:48 - INFO - Epoch 7 step 20440 eta 05:29:51: loss_a 0.397, un_loss_a 0.573, loss_b 0.655, un_loss_b 0.754, accuracy_a 0.875, accuracy_b 0.844
2022-05-30 02:33:10 - INFO - Epoch 7 step 20460 eta 05:29:21: loss_a 0.164, un_loss_a 0.241, loss_b 0.201, un_loss_b 0.340, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:33:33 - INFO - Epoch 7 step 20480 eta 05:28:59: loss_a 0.144, un_loss_a 0.536, loss_b 0.219, un_loss_b 0.664, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 02:33:54 - INFO - Epoch 7 step 20500 eta 05:28:28: loss_a 0.087, un_loss_a 0.796, loss_b 0.086, un_loss_b 0.537, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 02:34:18 - INFO - Epoch 7 step 20520 eta 05:28:06: loss_a 0.132, un_loss_a 0.740, loss_b 0.219, un_loss_b 0.580, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:34:39 - INFO - Epoch 7 step 20540 eta 05:27:36: loss_a 0.072, un_loss_a 0.656, loss_b 0.058, un_loss_b 0.423, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 02:35:01 - INFO - Epoch 7 step 20560 eta 05:27:06: loss_a 0.150, un_loss_a 0.414, loss_b 0.138, un_loss_b 0.295, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 02:35:24 - INFO - Epoch 7 step 20580 eta 05:26:44: loss_a 0.075, un_loss_a 0.436, loss_b 0.154, un_loss_b 0.491, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 02:35:45 - INFO - Epoch 7 step 20600 eta 05:26:14: loss_a 0.385, un_loss_a 0.586, loss_b 0.492, un_loss_b 0.487, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 02:36:09 - INFO - Epoch 7 step 20620 eta 05:25:52: loss_a 0.177, un_loss_a 0.330, loss_b 0.181, un_loss_b 0.430, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 02:36:30 - INFO - Epoch 7 step 20640 eta 05:25:22: loss_a 0.289, un_loss_a 0.538, loss_b 0.218, un_loss_b 0.664, accuracy_a 0.875, accuracy_b 0.938
2022-05-30 02:36:54 - INFO - Epoch 7 step 20660 eta 05:25:00: loss_a 0.109, un_loss_a 0.408, loss_b 0.142, un_loss_b 0.317, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 02:37:15 - INFO - Epoch 7 step 20680 eta 05:24:30: loss_a 0.083, un_loss_a 0.948, loss_b 0.142, un_loss_b 0.709, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 02:37:38 - INFO - Epoch 7 step 20700 eta 05:24:08: loss_a 0.494, un_loss_a 0.476, loss_b 0.300, un_loss_b 0.588, accuracy_a 0.875, accuracy_b 0.906
2022-05-30 02:38:00 - INFO - Epoch 7 step 20720 eta 05:23:38: loss_a 0.065, un_loss_a 0.763, loss_b 0.113, un_loss_b 1.121, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 02:38:21 - INFO - Epoch 7 step 20740 eta 05:23:07: loss_a 0.081, un_loss_a 0.408, loss_b 0.176, un_loss_b 0.311, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 02:38:45 - INFO - Epoch 7 step 20760 eta 05:22:46: loss_a 0.178, un_loss_a 0.448, loss_b 0.210, un_loss_b 0.296, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 02:39:06 - INFO - Epoch 7 step 20780 eta 05:22:15: loss_a 0.088, un_loss_a 0.275, loss_b 0.178, un_loss_b 0.396, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:39:28 - INFO - Epoch 7 step 20800 eta 05:21:45: loss_a 0.103, un_loss_a 0.624, loss_b 0.122, un_loss_b 0.582, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 02:39:51 - INFO - Epoch 7 step 20820 eta 05:21:23: loss_a 0.404, un_loss_a 0.315, loss_b 0.385, un_loss_b 0.431, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 02:40:12 - INFO - Epoch 7 step 20840 eta 05:20:53: loss_a 0.240, un_loss_a 0.505, loss_b 0.367, un_loss_b 0.435, accuracy_a 0.906, accuracy_b 0.969
2022-05-30 02:40:34 - INFO - Epoch 7 step 20860 eta 05:20:23: loss_a 0.096, un_loss_a 0.476, loss_b 0.253, un_loss_b 0.441, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:40:57 - INFO - Epoch 7 step 20880 eta 05:20:01: loss_a 0.381, un_loss_a 0.894, loss_b 0.728, un_loss_b 0.855, accuracy_a 0.938, accuracy_b 0.781
2022-05-30 02:41:18 - INFO - Epoch 7 step 20900 eta 05:19:31: loss_a 0.232, un_loss_a 0.283, loss_b 0.306, un_loss_b 0.278, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 02:41:42 - INFO - Epoch 7 step 20920 eta 05:19:09: loss_a 0.233, un_loss_a 0.557, loss_b 0.204, un_loss_b 0.601, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 02:42:03 - INFO - Epoch 7 step 20940 eta 05:18:39: loss_a 0.296, un_loss_a 0.276, loss_b 0.490, un_loss_b 0.250, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 02:42:25 - INFO - Epoch 7 step 20960 eta 05:18:09: loss_a 0.110, un_loss_a 0.285, loss_b 0.175, un_loss_b 0.509, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:42:48 - INFO - Epoch 7 step 20980 eta 05:17:47: loss_a 0.219, un_loss_a 0.495, loss_b 0.155, un_loss_b 0.590, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 02:43:09 - INFO - Epoch 7 step 21000 eta 05:17:17: loss_a 0.143, un_loss_a 0.557, loss_b 0.218, un_loss_b 0.575, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:43:31 - INFO - Epoch 7 step 21020 eta 05:16:47: loss_a 0.116, un_loss_a 0.592, loss_b 0.237, un_loss_b 0.265, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 02:43:54 - INFO - Epoch 7 step 21040 eta 05:16:25: loss_a 0.222, un_loss_a 0.351, loss_b 0.289, un_loss_b 0.396, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 02:44:16 - INFO - Epoch 7 step 21060 eta 05:15:55: loss_a 0.153, un_loss_a 0.512, loss_b 0.260, un_loss_b 0.627, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 02:44:39 - INFO - Epoch 7 step 21080 eta 05:15:33: loss_a 0.204, un_loss_a 0.558, loss_b 0.289, un_loss_b 0.634, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 02:45:00 - INFO - Epoch 7 step 21100 eta 05:15:03: loss_a 0.262, un_loss_a 0.391, loss_b 0.194, un_loss_b 0.391, accuracy_a 0.906, accuracy_b 0.969
2022-05-30 02:45:22 - INFO - Epoch 7 step 21120 eta 05:14:33: loss_a 0.119, un_loss_a 0.331, loss_b 0.162, un_loss_b 0.394, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 02:45:45 - INFO - Epoch 7 step 21140 eta 05:14:12: loss_a 0.170, un_loss_a 0.279, loss_b 0.258, un_loss_b 0.264, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 02:46:07 - INFO - Epoch 7 step 21160 eta 05:13:42: loss_a 0.183, un_loss_a 0.516, loss_b 0.260, un_loss_b 0.523, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 02:46:30 - INFO - Epoch 7 step 21180 eta 05:13:20: loss_a 0.207, un_loss_a 0.778, loss_b 0.296, un_loss_b 0.597, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 02:46:52 - INFO - Epoch 7 step 21200 eta 05:12:50: loss_a 0.068, un_loss_a 0.393, loss_b 0.176, un_loss_b 0.603, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 02:47:15 - INFO - Epoch 7 step 21220 eta 05:12:29: loss_a 0.161, un_loss_a 0.362, loss_b 0.122, un_loss_b 0.258, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 02:47:37 - INFO - Epoch 7 step 21240 eta 05:11:59: loss_a 0.179, un_loss_a 0.434, loss_b 0.139, un_loss_b 0.379, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 02:47:58 - INFO - Epoch 7 step 21260 eta 05:11:30: loss_a 0.143, un_loss_a 0.379, loss_b 0.180, un_loss_b 0.441, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:48:22 - INFO - Epoch 7 step 21280 eta 05:11:09: loss_a 0.252, un_loss_a 0.617, loss_b 0.378, un_loss_b 0.526, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 02:48:43 - INFO - Epoch 7 step 21300 eta 05:10:39: loss_a 0.155, un_loss_a 0.678, loss_b 0.257, un_loss_b 0.588, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 02:49:06 - INFO - Epoch 7 step 21320 eta 05:10:17: loss_a 0.166, un_loss_a 0.254, loss_b 0.205, un_loss_b 0.469, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:49:28 - INFO - Epoch 7 step 21340 eta 05:09:47: loss_a 0.246, un_loss_a 0.280, loss_b 0.373, un_loss_b 0.320, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 02:49:51 - INFO - Epoch 7 step 21360 eta 05:09:25: loss_a 0.264, un_loss_a 0.576, loss_b 0.429, un_loss_b 0.403, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 02:50:12 - INFO - Epoch 7 step 21380 eta 05:08:55: loss_a 0.100, un_loss_a 0.474, loss_b 0.136, un_loss_b 0.332, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 02:50:34 - INFO - Epoch 7 step 21400 eta 05:08:25: loss_a 0.092, un_loss_a 0.465, loss_b 0.124, un_loss_b 0.642, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 02:50:57 - INFO - Epoch 7 step 21420 eta 05:08:03: loss_a 0.054, un_loss_a 0.500, loss_b 0.064, un_loss_b 0.396, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 02:51:19 - INFO - Epoch 7 step 21440 eta 05:07:34: loss_a 0.192, un_loss_a 0.422, loss_b 0.096, un_loss_b 0.592, accuracy_a 0.938, accuracy_b 1.000
2022-05-30 02:51:40 - INFO - Epoch 7 step 21460 eta 05:07:04: loss_a 0.173, un_loss_a 0.729, loss_b 0.209, un_loss_b 0.472, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 02:52:03 - INFO - Epoch 7 step 21480 eta 05:06:42: loss_a 0.221, un_loss_a 0.650, loss_b 0.286, un_loss_b 0.505, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 02:52:25 - INFO - Epoch 7 step 21500 eta 05:06:13: loss_a 0.196, un_loss_a 0.485, loss_b 0.366, un_loss_b 0.819, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 02:52:46 - INFO - Epoch 7 step 21520 eta 05:05:43: loss_a 0.117, un_loss_a 0.504, loss_b 0.159, un_loss_b 0.642, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 02:53:10 - INFO - Epoch 7 step 21540 eta 05:05:21: loss_a 0.137, un_loss_a 0.512, loss_b 0.230, un_loss_b 0.429, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:53:31 - INFO - Epoch 7 step 21560 eta 05:04:51: loss_a 0.110, un_loss_a 0.901, loss_b 0.226, un_loss_b 1.071, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 02:53:54 - INFO - Epoch 7 step 21580 eta 05:04:29: loss_a 0.257, un_loss_a 0.477, loss_b 0.349, un_loss_b 0.330, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 02:54:16 - INFO - Epoch 7 step 21600 eta 05:04:00: loss_a 0.107, un_loss_a 0.266, loss_b 0.199, un_loss_b 0.237, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 02:54:37 - INFO - Epoch 7 step 21620 eta 05:03:30: loss_a 0.157, un_loss_a 0.634, loss_b 0.166, un_loss_b 0.706, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:55:01 - INFO - Epoch 7 step 21640 eta 05:03:08: loss_a 0.206, un_loss_a 0.785, loss_b 0.289, un_loss_b 0.692, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 02:55:22 - INFO - Epoch 7 step 21660 eta 05:02:39: loss_a 0.214, un_loss_a 0.881, loss_b 0.350, un_loss_b 1.097, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 02:55:45 - INFO - Epoch 7 step 21680 eta 05:02:17: loss_a 0.250, un_loss_a 0.333, loss_b 0.358, un_loss_b 0.434, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 02:56:07 - INFO - Epoch 7 step 21700 eta 05:01:47: loss_a 0.066, un_loss_a 0.418, loss_b 0.187, un_loss_b 0.373, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 02:56:28 - INFO - Epoch 7 step 21720 eta 05:01:18: loss_a 0.079, un_loss_a 0.272, loss_b 0.188, un_loss_b 0.379, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 02:56:52 - INFO - Epoch 7 step 21740 eta 05:00:56: loss_a 0.132, un_loss_a 0.447, loss_b 0.238, un_loss_b 0.398, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 02:57:13 - INFO - Epoch 7 step 21760 eta 05:00:26: loss_a 0.333, un_loss_a 0.992, loss_b 0.277, un_loss_b 0.937, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 02:57:36 - INFO - Epoch 7 step 21780 eta 05:00:04: loss_a 0.069, un_loss_a 0.269, loss_b 0.178, un_loss_b 0.490, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 02:57:58 - INFO - Epoch 7 step 21800 eta 04:59:35: loss_a 0.202, un_loss_a 0.528, loss_b 0.234, un_loss_b 0.547, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 02:58:19 - INFO - Epoch 7 step 21820 eta 04:59:05: loss_a 0.229, un_loss_a 0.121, loss_b 0.278, un_loss_b 0.161, accuracy_a 0.844, accuracy_b 0.906
2022-05-30 02:58:43 - INFO - Epoch 7 step 21840 eta 04:58:43: loss_a 0.326, un_loss_a 0.372, loss_b 0.280, un_loss_b 0.565, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 02:59:04 - INFO - Epoch 7 step 21860 eta 04:58:14: loss_a 0.323, un_loss_a 0.579, loss_b 0.592, un_loss_b 0.575, accuracy_a 0.906, accuracy_b 0.812
2022-05-30 02:59:28 - INFO - Epoch 7 step 21880 eta 04:57:54: loss_a 0.102, un_loss_a 0.659, loss_b 0.147, un_loss_b 0.380, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 02:59:49 - INFO - Epoch 7 step 21900 eta 04:57:24: loss_a 0.328, un_loss_a 0.621, loss_b 0.482, un_loss_b 0.399, accuracy_a 0.875, accuracy_b 0.844
2022-05-30 03:00:11 - INFO - Epoch 7 step 21920 eta 04:56:55: loss_a 0.205, un_loss_a 0.513, loss_b 0.220, un_loss_b 0.620, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 03:00:34 - INFO - Epoch 7 step 21940 eta 04:56:34: loss_a 0.495, un_loss_a 0.498, loss_b 0.559, un_loss_b 0.300, accuracy_a 0.844, accuracy_b 0.844
2022-05-30 03:00:56 - INFO - Epoch 7 step 21960 eta 04:56:04: loss_a 0.184, un_loss_a 0.354, loss_b 0.183, un_loss_b 0.278, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:01:19 - INFO - Epoch 7 step 21980 eta 04:55:42: loss_a 0.092, un_loss_a 0.638, loss_b 0.241, un_loss_b 0.748, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:01:40 - INFO - Epoch 7 step 22000 eta 04:55:13: loss_a 0.066, un_loss_a 0.473, loss_b 0.119, un_loss_b 0.450, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 03:02:04 - INFO - Epoch 7 step 22020 eta 04:54:51: loss_a 0.257, un_loss_a 0.599, loss_b 0.296, un_loss_b 0.581, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 03:02:25 - INFO - Epoch 7 step 22040 eta 04:54:22: loss_a 0.368, un_loss_a 0.584, loss_b 0.427, un_loss_b 0.614, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 03:02:47 - INFO - Epoch 7 step 22060 eta 04:53:52: loss_a 0.326, un_loss_a 0.387, loss_b 0.311, un_loss_b 0.429, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:03:10 - INFO - Epoch 7 step 22080 eta 04:53:31: loss_a 0.135, un_loss_a 0.355, loss_b 0.180, un_loss_b 0.332, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 03:03:31 - INFO - Epoch 7 step 22100 eta 04:53:01: loss_a 0.072, un_loss_a 0.636, loss_b 0.113, un_loss_b 0.528, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:03:53 - INFO - Epoch 7 step 22120 eta 04:52:32: loss_a 0.026, un_loss_a 0.516, loss_b 0.165, un_loss_b 0.642, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 03:04:16 - INFO - Epoch 7 step 22140 eta 04:52:10: loss_a 0.096, un_loss_a 0.263, loss_b 0.157, un_loss_b 0.437, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:04:38 - INFO - Epoch 7 step 22160 eta 04:51:41: loss_a 0.240, un_loss_a 0.663, loss_b 0.389, un_loss_b 0.610, accuracy_a 0.938, accuracy_b 0.781
2022-05-30 03:05:01 - INFO - Epoch 7 step 22180 eta 04:51:19: loss_a 0.232, un_loss_a 0.361, loss_b 0.306, un_loss_b 0.524, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 03:05:22 - INFO - Epoch 7 step 22200 eta 04:50:49: loss_a 0.181, un_loss_a 0.433, loss_b 0.161, un_loss_b 0.512, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:05:44 - INFO - Epoch 7 step 22220 eta 04:50:20: loss_a 0.200, un_loss_a 0.487, loss_b 0.169, un_loss_b 0.620, accuracy_a 0.875, accuracy_b 0.938
2022-05-30 03:06:07 - INFO - Epoch 7 step 22240 eta 04:49:58: loss_a 0.195, un_loss_a 0.623, loss_b 0.400, un_loss_b 0.701, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 03:06:28 - INFO - Epoch 7 step 22260 eta 04:49:29: loss_a 0.395, un_loss_a 0.578, loss_b 0.527, un_loss_b 0.518, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 03:06:50 - INFO - Epoch 7 step 22280 eta 04:49:00: loss_a 0.384, un_loss_a 0.432, loss_b 0.408, un_loss_b 0.553, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 03:07:13 - INFO - Epoch 7 step 22300 eta 04:48:38: loss_a 0.091, un_loss_a 0.480, loss_b 0.255, un_loss_b 0.345, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 03:07:35 - INFO - Epoch 7 step 22320 eta 04:48:09: loss_a 0.185, un_loss_a 0.665, loss_b 0.298, un_loss_b 0.676, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 03:07:58 - INFO - Epoch 7 step 22340 eta 04:47:47: loss_a 0.109, un_loss_a 0.644, loss_b 0.169, un_loss_b 0.789, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 03:08:19 - INFO - Epoch 7 step 22360 eta 04:47:18: loss_a 0.336, un_loss_a 0.226, loss_b 0.360, un_loss_b 0.385, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 03:08:41 - INFO - Epoch 7 step 22380 eta 04:46:48: loss_a 0.444, un_loss_a 0.636, loss_b 0.490, un_loss_b 0.437, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 03:09:04 - INFO - Epoch 7 step 22400 eta 04:46:26: loss_a 0.304, un_loss_a 0.545, loss_b 0.370, un_loss_b 0.453, accuracy_a 0.906, accuracy_b 0.875
2022-05-30 03:09:26 - INFO - Epoch 7 step 22420 eta 04:45:57: loss_a 0.207, un_loss_a 0.472, loss_b 0.218, un_loss_b 0.593, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:09:49 - INFO - Epoch 7 step 22440 eta 04:45:35: loss_a 0.207, un_loss_a 0.276, loss_b 0.441, un_loss_b 0.134, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 03:10:10 - INFO - Epoch 7 step 22460 eta 04:45:06: loss_a 0.219, un_loss_a 0.504, loss_b 0.178, un_loss_b 0.430, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:10:32 - INFO - Epoch 7 step 22480 eta 04:44:37: loss_a 0.584, un_loss_a 0.617, loss_b 0.417, un_loss_b 0.434, accuracy_a 0.844, accuracy_b 0.875
Begin Validation
2022-05-30 03:12:54 - INFO - Epoch 7 step 22496:, {'lv1_acc': 0.7756, 'lv2_acc': 0.6659, 'lv1_f1_micro': 0.7756, 'lv1_f1_macro': 0.7419, 'lv2_f1_micro': 0.6659, 'lv2_f1_macro': 0.5414, 'mean_f1': 0.6812}, {'lv1_acc': 0.779, 'lv2_acc': 0.6683, 'lv1_f1_micro': 0.779, 'lv1_f1_macro': 0.7453, 'lv2_f1_micro': 0.6683, 'lv2_f1_macro': 0.5569, 'mean_f1': 0.6874}
/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-05-30 03:13:02 - INFO - Epoch 8 step 22500 eta 04:52:41: loss_a 0.080, un_loss_a 0.438, loss_b 0.170, un_loss_b 0.931, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:13:23 - INFO - Epoch 8 step 22520 eta 04:52:12: loss_a 0.196, un_loss_a 0.331, loss_b 0.073, un_loss_b 0.336, accuracy_a 0.938, accuracy_b 1.000
2022-05-30 03:13:47 - INFO - Epoch 8 step 22540 eta 04:51:50: loss_a 0.082, un_loss_a 0.366, loss_b 0.152, un_loss_b 0.302, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 03:14:08 - INFO - Epoch 8 step 22560 eta 04:51:20: loss_a 0.116, un_loss_a 0.773, loss_b 0.151, un_loss_b 0.777, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:14:29 - INFO - Epoch 8 step 22580 eta 04:50:51: loss_a 0.194, un_loss_a 0.328, loss_b 0.285, un_loss_b 0.560, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 03:14:53 - INFO - Epoch 8 step 22600 eta 04:50:30: loss_a 0.149, un_loss_a 0.422, loss_b 0.307, un_loss_b 0.355, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:15:15 - INFO - Epoch 8 step 22620 eta 04:50:00: loss_a 0.179, un_loss_a 0.435, loss_b 0.173, un_loss_b 0.518, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:15:38 - INFO - Epoch 8 step 22640 eta 04:49:37: loss_a 0.040, un_loss_a 0.222, loss_b 0.078, un_loss_b 0.397, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 03:15:59 - INFO - Epoch 8 step 22660 eta 04:49:07: loss_a 0.228, un_loss_a 0.634, loss_b 0.114, un_loss_b 0.421, accuracy_a 0.906, accuracy_b 0.969
2022-05-30 03:16:21 - INFO - Epoch 8 step 22680 eta 04:48:38: loss_a 0.139, un_loss_a 0.392, loss_b 0.343, un_loss_b 0.423, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 03:16:44 - INFO - Epoch 8 step 22700 eta 04:48:15: loss_a 0.182, un_loss_a 0.514, loss_b 0.208, un_loss_b 0.262, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 03:17:05 - INFO - Epoch 8 step 22720 eta 04:47:45: loss_a 0.060, un_loss_a 0.389, loss_b 0.154, un_loss_b 0.198, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 03:17:28 - INFO - Epoch 8 step 22740 eta 04:47:22: loss_a 0.093, un_loss_a 0.328, loss_b 0.199, un_loss_b 0.207, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 03:17:50 - INFO - Epoch 8 step 22760 eta 04:46:52: loss_a 0.054, un_loss_a 0.518, loss_b 0.083, un_loss_b 0.668, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:18:13 - INFO - Epoch 8 step 22780 eta 04:46:29: loss_a 0.069, un_loss_a 0.268, loss_b 0.279, un_loss_b 0.615, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 03:18:34 - INFO - Epoch 8 step 22800 eta 04:45:59: loss_a 0.069, un_loss_a 0.605, loss_b 0.070, un_loss_b 0.679, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 03:18:56 - INFO - Epoch 8 step 22820 eta 04:45:30: loss_a 0.115, un_loss_a 0.909, loss_b 0.238, un_loss_b 0.855, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 03:19:19 - INFO - Epoch 8 step 22840 eta 04:45:07: loss_a 0.062, un_loss_a 0.665, loss_b 0.257, un_loss_b 0.760, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 03:19:40 - INFO - Epoch 8 step 22860 eta 04:44:37: loss_a 0.199, un_loss_a 0.394, loss_b 0.210, un_loss_b 0.628, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:20:02 - INFO - Epoch 8 step 22880 eta 04:44:08: loss_a 0.051, un_loss_a 0.528, loss_b 0.090, un_loss_b 0.307, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 03:20:26 - INFO - Epoch 8 step 22900 eta 04:43:48: loss_a 0.111, un_loss_a 0.589, loss_b 0.281, un_loss_b 0.482, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 03:20:47 - INFO - Epoch 8 step 22920 eta 04:43:19: loss_a 0.144, un_loss_a 0.487, loss_b 0.288, un_loss_b 0.414, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 03:21:10 - INFO - Epoch 8 step 22940 eta 04:42:57: loss_a 0.164, un_loss_a 1.115, loss_b 0.311, un_loss_b 0.823, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 03:21:32 - INFO - Epoch 8 step 22960 eta 04:42:27: loss_a 0.112, un_loss_a 0.326, loss_b 0.269, un_loss_b 0.225, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:21:53 - INFO - Epoch 8 step 22980 eta 04:41:57: loss_a 0.213, un_loss_a 0.527, loss_b 0.248, un_loss_b 0.387, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 03:22:16 - INFO - Epoch 8 step 23000 eta 04:41:34: loss_a 0.128, un_loss_a 0.472, loss_b 0.173, un_loss_b 0.575, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:22:38 - INFO - Epoch 8 step 23020 eta 04:41:05: loss_a 0.141, un_loss_a 0.270, loss_b 0.200, un_loss_b 0.513, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:23:01 - INFO - Epoch 8 step 23040 eta 04:40:42: loss_a 0.074, un_loss_a 0.593, loss_b 0.109, un_loss_b 0.751, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 03:23:22 - INFO - Epoch 8 step 23060 eta 04:40:13: loss_a 0.251, un_loss_a 0.437, loss_b 0.316, un_loss_b 0.412, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 03:23:44 - INFO - Epoch 8 step 23080 eta 04:39:43: loss_a 0.065, un_loss_a 0.374, loss_b 0.090, un_loss_b 0.666, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 03:24:07 - INFO - Epoch 8 step 23100 eta 04:39:20: loss_a 0.207, un_loss_a 0.788, loss_b 0.260, un_loss_b 0.709, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 03:24:28 - INFO - Epoch 8 step 23120 eta 04:38:51: loss_a 0.120, un_loss_a 0.442, loss_b 0.133, un_loss_b 0.611, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 03:24:51 - INFO - Epoch 8 step 23140 eta 04:38:28: loss_a 0.173, un_loss_a 0.449, loss_b 0.330, un_loss_b 0.740, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 03:25:13 - INFO - Epoch 8 step 23160 eta 04:37:58: loss_a 0.261, un_loss_a 0.884, loss_b 0.254, un_loss_b 0.382, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 03:25:36 - INFO - Epoch 8 step 23180 eta 04:37:35: loss_a 0.172, un_loss_a 0.566, loss_b 0.135, un_loss_b 0.734, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:25:58 - INFO - Epoch 8 step 23200 eta 04:37:06: loss_a 0.081, un_loss_a 0.350, loss_b 0.117, un_loss_b 0.433, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 03:26:19 - INFO - Epoch 8 step 23220 eta 04:36:37: loss_a 0.139, un_loss_a 0.642, loss_b 0.314, un_loss_b 0.432, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 03:26:43 - INFO - Epoch 8 step 23240 eta 04:36:17: loss_a 0.140, un_loss_a 0.474, loss_b 0.219, un_loss_b 0.502, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:27:04 - INFO - Epoch 8 step 23260 eta 04:35:47: loss_a 0.059, un_loss_a 0.777, loss_b 0.088, un_loss_b 0.490, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 03:27:28 - INFO - Epoch 8 step 23280 eta 04:35:26: loss_a 0.218, un_loss_a 0.397, loss_b 0.208, un_loss_b 0.519, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 03:27:49 - INFO - Epoch 8 step 23300 eta 04:34:57: loss_a 0.114, un_loss_a 0.421, loss_b 0.205, un_loss_b 0.839, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:28:11 - INFO - Epoch 8 step 23320 eta 04:34:27: loss_a 0.138, un_loss_a 0.924, loss_b 0.134, un_loss_b 0.966, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:28:34 - INFO - Epoch 8 step 23340 eta 04:34:04: loss_a 0.070, un_loss_a 0.610, loss_b 0.117, un_loss_b 0.487, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 03:28:55 - INFO - Epoch 8 step 23360 eta 04:33:35: loss_a 0.126, un_loss_a 0.825, loss_b 0.417, un_loss_b 0.429, accuracy_a 0.969, accuracy_b 0.844
2022-05-30 03:29:17 - INFO - Epoch 8 step 23380 eta 04:33:06: loss_a 0.127, un_loss_a 0.619, loss_b 0.220, un_loss_b 0.661, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 03:29:40 - INFO - Epoch 8 step 23400 eta 04:32:43: loss_a 0.112, un_loss_a 0.393, loss_b 0.185, un_loss_b 0.380, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 03:30:01 - INFO - Epoch 8 step 23420 eta 04:32:14: loss_a 0.119, un_loss_a 0.523, loss_b 0.171, un_loss_b 0.594, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:30:24 - INFO - Epoch 8 step 23440 eta 04:31:50: loss_a 0.039, un_loss_a 0.417, loss_b 0.126, un_loss_b 0.370, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 03:30:46 - INFO - Epoch 8 step 23460 eta 04:31:21: loss_a 0.122, un_loss_a 0.562, loss_b 0.137, un_loss_b 0.395, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:31:07 - INFO - Epoch 8 step 23480 eta 04:30:52: loss_a 0.102, un_loss_a 0.652, loss_b 0.109, un_loss_b 0.473, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:31:30 - INFO - Epoch 8 step 23500 eta 04:30:29: loss_a 0.108, un_loss_a 0.557, loss_b 0.175, un_loss_b 0.281, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:31:52 - INFO - Epoch 8 step 23520 eta 04:30:00: loss_a 0.273, un_loss_a 0.605, loss_b 0.331, un_loss_b 0.370, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 03:32:13 - INFO - Epoch 8 step 23540 eta 04:29:30: loss_a 0.024, un_loss_a 0.980, loss_b 0.059, un_loss_b 0.635, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 03:32:36 - INFO - Epoch 8 step 23560 eta 04:29:08: loss_a 0.108, un_loss_a 0.706, loss_b 0.081, un_loss_b 0.501, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:32:58 - INFO - Epoch 8 step 23580 eta 04:28:38: loss_a 0.198, un_loss_a 0.731, loss_b 0.292, un_loss_b 0.632, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:33:21 - INFO - Epoch 8 step 23600 eta 04:28:16: loss_a 0.113, un_loss_a 0.780, loss_b 0.225, un_loss_b 0.796, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 03:33:42 - INFO - Epoch 8 step 23620 eta 04:27:46: loss_a 0.125, un_loss_a 0.323, loss_b 0.361, un_loss_b 0.355, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:34:04 - INFO - Epoch 8 step 23640 eta 04:27:17: loss_a 0.037, un_loss_a 0.568, loss_b 0.131, un_loss_b 0.620, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 03:34:27 - INFO - Epoch 8 step 23660 eta 04:26:54: loss_a 0.066, un_loss_a 0.287, loss_b 0.205, un_loss_b 0.395, accuracy_a 1.000, accuracy_b 0.875
2022-05-30 03:34:48 - INFO - Epoch 8 step 23680 eta 04:26:25: loss_a 0.195, un_loss_a 0.518, loss_b 0.341, un_loss_b 0.860, accuracy_a 0.969, accuracy_b 0.844
2022-05-30 03:35:11 - INFO - Epoch 8 step 23700 eta 04:26:02: loss_a 0.102, un_loss_a 0.572, loss_b 0.317, un_loss_b 0.369, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 03:35:33 - INFO - Epoch 8 step 23720 eta 04:25:33: loss_a 0.193, un_loss_a 0.419, loss_b 0.227, un_loss_b 0.284, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:35:54 - INFO - Epoch 8 step 23740 eta 04:25:04: loss_a 0.081, un_loss_a 0.719, loss_b 0.152, un_loss_b 0.557, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 03:36:17 - INFO - Epoch 8 step 23760 eta 04:24:41: loss_a 0.133, un_loss_a 0.359, loss_b 0.133, un_loss_b 0.369, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 03:36:39 - INFO - Epoch 8 step 23780 eta 04:24:12: loss_a 0.056, un_loss_a 0.580, loss_b 0.138, un_loss_b 0.600, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 03:37:03 - INFO - Epoch 8 step 23800 eta 04:23:52: loss_a 0.137, un_loss_a 0.658, loss_b 0.169, un_loss_b 0.590, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:37:24 - INFO - Epoch 8 step 23820 eta 04:23:23: loss_a 0.057, un_loss_a 0.419, loss_b 0.311, un_loss_b 0.534, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 03:37:47 - INFO - Epoch 8 step 23840 eta 04:23:01: loss_a 0.304, un_loss_a 0.301, loss_b 0.442, un_loss_b 0.287, accuracy_a 0.875, accuracy_b 0.906
2022-05-30 03:38:09 - INFO - Epoch 8 step 23860 eta 04:22:32: loss_a 0.079, un_loss_a 0.376, loss_b 0.094, un_loss_b 0.519, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:38:32 - INFO - Epoch 8 step 23880 eta 04:22:09: loss_a 0.112, un_loss_a 0.394, loss_b 0.209, un_loss_b 0.509, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 03:38:53 - INFO - Epoch 8 step 23900 eta 04:21:40: loss_a 0.153, un_loss_a 0.697, loss_b 0.214, un_loss_b 0.690, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:39:15 - INFO - Epoch 8 step 23920 eta 04:21:11: loss_a 0.085, un_loss_a 0.566, loss_b 0.113, un_loss_b 0.567, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 03:39:38 - INFO - Epoch 8 step 23940 eta 04:20:48: loss_a 0.109, un_loss_a 0.359, loss_b 0.211, un_loss_b 0.374, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:39:59 - INFO - Epoch 8 step 23960 eta 04:20:19: loss_a 0.129, un_loss_a 0.530, loss_b 0.210, un_loss_b 0.553, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:40:21 - INFO - Epoch 8 step 23980 eta 04:19:50: loss_a 0.214, un_loss_a 0.366, loss_b 0.111, un_loss_b 0.440, accuracy_a 0.906, accuracy_b 1.000
2022-05-30 03:40:44 - INFO - Epoch 8 step 24000 eta 04:19:28: loss_a 0.247, un_loss_a 0.881, loss_b 0.319, un_loss_b 0.610, accuracy_a 0.906, accuracy_b 0.844
2022-05-30 03:41:05 - INFO - Epoch 8 step 24020 eta 04:18:59: loss_a 0.109, un_loss_a 0.340, loss_b 0.331, un_loss_b 0.380, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 03:41:27 - INFO - Epoch 8 step 24040 eta 04:18:30: loss_a 0.128, un_loss_a 0.331, loss_b 0.185, un_loss_b 0.559, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:41:50 - INFO - Epoch 8 step 24060 eta 04:18:07: loss_a 0.073, un_loss_a 0.485, loss_b 0.106, un_loss_b 0.473, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:42:11 - INFO - Epoch 8 step 24080 eta 04:17:38: loss_a 0.195, un_loss_a 0.674, loss_b 0.236, un_loss_b 0.762, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:42:35 - INFO - Epoch 8 step 24100 eta 04:17:15: loss_a 0.306, un_loss_a 0.496, loss_b 0.184, un_loss_b 0.394, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 03:42:56 - INFO - Epoch 8 step 24120 eta 04:16:46: loss_a 0.192, un_loss_a 0.363, loss_b 0.171, un_loss_b 0.505, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 03:43:18 - INFO - Epoch 8 step 24140 eta 04:16:18: loss_a 0.163, un_loss_a 0.157, loss_b 0.238, un_loss_b 0.346, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:43:41 - INFO - Epoch 8 step 24160 eta 04:15:55: loss_a 0.215, un_loss_a 0.285, loss_b 0.254, un_loss_b 0.140, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 03:44:02 - INFO - Epoch 8 step 24180 eta 04:15:26: loss_a 0.121, un_loss_a 0.413, loss_b 0.137, un_loss_b 0.502, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:44:25 - INFO - Epoch 8 step 24200 eta 04:15:03: loss_a 0.038, un_loss_a 0.670, loss_b 0.084, un_loss_b 0.785, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 03:44:47 - INFO - Epoch 8 step 24220 eta 04:14:34: loss_a 0.221, un_loss_a 0.783, loss_b 0.297, un_loss_b 0.869, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 03:45:08 - INFO - Epoch 8 step 24240 eta 04:14:05: loss_a 0.195, un_loss_a 0.483, loss_b 0.119, un_loss_b 0.401, accuracy_a 0.906, accuracy_b 1.000
2022-05-30 03:45:31 - INFO - Epoch 8 step 24260 eta 04:13:43: loss_a 0.190, un_loss_a 0.273, loss_b 0.194, un_loss_b 0.354, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 03:45:53 - INFO - Epoch 8 step 24280 eta 04:13:14: loss_a 0.143, un_loss_a 0.170, loss_b 0.200, un_loss_b 0.111, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:46:16 - INFO - Epoch 8 step 24300 eta 04:12:51: loss_a 0.038, un_loss_a 0.401, loss_b 0.249, un_loss_b 0.661, accuracy_a 1.000, accuracy_b 0.875
2022-05-30 03:46:37 - INFO - Epoch 8 step 24320 eta 04:12:22: loss_a 0.277, un_loss_a 0.419, loss_b 0.408, un_loss_b 0.525, accuracy_a 0.906, accuracy_b 0.781
2022-05-30 03:46:59 - INFO - Epoch 8 step 24340 eta 04:11:54: loss_a 0.157, un_loss_a 0.319, loss_b 0.351, un_loss_b 0.459, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 03:47:22 - INFO - Epoch 8 step 24360 eta 04:11:30: loss_a 0.220, un_loss_a 0.452, loss_b 0.097, un_loss_b 0.462, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 03:47:43 - INFO - Epoch 8 step 24380 eta 04:11:02: loss_a 0.203, un_loss_a 0.755, loss_b 0.240, un_loss_b 0.735, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 03:48:06 - INFO - Epoch 8 step 24400 eta 04:10:39: loss_a 0.397, un_loss_a 0.331, loss_b 0.312, un_loss_b 0.307, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:48:28 - INFO - Epoch 8 step 24420 eta 04:10:10: loss_a 0.103, un_loss_a 0.359, loss_b 0.240, un_loss_b 0.266, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 03:48:49 - INFO - Epoch 8 step 24440 eta 04:09:42: loss_a 0.139, un_loss_a 0.209, loss_b 0.415, un_loss_b 0.261, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 03:49:12 - INFO - Epoch 8 step 24460 eta 04:09:19: loss_a 0.046, un_loss_a 0.723, loss_b 0.207, un_loss_b 0.626, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 03:49:34 - INFO - Epoch 8 step 24480 eta 04:08:50: loss_a 0.068, un_loss_a 0.315, loss_b 0.098, un_loss_b 0.314, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 03:49:57 - INFO - Epoch 8 step 24500 eta 04:08:27: loss_a 0.117, un_loss_a 0.918, loss_b 0.192, un_loss_b 0.780, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 03:50:18 - INFO - Epoch 8 step 24520 eta 04:07:58: loss_a 0.144, un_loss_a 0.640, loss_b 0.171, un_loss_b 0.524, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:50:41 - INFO - Epoch 8 step 24540 eta 04:07:36: loss_a 0.127, un_loss_a 0.496, loss_b 0.135, un_loss_b 0.649, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 03:51:03 - INFO - Epoch 8 step 24560 eta 04:07:07: loss_a 0.241, un_loss_a 0.394, loss_b 0.297, un_loss_b 0.602, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:51:24 - INFO - Epoch 8 step 24580 eta 04:06:38: loss_a 0.210, un_loss_a 0.569, loss_b 0.478, un_loss_b 0.556, accuracy_a 0.906, accuracy_b 0.812
2022-05-30 03:51:47 - INFO - Epoch 8 step 24600 eta 04:06:16: loss_a 0.104, un_loss_a 0.187, loss_b 0.319, un_loss_b 0.172, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 03:52:09 - INFO - Epoch 8 step 24620 eta 04:05:47: loss_a 0.068, un_loss_a 0.497, loss_b 0.111, un_loss_b 0.494, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:52:30 - INFO - Epoch 8 step 24640 eta 04:05:18: loss_a 0.181, un_loss_a 0.425, loss_b 0.342, un_loss_b 0.530, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 03:52:53 - INFO - Epoch 8 step 24660 eta 04:04:56: loss_a 0.205, un_loss_a 0.233, loss_b 0.381, un_loss_b 0.219, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 03:53:15 - INFO - Epoch 8 step 24680 eta 04:04:27: loss_a 0.144, un_loss_a 0.409, loss_b 0.238, un_loss_b 0.390, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 03:53:38 - INFO - Epoch 8 step 24700 eta 04:04:04: loss_a 0.249, un_loss_a 0.565, loss_b 0.454, un_loss_b 0.590, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 03:53:59 - INFO - Epoch 8 step 24720 eta 04:03:35: loss_a 0.098, un_loss_a 0.496, loss_b 0.138, un_loss_b 0.580, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 03:54:21 - INFO - Epoch 8 step 24740 eta 04:03:07: loss_a 0.179, un_loss_a 0.810, loss_b 0.389, un_loss_b 0.841, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 03:54:45 - INFO - Epoch 8 step 24760 eta 04:02:47: loss_a 0.173, un_loss_a 0.322, loss_b 0.296, un_loss_b 0.436, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 03:55:06 - INFO - Epoch 8 step 24780 eta 04:02:18: loss_a 0.092, un_loss_a 0.607, loss_b 0.213, un_loss_b 0.724, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 03:55:29 - INFO - Epoch 8 step 24800 eta 04:01:56: loss_a 0.129, un_loss_a 0.717, loss_b 0.279, un_loss_b 0.526, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 03:55:51 - INFO - Epoch 8 step 24820 eta 04:01:28: loss_a 0.056, un_loss_a 0.374, loss_b 0.177, un_loss_b 0.407, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 03:56:14 - INFO - Epoch 8 step 24840 eta 04:01:05: loss_a 0.190, un_loss_a 0.891, loss_b 0.304, un_loss_b 0.892, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:56:35 - INFO - Epoch 8 step 24860 eta 04:00:37: loss_a 0.287, un_loss_a 0.344, loss_b 0.530, un_loss_b 0.440, accuracy_a 0.875, accuracy_b 0.781
2022-05-30 03:56:59 - INFO - Epoch 8 step 24880 eta 04:00:16: loss_a 0.132, un_loss_a 0.572, loss_b 0.148, un_loss_b 0.717, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:57:21 - INFO - Epoch 8 step 24900 eta 03:59:48: loss_a 0.128, un_loss_a 0.491, loss_b 0.205, un_loss_b 0.212, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 03:57:42 - INFO - Epoch 8 step 24920 eta 03:59:19: loss_a 0.094, un_loss_a 0.286, loss_b 0.220, un_loss_b 0.479, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:58:06 - INFO - Epoch 8 step 24940 eta 03:58:58: loss_a 0.108, un_loss_a 0.450, loss_b 0.223, un_loss_b 0.384, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 03:58:27 - INFO - Epoch 8 step 24960 eta 03:58:29: loss_a 0.116, un_loss_a 0.454, loss_b 0.110, un_loss_b 0.564, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 03:58:48 - INFO - Epoch 8 step 24980 eta 03:58:01: loss_a 0.058, un_loss_a 0.385, loss_b 0.089, un_loss_b 0.519, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 03:59:12 - INFO - Epoch 8 step 25000 eta 03:57:38: loss_a 0.099, un_loss_a 0.550, loss_b 0.096, un_loss_b 0.689, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 03:59:33 - INFO - Epoch 8 step 25020 eta 03:57:10: loss_a 0.087, un_loss_a 0.736, loss_b 0.033, un_loss_b 0.952, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 03:59:55 - INFO - Epoch 8 step 25040 eta 03:56:41: loss_a 0.124, un_loss_a 0.202, loss_b 0.081, un_loss_b 0.306, accuracy_a 0.938, accuracy_b 1.000
2022-05-30 04:00:18 - INFO - Epoch 8 step 25060 eta 03:56:19: loss_a 0.087, un_loss_a 0.538, loss_b 0.067, un_loss_b 0.621, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:00:39 - INFO - Epoch 8 step 25080 eta 03:55:50: loss_a 0.171, un_loss_a 0.368, loss_b 0.266, un_loss_b 0.322, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 04:01:02 - INFO - Epoch 8 step 25100 eta 03:55:28: loss_a 0.149, un_loss_a 0.432, loss_b 0.172, un_loss_b 0.681, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:01:24 - INFO - Epoch 8 step 25120 eta 03:54:59: loss_a 0.262, un_loss_a 0.393, loss_b 0.269, un_loss_b 0.326, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:01:45 - INFO - Epoch 8 step 25140 eta 03:54:31: loss_a 0.322, un_loss_a 0.293, loss_b 0.343, un_loss_b 0.672, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 04:02:09 - INFO - Epoch 8 step 25160 eta 03:54:11: loss_a 0.122, un_loss_a 0.704, loss_b 0.358, un_loss_b 0.538, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 04:02:31 - INFO - Epoch 8 step 25180 eta 03:53:43: loss_a 0.199, un_loss_a 0.446, loss_b 0.255, un_loss_b 0.245, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 04:02:52 - INFO - Epoch 8 step 25200 eta 03:53:14: loss_a 0.155, un_loss_a 1.173, loss_b 0.248, un_loss_b 0.569, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 04:03:16 - INFO - Epoch 8 step 25220 eta 03:52:53: loss_a 0.084, un_loss_a 0.209, loss_b 0.199, un_loss_b 0.261, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:03:37 - INFO - Epoch 8 step 25240 eta 03:52:25: loss_a 0.218, un_loss_a 0.643, loss_b 0.476, un_loss_b 0.892, accuracy_a 0.906, accuracy_b 0.781
2022-05-30 04:04:00 - INFO - Epoch 8 step 25260 eta 03:52:03: loss_a 0.146, un_loss_a 0.468, loss_b 0.190, un_loss_b 0.432, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:04:22 - INFO - Epoch 8 step 25280 eta 03:51:34: loss_a 0.113, un_loss_a 0.311, loss_b 0.071, un_loss_b 0.434, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:04:43 - INFO - Epoch 8 step 25300 eta 03:51:06: loss_a 0.118, un_loss_a 0.572, loss_b 0.248, un_loss_b 0.589, accuracy_a 0.969, accuracy_b 0.875
Begin Validation
2022-05-30 04:06:56 - INFO - Epoch 8 step 25308:, {'lv1_acc': 0.7745, 'lv2_acc': 0.6674, 'lv1_f1_micro': 0.7745, 'lv1_f1_macro': 0.7374, 'lv2_f1_micro': 0.6674, 'lv2_f1_macro': 0.5462, 'mean_f1': 0.6814}, {'lv1_acc': 0.7795, 'lv2_acc': 0.6714, 'lv1_f1_micro': 0.7795, 'lv1_f1_macro': 0.7457, 'lv2_f1_micro': 0.6714, 'lv2_f1_macro': 0.5515, 'mean_f1': 0.687}
/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-05-30 04:07:12 - INFO - Epoch 9 step 25320 eta 03:57:55: loss_a 0.113, un_loss_a 0.676, loss_b 0.100, un_loss_b 0.518, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:07:33 - INFO - Epoch 9 step 25340 eta 03:57:26: loss_a 0.047, un_loss_a 0.763, loss_b 0.089, un_loss_b 0.634, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:07:57 - INFO - Epoch 9 step 25360 eta 03:57:05: loss_a 0.072, un_loss_a 0.685, loss_b 0.118, un_loss_b 0.631, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:08:18 - INFO - Epoch 9 step 25380 eta 03:56:36: loss_a 0.179, un_loss_a 0.698, loss_b 0.323, un_loss_b 0.510, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 04:08:41 - INFO - Epoch 9 step 25400 eta 03:56:14: loss_a 0.088, un_loss_a 0.188, loss_b 0.123, un_loss_b 0.198, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:09:03 - INFO - Epoch 9 step 25420 eta 03:55:45: loss_a 0.072, un_loss_a 0.238, loss_b 0.169, un_loss_b 0.416, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:09:24 - INFO - Epoch 9 step 25440 eta 03:55:16: loss_a 0.148, un_loss_a 0.296, loss_b 0.252, un_loss_b 0.533, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 04:09:48 - INFO - Epoch 9 step 25460 eta 03:54:56: loss_a 0.090, un_loss_a 0.409, loss_b 0.250, un_loss_b 0.412, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 04:10:10 - INFO - Epoch 9 step 25480 eta 03:54:27: loss_a 0.146, un_loss_a 0.579, loss_b 0.174, un_loss_b 0.559, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 04:10:33 - INFO - Epoch 9 step 25500 eta 03:54:06: loss_a 0.170, un_loss_a 0.306, loss_b 0.101, un_loss_b 0.132, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 04:10:55 - INFO - Epoch 9 step 25520 eta 03:53:37: loss_a 0.050, un_loss_a 0.249, loss_b 0.057, un_loss_b 0.313, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:11:16 - INFO - Epoch 9 step 25540 eta 03:53:08: loss_a 0.036, un_loss_a 0.449, loss_b 0.158, un_loss_b 0.755, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:11:40 - INFO - Epoch 9 step 25560 eta 03:52:46: loss_a 0.075, un_loss_a 0.444, loss_b 0.278, un_loss_b 0.373, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:12:01 - INFO - Epoch 9 step 25580 eta 03:52:18: loss_a 0.060, un_loss_a 0.613, loss_b 0.091, un_loss_b 0.576, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 04:12:24 - INFO - Epoch 9 step 25600 eta 03:51:55: loss_a 0.038, un_loss_a 0.504, loss_b 0.164, un_loss_b 0.620, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 04:12:46 - INFO - Epoch 9 step 25620 eta 03:51:27: loss_a 0.024, un_loss_a 1.030, loss_b 0.146, un_loss_b 0.793, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 04:13:07 - INFO - Epoch 9 step 25640 eta 03:50:58: loss_a 0.035, un_loss_a 0.344, loss_b 0.132, un_loss_b 0.324, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:13:31 - INFO - Epoch 9 step 25660 eta 03:50:37: loss_a 0.088, un_loss_a 0.365, loss_b 0.155, un_loss_b 0.376, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 04:13:53 - INFO - Epoch 9 step 25680 eta 03:50:09: loss_a 0.128, un_loss_a 0.319, loss_b 0.380, un_loss_b 0.284, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 04:14:16 - INFO - Epoch 9 step 25700 eta 03:49:47: loss_a 0.112, un_loss_a 0.284, loss_b 0.181, un_loss_b 0.660, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 04:14:38 - INFO - Epoch 9 step 25720 eta 03:49:19: loss_a 0.060, un_loss_a 0.445, loss_b 0.089, un_loss_b 0.487, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:15:01 - INFO - Epoch 9 step 25740 eta 03:48:58: loss_a 0.132, un_loss_a 0.312, loss_b 0.330, un_loss_b 0.280, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 04:15:23 - INFO - Epoch 9 step 25760 eta 03:48:29: loss_a 0.059, un_loss_a 0.320, loss_b 0.070, un_loss_b 0.523, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:15:44 - INFO - Epoch 9 step 25780 eta 03:48:01: loss_a 0.107, un_loss_a 0.392, loss_b 0.155, un_loss_b 0.234, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:16:08 - INFO - Epoch 9 step 25800 eta 03:47:40: loss_a 0.067, un_loss_a 0.204, loss_b 0.054, un_loss_b 0.383, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:16:30 - INFO - Epoch 9 step 25820 eta 03:47:12: loss_a 0.070, un_loss_a 0.590, loss_b 0.074, un_loss_b 0.533, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:16:51 - INFO - Epoch 9 step 25840 eta 03:46:43: loss_a 0.076, un_loss_a 0.140, loss_b 0.188, un_loss_b 0.381, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:17:14 - INFO - Epoch 9 step 25860 eta 03:46:21: loss_a 0.053, un_loss_a 0.572, loss_b 0.165, un_loss_b 0.421, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 04:17:36 - INFO - Epoch 9 step 25880 eta 03:45:53: loss_a 0.123, un_loss_a 0.266, loss_b 0.157, un_loss_b 0.481, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:17:59 - INFO - Epoch 9 step 25900 eta 03:45:30: loss_a 0.098, un_loss_a 0.460, loss_b 0.125, un_loss_b 0.299, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:18:20 - INFO - Epoch 9 step 25920 eta 03:45:01: loss_a 0.098, un_loss_a 0.669, loss_b 0.106, un_loss_b 0.559, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:18:42 - INFO - Epoch 9 step 25940 eta 03:44:33: loss_a 0.066, un_loss_a 0.795, loss_b 0.236, un_loss_b 0.388, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 04:19:05 - INFO - Epoch 9 step 25960 eta 03:44:10: loss_a 0.088, un_loss_a 0.494, loss_b 0.221, un_loss_b 0.422, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:19:26 - INFO - Epoch 9 step 25980 eta 03:43:41: loss_a 0.135, un_loss_a 0.226, loss_b 0.130, un_loss_b 0.269, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:19:48 - INFO - Epoch 9 step 26000 eta 03:43:13: loss_a 0.097, un_loss_a 0.481, loss_b 0.205, un_loss_b 0.593, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 04:20:11 - INFO - Epoch 9 step 26020 eta 03:42:49: loss_a 0.049, un_loss_a 0.409, loss_b 0.092, un_loss_b 0.662, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:20:32 - INFO - Epoch 9 step 26040 eta 03:42:21: loss_a 0.067, un_loss_a 0.593, loss_b 0.109, un_loss_b 0.691, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:20:55 - INFO - Epoch 9 step 26060 eta 03:41:58: loss_a 0.115, un_loss_a 0.511, loss_b 0.069, un_loss_b 0.640, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:21:17 - INFO - Epoch 9 step 26080 eta 03:41:29: loss_a 0.059, un_loss_a 0.799, loss_b 0.084, un_loss_b 0.651, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:21:38 - INFO - Epoch 9 step 26100 eta 03:41:01: loss_a 0.100, un_loss_a 0.526, loss_b 0.122, un_loss_b 0.442, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:22:01 - INFO - Epoch 9 step 26120 eta 03:40:38: loss_a 0.037, un_loss_a 0.463, loss_b 0.091, un_loss_b 0.527, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:22:23 - INFO - Epoch 9 step 26140 eta 03:40:09: loss_a 0.199, un_loss_a 0.680, loss_b 0.136, un_loss_b 0.847, accuracy_a 0.875, accuracy_b 0.969
2022-05-30 04:22:46 - INFO - Epoch 9 step 26160 eta 03:39:46: loss_a 0.084, un_loss_a 0.561, loss_b 0.095, un_loss_b 0.568, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:23:07 - INFO - Epoch 9 step 26180 eta 03:39:18: loss_a 0.084, un_loss_a 0.582, loss_b 0.147, un_loss_b 0.595, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:23:29 - INFO - Epoch 9 step 26200 eta 03:38:49: loss_a 0.056, un_loss_a 0.530, loss_b 0.106, un_loss_b 0.767, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:23:52 - INFO - Epoch 9 step 26220 eta 03:38:26: loss_a 0.439, un_loss_a 0.668, loss_b 0.459, un_loss_b 0.790, accuracy_a 0.812, accuracy_b 0.906
2022-05-30 04:24:13 - INFO - Epoch 9 step 26240 eta 03:37:58: loss_a 0.108, un_loss_a 0.454, loss_b 0.102, un_loss_b 0.331, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:24:37 - INFO - Epoch 9 step 26260 eta 03:37:35: loss_a 0.093, un_loss_a 0.426, loss_b 0.227, un_loss_b 0.652, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:24:58 - INFO - Epoch 9 step 26280 eta 03:37:07: loss_a 0.057, un_loss_a 0.718, loss_b 0.037, un_loss_b 0.482, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 04:25:19 - INFO - Epoch 9 step 26300 eta 03:36:38: loss_a 0.065, un_loss_a 0.535, loss_b 0.124, un_loss_b 0.595, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:25:43 - INFO - Epoch 9 step 26320 eta 03:36:15: loss_a 0.098, un_loss_a 0.723, loss_b 0.382, un_loss_b 0.624, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 04:26:04 - INFO - Epoch 9 step 26340 eta 03:35:47: loss_a 0.084, un_loss_a 0.807, loss_b 0.188, un_loss_b 0.710, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:26:27 - INFO - Epoch 9 step 26360 eta 03:35:24: loss_a 0.207, un_loss_a 0.285, loss_b 0.104, un_loss_b 0.300, accuracy_a 0.906, accuracy_b 0.969
2022-05-30 04:26:49 - INFO - Epoch 9 step 26380 eta 03:34:56: loss_a 0.090, un_loss_a 0.310, loss_b 0.129, un_loss_b 0.387, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:27:11 - INFO - Epoch 9 step 26400 eta 03:34:32: loss_a 0.060, un_loss_a 0.251, loss_b 0.151, un_loss_b 0.190, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 04:27:33 - INFO - Epoch 9 step 26420 eta 03:34:04: loss_a 0.073, un_loss_a 0.520, loss_b 0.078, un_loss_b 0.588, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 04:27:54 - INFO - Epoch 9 step 26440 eta 03:33:36: loss_a 0.061, un_loss_a 0.648, loss_b 0.133, un_loss_b 0.511, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 04:28:17 - INFO - Epoch 9 step 26460 eta 03:33:12: loss_a 0.224, un_loss_a 0.441, loss_b 0.366, un_loss_b 0.558, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 04:28:39 - INFO - Epoch 9 step 26480 eta 03:32:44: loss_a 0.078, un_loss_a 0.792, loss_b 0.107, un_loss_b 0.784, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:29:00 - INFO - Epoch 9 step 26500 eta 03:32:16: loss_a 0.125, un_loss_a 0.423, loss_b 0.091, un_loss_b 0.556, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 04:29:23 - INFO - Epoch 9 step 26520 eta 03:31:53: loss_a 0.145, un_loss_a 0.614, loss_b 0.124, un_loss_b 0.576, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 04:29:45 - INFO - Epoch 9 step 26540 eta 03:31:24: loss_a 0.049, un_loss_a 0.316, loss_b 0.095, un_loss_b 0.580, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:30:08 - INFO - Epoch 9 step 26560 eta 03:31:01: loss_a 0.154, un_loss_a 0.427, loss_b 0.151, un_loss_b 0.328, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:30:29 - INFO - Epoch 9 step 26580 eta 03:30:33: loss_a 0.047, un_loss_a 0.667, loss_b 0.058, un_loss_b 0.664, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:30:51 - INFO - Epoch 9 step 26600 eta 03:30:05: loss_a 0.226, un_loss_a 0.741, loss_b 0.200, un_loss_b 0.737, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 04:31:14 - INFO - Epoch 9 step 26620 eta 03:29:42: loss_a 0.137, un_loss_a 0.498, loss_b 0.151, un_loss_b 0.572, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:31:35 - INFO - Epoch 9 step 26640 eta 03:29:13: loss_a 0.039, un_loss_a 0.244, loss_b 0.063, un_loss_b 0.318, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:31:57 - INFO - Epoch 9 step 26660 eta 03:28:45: loss_a 0.188, un_loss_a 0.857, loss_b 0.227, un_loss_b 0.613, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:32:20 - INFO - Epoch 9 step 26680 eta 03:28:22: loss_a 0.153, un_loss_a 0.281, loss_b 0.258, un_loss_b 0.352, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 04:32:41 - INFO - Epoch 9 step 26700 eta 03:27:54: loss_a 0.114, un_loss_a 0.588, loss_b 0.185, un_loss_b 0.538, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:33:04 - INFO - Epoch 9 step 26720 eta 03:27:31: loss_a 0.075, un_loss_a 0.703, loss_b 0.158, un_loss_b 0.736, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:33:26 - INFO - Epoch 9 step 26740 eta 03:27:03: loss_a 0.127, un_loss_a 0.723, loss_b 0.110, un_loss_b 0.608, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 04:33:47 - INFO - Epoch 9 step 26760 eta 03:26:34: loss_a 0.099, un_loss_a 0.338, loss_b 0.170, un_loss_b 0.231, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:34:10 - INFO - Epoch 9 step 26780 eta 03:26:11: loss_a 0.122, un_loss_a 0.231, loss_b 0.117, un_loss_b 0.311, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 04:34:32 - INFO - Epoch 9 step 26800 eta 03:25:43: loss_a 0.049, un_loss_a 0.446, loss_b 0.081, un_loss_b 0.343, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:34:55 - INFO - Epoch 9 step 26820 eta 03:25:20: loss_a 0.091, un_loss_a 0.628, loss_b 0.112, un_loss_b 0.416, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:35:16 - INFO - Epoch 9 step 26840 eta 03:24:52: loss_a 0.144, un_loss_a 0.377, loss_b 0.215, un_loss_b 0.238, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 04:35:38 - INFO - Epoch 9 step 26860 eta 03:24:24: loss_a 0.104, un_loss_a 0.375, loss_b 0.074, un_loss_b 0.395, accuracy_a 0.938, accuracy_b 1.000
2022-05-30 04:36:01 - INFO - Epoch 9 step 26880 eta 03:24:01: loss_a 0.133, un_loss_a 0.496, loss_b 0.146, un_loss_b 0.239, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 04:36:22 - INFO - Epoch 9 step 26900 eta 03:23:33: loss_a 0.213, un_loss_a 0.612, loss_b 0.196, un_loss_b 0.972, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:36:45 - INFO - Epoch 9 step 26920 eta 03:23:10: loss_a 0.092, un_loss_a 0.499, loss_b 0.111, un_loss_b 0.564, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:37:07 - INFO - Epoch 9 step 26940 eta 03:22:41: loss_a 0.046, un_loss_a 0.431, loss_b 0.096, un_loss_b 0.647, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:37:30 - INFO - Epoch 9 step 26960 eta 03:22:18: loss_a 0.095, un_loss_a 0.676, loss_b 0.290, un_loss_b 0.673, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 04:37:51 - INFO - Epoch 9 step 26980 eta 03:21:50: loss_a 0.090, un_loss_a 0.285, loss_b 0.163, un_loss_b 0.533, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:38:12 - INFO - Epoch 9 step 27000 eta 03:21:22: loss_a 0.266, un_loss_a 0.473, loss_b 0.335, un_loss_b 0.414, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 04:38:35 - INFO - Epoch 9 step 27020 eta 03:20:59: loss_a 0.112, un_loss_a 0.346, loss_b 0.244, un_loss_b 0.396, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:38:57 - INFO - Epoch 9 step 27040 eta 03:20:31: loss_a 0.119, un_loss_a 0.408, loss_b 0.046, un_loss_b 0.557, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 04:39:21 - INFO - Epoch 9 step 27060 eta 03:20:10: loss_a 0.047, un_loss_a 0.305, loss_b 0.059, un_loss_b 0.344, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:39:42 - INFO - Epoch 9 step 27080 eta 03:19:42: loss_a 0.109, un_loss_a 0.364, loss_b 0.119, un_loss_b 0.269, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:40:04 - INFO - Epoch 9 step 27100 eta 03:19:14: loss_a 0.165, un_loss_a 0.361, loss_b 0.215, un_loss_b 0.531, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:40:27 - INFO - Epoch 9 step 27120 eta 03:18:52: loss_a 0.053, un_loss_a 0.386, loss_b 0.076, un_loss_b 0.382, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:40:48 - INFO - Epoch 9 step 27140 eta 03:18:24: loss_a 0.260, un_loss_a 0.382, loss_b 0.200, un_loss_b 0.519, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 04:41:11 - INFO - Epoch 9 step 27160 eta 03:18:00: loss_a 0.130, un_loss_a 0.471, loss_b 0.318, un_loss_b 0.478, accuracy_a 0.938, accuracy_b 0.812
2022-05-30 04:41:33 - INFO - Epoch 9 step 27180 eta 03:17:32: loss_a 0.175, un_loss_a 0.776, loss_b 0.221, un_loss_b 0.544, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 04:41:54 - INFO - Epoch 9 step 27200 eta 03:17:04: loss_a 0.041, un_loss_a 0.294, loss_b 0.088, un_loss_b 0.493, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:42:17 - INFO - Epoch 9 step 27220 eta 03:16:41: loss_a 0.060, un_loss_a 0.765, loss_b 0.110, un_loss_b 0.776, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:42:38 - INFO - Epoch 9 step 27240 eta 03:16:13: loss_a 0.101, un_loss_a 0.485, loss_b 0.153, un_loss_b 0.428, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:43:00 - INFO - Epoch 9 step 27260 eta 03:15:45: loss_a 0.037, un_loss_a 0.531, loss_b 0.043, un_loss_b 0.465, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:43:23 - INFO - Epoch 9 step 27280 eta 03:15:22: loss_a 0.060, un_loss_a 0.284, loss_b 0.107, un_loss_b 0.358, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:43:44 - INFO - Epoch 9 step 27300 eta 03:14:54: loss_a 0.088, un_loss_a 0.503, loss_b 0.045, un_loss_b 0.802, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 04:44:06 - INFO - Epoch 9 step 27320 eta 03:14:26: loss_a 0.048, un_loss_a 0.496, loss_b 0.089, un_loss_b 0.421, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:44:30 - INFO - Epoch 9 step 27340 eta 03:14:05: loss_a 0.040, un_loss_a 0.608, loss_b 0.221, un_loss_b 0.474, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 04:44:51 - INFO - Epoch 9 step 27360 eta 03:13:37: loss_a 0.164, un_loss_a 0.382, loss_b 0.087, un_loss_b 0.243, accuracy_a 0.938, accuracy_b 1.000
2022-05-30 04:45:15 - INFO - Epoch 9 step 27380 eta 03:13:16: loss_a 0.127, un_loss_a 0.833, loss_b 0.269, un_loss_b 0.684, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:45:36 - INFO - Epoch 9 step 27400 eta 03:12:48: loss_a 0.128, un_loss_a 0.307, loss_b 0.113, un_loss_b 0.316, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:45:57 - INFO - Epoch 9 step 27420 eta 03:12:20: loss_a 0.129, un_loss_a 0.212, loss_b 0.209, un_loss_b 0.383, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 04:46:20 - INFO - Epoch 9 step 27440 eta 03:11:56: loss_a 0.073, un_loss_a 0.146, loss_b 0.203, un_loss_b 0.150, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 04:46:42 - INFO - Epoch 9 step 27460 eta 03:11:29: loss_a 0.136, un_loss_a 0.371, loss_b 0.217, un_loss_b 0.520, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 04:47:05 - INFO - Epoch 9 step 27480 eta 03:11:06: loss_a 0.056, un_loss_a 0.652, loss_b 0.178, un_loss_b 0.824, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:47:26 - INFO - Epoch 9 step 27500 eta 03:10:38: loss_a 0.179, un_loss_a 0.748, loss_b 0.211, un_loss_b 0.637, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 04:47:49 - INFO - Epoch 9 step 27520 eta 03:10:14: loss_a 0.141, un_loss_a 0.432, loss_b 0.049, un_loss_b 0.827, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 04:48:11 - INFO - Epoch 9 step 27540 eta 03:09:47: loss_a 0.060, un_loss_a 0.786, loss_b 0.127, un_loss_b 0.684, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 04:48:32 - INFO - Epoch 9 step 27560 eta 03:09:19: loss_a 0.131, un_loss_a 0.420, loss_b 0.098, un_loss_b 0.467, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 04:48:55 - INFO - Epoch 9 step 27580 eta 03:08:55: loss_a 0.108, un_loss_a 0.422, loss_b 0.154, un_loss_b 0.295, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:49:17 - INFO - Epoch 9 step 27600 eta 03:08:28: loss_a 0.239, un_loss_a 0.227, loss_b 0.185, un_loss_b 0.371, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 04:49:40 - INFO - Epoch 9 step 27620 eta 03:08:04: loss_a 0.219, un_loss_a 0.561, loss_b 0.427, un_loss_b 0.646, accuracy_a 0.938, accuracy_b 0.875
2022-05-30 04:50:01 - INFO - Epoch 9 step 27640 eta 03:07:36: loss_a 0.050, un_loss_a 0.716, loss_b 0.087, un_loss_b 0.822, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:50:22 - INFO - Epoch 9 step 27660 eta 03:07:09: loss_a 0.064, un_loss_a 0.776, loss_b 0.079, un_loss_b 0.512, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:50:46 - INFO - Epoch 9 step 27680 eta 03:06:46: loss_a 0.224, un_loss_a 0.439, loss_b 0.262, un_loss_b 0.347, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 04:51:07 - INFO - Epoch 9 step 27700 eta 03:06:18: loss_a 0.317, un_loss_a 0.277, loss_b 0.407, un_loss_b 0.313, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 04:51:30 - INFO - Epoch 9 step 27720 eta 03:05:55: loss_a 0.123, un_loss_a 0.712, loss_b 0.207, un_loss_b 0.478, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 04:51:51 - INFO - Epoch 9 step 27740 eta 03:05:27: loss_a 0.080, un_loss_a 0.158, loss_b 0.104, un_loss_b 0.195, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:52:13 - INFO - Epoch 9 step 27760 eta 03:04:59: loss_a 0.202, un_loss_a 0.534, loss_b 0.237, un_loss_b 0.502, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 04:52:36 - INFO - Epoch 9 step 27780 eta 03:04:37: loss_a 0.065, un_loss_a 0.492, loss_b 0.078, un_loss_b 0.422, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:52:57 - INFO - Epoch 9 step 27800 eta 03:04:09: loss_a 0.073, un_loss_a 0.558, loss_b 0.099, un_loss_b 0.383, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:53:21 - INFO - Epoch 9 step 27820 eta 03:03:46: loss_a 0.070, un_loss_a 0.585, loss_b 0.110, un_loss_b 0.598, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:53:42 - INFO - Epoch 9 step 27840 eta 03:03:18: loss_a 0.106, un_loss_a 0.389, loss_b 0.166, un_loss_b 0.359, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 04:54:04 - INFO - Epoch 9 step 27860 eta 03:02:51: loss_a 0.142, un_loss_a 0.540, loss_b 0.335, un_loss_b 0.743, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 04:54:27 - INFO - Epoch 9 step 27880 eta 03:02:28: loss_a 0.072, un_loss_a 0.646, loss_b 0.085, un_loss_b 0.347, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:54:48 - INFO - Epoch 9 step 27900 eta 03:02:00: loss_a 0.198, un_loss_a 0.344, loss_b 0.214, un_loss_b 0.490, accuracy_a 0.906, accuracy_b 0.938
2022-05-30 04:55:09 - INFO - Epoch 9 step 27920 eta 03:01:32: loss_a 0.106, un_loss_a 0.274, loss_b 0.194, un_loss_b 0.276, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 04:55:32 - INFO - Epoch 9 step 27940 eta 03:01:09: loss_a 0.103, un_loss_a 0.139, loss_b 0.145, un_loss_b 0.300, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 04:55:54 - INFO - Epoch 9 step 27960 eta 03:00:41: loss_a 0.204, un_loss_a 0.755, loss_b 0.190, un_loss_b 0.593, accuracy_a 0.906, accuracy_b 0.969
2022-05-30 04:56:17 - INFO - Epoch 9 step 27980 eta 03:00:19: loss_a 0.267, un_loss_a 0.442, loss_b 0.518, un_loss_b 0.932, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 04:56:38 - INFO - Epoch 9 step 28000 eta 02:59:51: loss_a 0.256, un_loss_a 0.393, loss_b 0.417, un_loss_b 0.298, accuracy_a 0.875, accuracy_b 0.875
2022-05-30 04:57:00 - INFO - Epoch 9 step 28020 eta 02:59:23: loss_a 0.218, un_loss_a 0.412, loss_b 0.309, un_loss_b 0.296, accuracy_a 0.938, accuracy_b 0.844
2022-05-30 04:57:23 - INFO - Epoch 9 step 28040 eta 02:59:01: loss_a 0.085, un_loss_a 0.391, loss_b 0.088, un_loss_b 0.508, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:57:44 - INFO - Epoch 9 step 28060 eta 02:58:33: loss_a 0.060, un_loss_a 0.234, loss_b 0.060, un_loss_b 0.315, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 04:58:08 - INFO - Epoch 9 step 28080 eta 02:58:10: loss_a 0.070, un_loss_a 0.627, loss_b 0.092, un_loss_b 0.443, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 04:58:29 - INFO - Epoch 9 step 28100 eta 02:57:42: loss_a 0.137, un_loss_a 0.534, loss_b 0.216, un_loss_b 0.506, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 04:58:50 - INFO - Epoch 9 step 28120 eta 02:57:15: loss_a 0.064, un_loss_a 0.247, loss_b 0.050, un_loss_b 0.847, accuracy_a 1.000, accuracy_b 1.000
Begin Validation
2022-05-30 05:00:56 - INFO - Epoch 9 step 28120:, {'lv1_acc': 0.7767, 'lv2_acc': 0.6711, 'lv1_f1_micro': 0.7767, 'lv1_f1_macro': 0.7431, 'lv2_f1_micro': 0.6711, 'lv2_f1_macro': 0.5477, 'mean_f1': 0.6846}, {'lv1_acc': 0.7814, 'lv2_acc': 0.6723, 'lv1_f1_micro': 0.7814, 'lv1_f1_macro': 0.747, 'lv2_f1_micro': 0.6723, 'lv2_f1_macro': 0.5551, 'mean_f1': 0.6889}
/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-05-30 05:01:27 - INFO - Epoch 10 step 28140 eta 03:03:33: loss_a 0.017, un_loss_a 0.158, loss_b 0.038, un_loss_b 0.153, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:01:49 - INFO - Epoch 10 step 28160 eta 03:03:05: loss_a 0.047, un_loss_a 0.644, loss_b 0.055, un_loss_b 0.563, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:02:10 - INFO - Epoch 10 step 28180 eta 03:02:37: loss_a 0.075, un_loss_a 0.563, loss_b 0.095, un_loss_b 0.849, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:02:34 - INFO - Epoch 10 step 28200 eta 03:02:15: loss_a 0.084, un_loss_a 0.496, loss_b 0.074, un_loss_b 0.523, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:02:55 - INFO - Epoch 10 step 28220 eta 03:01:47: loss_a 0.059, un_loss_a 0.507, loss_b 0.155, un_loss_b 0.243, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:03:19 - INFO - Epoch 10 step 28240 eta 03:01:26: loss_a 0.043, un_loss_a 0.328, loss_b 0.040, un_loss_b 0.577, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:03:40 - INFO - Epoch 10 step 28260 eta 03:00:58: loss_a 0.041, un_loss_a 0.221, loss_b 0.060, un_loss_b 0.290, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:04:02 - INFO - Epoch 10 step 28280 eta 03:00:30: loss_a 0.125, un_loss_a 0.473, loss_b 0.122, un_loss_b 0.425, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 05:04:26 - INFO - Epoch 10 step 28300 eta 03:00:08: loss_a 0.044, un_loss_a 0.574, loss_b 0.200, un_loss_b 0.529, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 05:04:47 - INFO - Epoch 10 step 28320 eta 02:59:41: loss_a 0.189, un_loss_a 0.527, loss_b 0.251, un_loss_b 0.332, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:05:08 - INFO - Epoch 10 step 28340 eta 02:59:13: loss_a 0.052, un_loss_a 0.566, loss_b 0.164, un_loss_b 0.474, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 05:05:32 - INFO - Epoch 10 step 28360 eta 02:58:52: loss_a 0.056, un_loss_a 0.207, loss_b 0.044, un_loss_b 0.275, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:05:54 - INFO - Epoch 10 step 28380 eta 02:58:24: loss_a 0.086, un_loss_a 0.918, loss_b 0.065, un_loss_b 0.862, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 05:06:17 - INFO - Epoch 10 step 28400 eta 02:58:01: loss_a 0.028, un_loss_a 0.369, loss_b 0.053, un_loss_b 0.384, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:06:39 - INFO - Epoch 10 step 28420 eta 02:57:34: loss_a 0.037, un_loss_a 0.326, loss_b 0.066, un_loss_b 0.140, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:07:00 - INFO - Epoch 10 step 28440 eta 02:57:06: loss_a 0.131, un_loss_a 0.550, loss_b 0.120, un_loss_b 0.633, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:07:23 - INFO - Epoch 10 step 28460 eta 02:56:44: loss_a 0.037, un_loss_a 0.457, loss_b 0.113, un_loss_b 0.339, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:07:45 - INFO - Epoch 10 step 28480 eta 02:56:16: loss_a 0.156, un_loss_a 0.428, loss_b 0.100, un_loss_b 0.444, accuracy_a 0.938, accuracy_b 1.000
2022-05-30 05:08:08 - INFO - Epoch 10 step 28500 eta 02:55:54: loss_a 0.054, un_loss_a 0.653, loss_b 0.099, un_loss_b 0.562, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:08:30 - INFO - Epoch 10 step 28520 eta 02:55:26: loss_a 0.080, un_loss_a 0.348, loss_b 0.099, un_loss_b 0.293, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:08:51 - INFO - Epoch 10 step 28540 eta 02:54:58: loss_a 0.074, un_loss_a 0.239, loss_b 0.113, un_loss_b 0.372, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 05:09:15 - INFO - Epoch 10 step 28560 eta 02:54:36: loss_a 0.054, un_loss_a 0.193, loss_b 0.073, un_loss_b 0.188, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 05:09:36 - INFO - Epoch 10 step 28580 eta 02:54:08: loss_a 0.038, un_loss_a 0.341, loss_b 0.069, un_loss_b 0.213, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:10:00 - INFO - Epoch 10 step 28600 eta 02:53:46: loss_a 0.048, un_loss_a 0.270, loss_b 0.118, un_loss_b 0.280, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:10:21 - INFO - Epoch 10 step 28620 eta 02:53:18: loss_a 0.027, un_loss_a 0.559, loss_b 0.078, un_loss_b 0.634, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:10:43 - INFO - Epoch 10 step 28640 eta 02:52:50: loss_a 0.076, un_loss_a 0.225, loss_b 0.084, un_loss_b 0.358, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:11:06 - INFO - Epoch 10 step 28660 eta 02:52:29: loss_a 0.081, un_loss_a 0.237, loss_b 0.134, un_loss_b 0.212, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:11:28 - INFO - Epoch 10 step 28680 eta 02:52:01: loss_a 0.091, un_loss_a 0.377, loss_b 0.032, un_loss_b 0.311, accuracy_a 0.938, accuracy_b 1.000
2022-05-30 05:11:51 - INFO - Epoch 10 step 28700 eta 02:51:39: loss_a 0.101, un_loss_a 0.257, loss_b 0.136, un_loss_b 0.535, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:12:13 - INFO - Epoch 10 step 28720 eta 02:51:11: loss_a 0.078, un_loss_a 0.908, loss_b 0.163, un_loss_b 0.617, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:12:36 - INFO - Epoch 10 step 28740 eta 02:50:49: loss_a 0.074, un_loss_a 0.801, loss_b 0.171, un_loss_b 0.589, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 05:12:58 - INFO - Epoch 10 step 28760 eta 02:50:21: loss_a 0.111, un_loss_a 0.361, loss_b 0.250, un_loss_b 0.411, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 05:13:19 - INFO - Epoch 10 step 28780 eta 02:49:54: loss_a 0.035, un_loss_a 0.766, loss_b 0.029, un_loss_b 0.572, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:13:42 - INFO - Epoch 10 step 28800 eta 02:49:31: loss_a 0.136, un_loss_a 0.256, loss_b 0.246, un_loss_b 0.266, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:14:04 - INFO - Epoch 10 step 28820 eta 02:49:03: loss_a 0.052, un_loss_a 0.627, loss_b 0.129, un_loss_b 0.345, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:14:27 - INFO - Epoch 10 step 28840 eta 02:48:41: loss_a 0.131, un_loss_a 0.417, loss_b 0.242, un_loss_b 0.505, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:14:49 - INFO - Epoch 10 step 28860 eta 02:48:13: loss_a 0.245, un_loss_a 0.648, loss_b 0.306, un_loss_b 0.412, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 05:15:10 - INFO - Epoch 10 step 28880 eta 02:47:45: loss_a 0.057, un_loss_a 0.246, loss_b 0.124, un_loss_b 0.396, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:15:33 - INFO - Epoch 10 step 28900 eta 02:47:23: loss_a 0.089, un_loss_a 0.313, loss_b 0.136, un_loss_b 0.376, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:15:55 - INFO - Epoch 10 step 28920 eta 02:46:55: loss_a 0.086, un_loss_a 0.756, loss_b 0.243, un_loss_b 0.887, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:16:16 - INFO - Epoch 10 step 28940 eta 02:46:28: loss_a 0.092, un_loss_a 0.461, loss_b 0.206, un_loss_b 0.486, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 05:16:40 - INFO - Epoch 10 step 28960 eta 02:46:05: loss_a 0.093, un_loss_a 0.366, loss_b 0.201, un_loss_b 0.384, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 05:17:01 - INFO - Epoch 10 step 28980 eta 02:45:37: loss_a 0.183, un_loss_a 0.468, loss_b 0.182, un_loss_b 0.525, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 05:17:22 - INFO - Epoch 10 step 29000 eta 02:45:10: loss_a 0.102, un_loss_a 0.578, loss_b 0.144, un_loss_b 0.602, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 05:17:46 - INFO - Epoch 10 step 29020 eta 02:44:47: loss_a 0.068, un_loss_a 0.527, loss_b 0.073, un_loss_b 0.703, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:18:07 - INFO - Epoch 10 step 29040 eta 02:44:20: loss_a 0.183, un_loss_a 0.487, loss_b 0.163, un_loss_b 0.264, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 05:18:31 - INFO - Epoch 10 step 29060 eta 02:43:57: loss_a 0.077, un_loss_a 0.585, loss_b 0.104, un_loss_b 0.370, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:18:52 - INFO - Epoch 10 step 29080 eta 02:43:30: loss_a 0.073, un_loss_a 0.257, loss_b 0.170, un_loss_b 0.224, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:19:14 - INFO - Epoch 10 step 29100 eta 02:43:02: loss_a 0.069, un_loss_a 0.605, loss_b 0.069, un_loss_b 0.820, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 05:19:37 - INFO - Epoch 10 step 29120 eta 02:42:40: loss_a 0.070, un_loss_a 0.300, loss_b 0.086, un_loss_b 0.303, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:19:58 - INFO - Epoch 10 step 29140 eta 02:42:12: loss_a 0.010, un_loss_a 0.752, loss_b 0.021, un_loss_b 1.033, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:20:22 - INFO - Epoch 10 step 29160 eta 02:41:50: loss_a 0.028, un_loss_a 0.521, loss_b 0.125, un_loss_b 0.455, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:20:43 - INFO - Epoch 10 step 29180 eta 02:41:22: loss_a 0.141, un_loss_a 0.285, loss_b 0.191, un_loss_b 0.365, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:21:05 - INFO - Epoch 10 step 29200 eta 02:40:54: loss_a 0.124, un_loss_a 0.178, loss_b 0.173, un_loss_b 0.240, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 05:21:28 - INFO - Epoch 10 step 29220 eta 02:40:31: loss_a 0.071, un_loss_a 0.345, loss_b 0.077, un_loss_b 0.465, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 05:21:49 - INFO - Epoch 10 step 29240 eta 02:40:04: loss_a 0.140, un_loss_a 0.387, loss_b 0.211, un_loss_b 0.530, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:22:12 - INFO - Epoch 10 step 29260 eta 02:39:41: loss_a 0.080, un_loss_a 0.416, loss_b 0.140, un_loss_b 0.555, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:22:34 - INFO - Epoch 10 step 29280 eta 02:39:14: loss_a 0.042, un_loss_a 0.537, loss_b 0.136, un_loss_b 0.607, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 05:22:55 - INFO - Epoch 10 step 29300 eta 02:38:46: loss_a 0.041, un_loss_a 0.612, loss_b 0.082, un_loss_b 0.445, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:23:19 - INFO - Epoch 10 step 29320 eta 02:38:24: loss_a 0.114, un_loss_a 0.314, loss_b 0.124, un_loss_b 0.380, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:23:40 - INFO - Epoch 10 step 29340 eta 02:37:56: loss_a 0.093, un_loss_a 0.852, loss_b 0.173, un_loss_b 0.749, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:24:03 - INFO - Epoch 10 step 29360 eta 02:37:33: loss_a 0.072, un_loss_a 0.830, loss_b 0.062, un_loss_b 0.710, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 05:24:25 - INFO - Epoch 10 step 29380 eta 02:37:06: loss_a 0.027, un_loss_a 0.537, loss_b 0.060, un_loss_b 0.604, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:24:48 - INFO - Epoch 10 step 29400 eta 02:36:43: loss_a 0.100, un_loss_a 0.257, loss_b 0.152, un_loss_b 0.160, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:25:10 - INFO - Epoch 10 step 29420 eta 02:36:16: loss_a 0.048, un_loss_a 0.714, loss_b 0.141, un_loss_b 0.682, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:25:31 - INFO - Epoch 10 step 29440 eta 02:35:48: loss_a 0.062, un_loss_a 0.637, loss_b 0.185, un_loss_b 0.431, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 05:25:54 - INFO - Epoch 10 step 29460 eta 02:35:26: loss_a 0.081, un_loss_a 0.593, loss_b 0.121, un_loss_b 0.436, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:26:16 - INFO - Epoch 10 step 29480 eta 02:34:58: loss_a 0.078, un_loss_a 0.206, loss_b 0.060, un_loss_b 0.106, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:26:39 - INFO - Epoch 10 step 29500 eta 02:34:35: loss_a 0.147, un_loss_a 0.448, loss_b 0.126, un_loss_b 0.419, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:27:00 - INFO - Epoch 10 step 29520 eta 02:34:08: loss_a 0.086, un_loss_a 0.190, loss_b 0.175, un_loss_b 0.291, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:27:22 - INFO - Epoch 10 step 29540 eta 02:33:40: loss_a 0.186, un_loss_a 0.384, loss_b 0.157, un_loss_b 0.388, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 05:27:45 - INFO - Epoch 10 step 29560 eta 02:33:18: loss_a 0.083, un_loss_a 0.227, loss_b 0.106, un_loss_b 0.246, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:28:07 - INFO - Epoch 10 step 29580 eta 02:32:51: loss_a 0.059, un_loss_a 0.405, loss_b 0.081, un_loss_b 0.282, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:28:28 - INFO - Epoch 10 step 29600 eta 02:32:23: loss_a 0.063, un_loss_a 0.228, loss_b 0.043, un_loss_b 0.121, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:28:51 - INFO - Epoch 10 step 29620 eta 02:32:00: loss_a 0.086, un_loss_a 0.291, loss_b 0.273, un_loss_b 0.310, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 05:29:13 - INFO - Epoch 10 step 29640 eta 02:31:33: loss_a 0.168, un_loss_a 0.583, loss_b 0.085, un_loss_b 0.423, accuracy_a 0.938, accuracy_b 0.969
2022-05-30 05:29:36 - INFO - Epoch 10 step 29660 eta 02:31:10: loss_a 0.067, un_loss_a 0.395, loss_b 0.208, un_loss_b 0.297, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 05:29:58 - INFO - Epoch 10 step 29680 eta 02:30:43: loss_a 0.124, un_loss_a 0.387, loss_b 0.165, un_loss_b 0.289, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:30:19 - INFO - Epoch 10 step 29700 eta 02:30:16: loss_a 0.064, un_loss_a 0.261, loss_b 0.076, un_loss_b 0.215, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 05:30:43 - INFO - Epoch 10 step 29720 eta 02:29:54: loss_a 0.083, un_loss_a 0.618, loss_b 0.074, un_loss_b 0.597, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 05:31:04 - INFO - Epoch 10 step 29740 eta 02:29:27: loss_a 0.048, un_loss_a 0.610, loss_b 0.047, un_loss_b 0.601, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 05:31:26 - INFO - Epoch 10 step 29760 eta 02:29:00: loss_a 0.052, un_loss_a 0.318, loss_b 0.056, un_loss_b 0.221, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:31:49 - INFO - Epoch 10 step 29780 eta 02:28:38: loss_a 0.092, un_loss_a 0.328, loss_b 0.082, un_loss_b 0.398, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:32:11 - INFO - Epoch 10 step 29800 eta 02:28:10: loss_a 0.186, un_loss_a 0.617, loss_b 0.113, un_loss_b 0.423, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:32:34 - INFO - Epoch 10 step 29820 eta 02:27:48: loss_a 0.117, un_loss_a 0.495, loss_b 0.158, un_loss_b 0.462, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:32:55 - INFO - Epoch 10 step 29840 eta 02:27:20: loss_a 0.120, un_loss_a 0.110, loss_b 0.151, un_loss_b 0.094, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:33:17 - INFO - Epoch 10 step 29860 eta 02:26:53: loss_a 0.088, un_loss_a 0.260, loss_b 0.115, un_loss_b 0.500, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:33:40 - INFO - Epoch 10 step 29880 eta 02:26:30: loss_a 0.026, un_loss_a 0.456, loss_b 0.044, un_loss_b 0.652, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:34:02 - INFO - Epoch 10 step 29900 eta 02:26:03: loss_a 0.078, un_loss_a 0.444, loss_b 0.068, un_loss_b 0.485, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:34:25 - INFO - Epoch 10 step 29920 eta 02:25:41: loss_a 0.126, un_loss_a 0.348, loss_b 0.324, un_loss_b 0.583, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 05:34:46 - INFO - Epoch 10 step 29940 eta 02:25:13: loss_a 0.019, un_loss_a 0.370, loss_b 0.147, un_loss_b 0.237, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:35:08 - INFO - Epoch 10 step 29960 eta 02:24:46: loss_a 0.155, un_loss_a 0.473, loss_b 0.125, un_loss_b 0.274, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:35:31 - INFO - Epoch 10 step 29980 eta 02:24:24: loss_a 0.058, un_loss_a 0.306, loss_b 0.127, un_loss_b 0.403, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:35:53 - INFO - Epoch 10 step 30000 eta 02:23:57: loss_a 0.054, un_loss_a 0.442, loss_b 0.207, un_loss_b 0.441, accuracy_a 1.000, accuracy_b 0.906
2022-05-30 05:36:16 - INFO - Epoch 10 step 30020 eta 02:23:35: loss_a 0.045, un_loss_a 0.490, loss_b 0.091, un_loss_b 0.393, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:36:38 - INFO - Epoch 10 step 30040 eta 02:23:08: loss_a 0.048, un_loss_a 0.680, loss_b 0.077, un_loss_b 0.619, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:37:01 - INFO - Epoch 10 step 30060 eta 02:22:45: loss_a 0.040, un_loss_a 0.531, loss_b 0.064, un_loss_b 0.825, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:37:22 - INFO - Epoch 10 step 30080 eta 02:22:18: loss_a 0.068, un_loss_a 0.564, loss_b 0.083, un_loss_b 0.683, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:37:46 - INFO - Epoch 10 step 30100 eta 02:21:56: loss_a 0.078, un_loss_a 0.229, loss_b 0.172, un_loss_b 0.223, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:38:07 - INFO - Epoch 10 step 30120 eta 02:21:28: loss_a 0.148, un_loss_a 0.557, loss_b 0.117, un_loss_b 0.669, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:38:29 - INFO - Epoch 10 step 30140 eta 02:21:01: loss_a 0.073, un_loss_a 0.630, loss_b 0.084, un_loss_b 0.491, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:38:52 - INFO - Epoch 10 step 30160 eta 02:20:39: loss_a 0.075, un_loss_a 0.415, loss_b 0.078, un_loss_b 0.536, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:39:14 - INFO - Epoch 10 step 30180 eta 02:20:11: loss_a 0.061, un_loss_a 0.428, loss_b 0.047, un_loss_b 0.423, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:39:35 - INFO - Epoch 10 step 30200 eta 02:19:44: loss_a 0.118, un_loss_a 0.431, loss_b 0.123, un_loss_b 0.670, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:39:58 - INFO - Epoch 10 step 30220 eta 02:19:22: loss_a 0.041, un_loss_a 0.555, loss_b 0.070, un_loss_b 0.644, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:40:20 - INFO - Epoch 10 step 30240 eta 02:18:54: loss_a 0.191, un_loss_a 0.856, loss_b 0.161, un_loss_b 0.561, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 05:40:41 - INFO - Epoch 10 step 30260 eta 02:18:27: loss_a 0.116, un_loss_a 0.519, loss_b 0.191, un_loss_b 0.565, accuracy_a 0.938, accuracy_b 0.938
2022-05-30 05:41:04 - INFO - Epoch 10 step 30280 eta 02:18:04: loss_a 0.143, un_loss_a 0.321, loss_b 0.144, un_loss_b 0.373, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:41:26 - INFO - Epoch 10 step 30300 eta 02:17:37: loss_a 0.075, un_loss_a 0.341, loss_b 0.105, un_loss_b 0.381, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:41:49 - INFO - Epoch 10 step 30320 eta 02:17:15: loss_a 0.047, un_loss_a 0.505, loss_b 0.069, un_loss_b 0.636, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:42:11 - INFO - Epoch 10 step 30340 eta 02:16:48: loss_a 0.091, un_loss_a 0.375, loss_b 0.096, un_loss_b 0.293, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 05:42:32 - INFO - Epoch 10 step 30360 eta 02:16:20: loss_a 0.044, un_loss_a 0.416, loss_b 0.047, un_loss_b 0.374, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:42:56 - INFO - Epoch 10 step 30380 eta 02:15:59: loss_a 0.058, un_loss_a 0.313, loss_b 0.062, un_loss_b 0.352, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:43:17 - INFO - Epoch 10 step 30400 eta 02:15:31: loss_a 0.048, un_loss_a 0.395, loss_b 0.143, un_loss_b 0.457, accuracy_a 1.000, accuracy_b 0.938
2022-05-30 05:43:41 - INFO - Epoch 10 step 30420 eta 02:15:09: loss_a 0.121, un_loss_a 0.390, loss_b 0.116, un_loss_b 0.595, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:44:02 - INFO - Epoch 10 step 30440 eta 02:14:42: loss_a 0.132, un_loss_a 0.445, loss_b 0.071, un_loss_b 0.410, accuracy_a 0.938, accuracy_b 1.000
2022-05-30 05:44:24 - INFO - Epoch 10 step 30460 eta 02:14:15: loss_a 0.083, un_loss_a 0.343, loss_b 0.076, un_loss_b 0.411, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 05:44:47 - INFO - Epoch 10 step 30480 eta 02:13:53: loss_a 0.015, un_loss_a 0.182, loss_b 0.117, un_loss_b 0.130, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:45:08 - INFO - Epoch 10 step 30500 eta 02:13:26: loss_a 0.107, un_loss_a 0.553, loss_b 0.214, un_loss_b 0.589, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 05:45:32 - INFO - Epoch 10 step 30520 eta 02:13:04: loss_a 0.058, un_loss_a 0.472, loss_b 0.053, un_loss_b 0.620, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:45:53 - INFO - Epoch 10 step 30540 eta 02:12:37: loss_a 0.057, un_loss_a 0.276, loss_b 0.056, un_loss_b 0.517, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:46:15 - INFO - Epoch 10 step 30560 eta 02:12:10: loss_a 0.130, un_loss_a 0.417, loss_b 0.184, un_loss_b 0.444, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:46:38 - INFO - Epoch 10 step 30580 eta 02:11:48: loss_a 0.058, un_loss_a 0.324, loss_b 0.058, un_loss_b 0.281, accuracy_a 0.969, accuracy_b 1.000
2022-05-30 05:47:00 - INFO - Epoch 10 step 30600 eta 02:11:21: loss_a 0.218, un_loss_a 0.384, loss_b 0.209, un_loss_b 0.591, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 05:47:23 - INFO - Epoch 10 step 30620 eta 02:10:58: loss_a 0.177, un_loss_a 0.551, loss_b 0.292, un_loss_b 0.517, accuracy_a 0.906, accuracy_b 0.906
2022-05-30 05:47:45 - INFO - Epoch 10 step 30640 eta 02:10:31: loss_a 0.120, un_loss_a 0.630, loss_b 0.262, un_loss_b 0.425, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 05:48:06 - INFO - Epoch 10 step 30660 eta 02:10:04: loss_a 0.105, un_loss_a 0.513, loss_b 0.136, un_loss_b 0.418, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:48:29 - INFO - Epoch 10 step 30680 eta 02:09:42: loss_a 0.185, un_loss_a 0.422, loss_b 0.329, un_loss_b 0.632, accuracy_a 0.969, accuracy_b 0.875
2022-05-30 05:48:51 - INFO - Epoch 10 step 30700 eta 02:09:14: loss_a 0.066, un_loss_a 0.332, loss_b 0.139, un_loss_b 0.389, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:49:14 - INFO - Epoch 10 step 30720 eta 02:08:52: loss_a 0.097, un_loss_a 0.826, loss_b 0.124, un_loss_b 1.123, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:49:36 - INFO - Epoch 10 step 30740 eta 02:08:25: loss_a 0.040, un_loss_a 0.706, loss_b 0.069, un_loss_b 0.866, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:49:59 - INFO - Epoch 10 step 30760 eta 02:08:02: loss_a 0.124, un_loss_a 0.478, loss_b 0.130, un_loss_b 0.393, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:50:20 - INFO - Epoch 10 step 30780 eta 02:07:35: loss_a 0.157, un_loss_a 0.265, loss_b 0.182, un_loss_b 0.178, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:50:42 - INFO - Epoch 10 step 30800 eta 02:07:08: loss_a 0.161, un_loss_a 0.408, loss_b 0.339, un_loss_b 0.239, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 05:51:05 - INFO - Epoch 10 step 30820 eta 02:06:46: loss_a 0.084, un_loss_a 0.551, loss_b 0.144, un_loss_b 0.427, accuracy_a 0.969, accuracy_b 0.906
2022-05-30 05:51:27 - INFO - Epoch 10 step 30840 eta 02:06:19: loss_a 0.074, un_loss_a 0.255, loss_b 0.205, un_loss_b 0.119, accuracy_a 0.969, accuracy_b 0.938
2022-05-30 05:51:48 - INFO - Epoch 10 step 30860 eta 02:05:52: loss_a 0.118, un_loss_a 0.466, loss_b 0.122, un_loss_b 0.578, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:52:11 - INFO - Epoch 10 step 30880 eta 02:05:29: loss_a 0.022, un_loss_a 0.259, loss_b 0.033, un_loss_b 0.230, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:52:33 - INFO - Epoch 10 step 30900 eta 02:05:02: loss_a 0.098, un_loss_a 0.298, loss_b 0.107, un_loss_b 0.430, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:52:56 - INFO - Epoch 10 step 30920 eta 02:04:40: loss_a 0.031, un_loss_a 0.524, loss_b 0.115, un_loss_b 0.430, accuracy_a 1.000, accuracy_b 0.938
Begin Validation
2022-05-30 05:55:12 - INFO - Epoch 10 step 30932:, {'lv1_acc': 0.7766, 'lv2_acc': 0.6736, 'lv1_f1_micro': 0.7766, 'lv1_f1_macro': 0.7452, 'lv2_f1_micro': 0.6736, 'lv2_f1_macro': 0.5517, 'mean_f1': 0.6868}, {'lv1_acc': 0.7814, 'lv2_acc': 0.6757, 'lv1_f1_micro': 0.7814, 'lv1_f1_macro': 0.75, 'lv2_f1_micro': 0.6757, 'lv2_f1_macro': 0.5517, 'mean_f1': 0.6897}
/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
2022-05-30 05:55:24 - INFO - Epoch 11 step 30940 eta 02:09:47: loss_a 0.057, un_loss_a 0.588, loss_b 0.192, un_loss_b 0.348, accuracy_a 0.969, accuracy_b 0.969
2022-05-30 05:55:46 - INFO - Epoch 11 step 30960 eta 02:09:19: loss_a 0.082, un_loss_a 0.507, loss_b 0.094, un_loss_b 0.572, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:56:09 - INFO - Epoch 11 step 30980 eta 02:08:57: loss_a 0.141, un_loss_a 0.397, loss_b 0.272, un_loss_b 0.495, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 05:56:31 - INFO - Epoch 11 step 31000 eta 02:08:30: loss_a 0.121, un_loss_a 0.192, loss_b 0.162, un_loss_b 0.203, accuracy_a 0.938, accuracy_b 0.906
2022-05-30 05:56:54 - INFO - Epoch 11 step 31020 eta 02:08:08: loss_a 0.048, un_loss_a 0.493, loss_b 0.118, un_loss_b 0.565, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:57:16 - INFO - Epoch 11 step 31040 eta 02:07:41: loss_a 0.043, un_loss_a 0.232, loss_b 0.094, un_loss_b 0.192, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:57:37 - INFO - Epoch 11 step 31060 eta 02:07:14: loss_a 0.033, un_loss_a 0.522, loss_b 0.035, un_loss_b 0.565, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:58:01 - INFO - Epoch 11 step 31080 eta 02:06:51: loss_a 0.058, un_loss_a 0.307, loss_b 0.056, un_loss_b 0.454, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:58:22 - INFO - Epoch 11 step 31100 eta 02:06:24: loss_a 0.024, un_loss_a 0.658, loss_b 0.068, un_loss_b 0.451, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:58:46 - INFO - Epoch 11 step 31120 eta 02:06:01: loss_a 0.086, un_loss_a 0.568, loss_b 0.170, un_loss_b 0.410, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:59:07 - INFO - Epoch 11 step 31140 eta 02:05:34: loss_a 0.030, un_loss_a 0.158, loss_b 0.065, un_loss_b 0.209, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 05:59:28 - INFO - Epoch 11 step 31160 eta 02:05:06: loss_a 0.041, un_loss_a 0.293, loss_b 0.067, un_loss_b 0.442, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 05:59:52 - INFO - Epoch 11 step 31180 eta 02:04:44: loss_a 0.059, un_loss_a 0.540, loss_b 0.060, un_loss_b 0.462, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 06:00:13 - INFO - Epoch 11 step 31200 eta 02:04:17: loss_a 0.019, un_loss_a 0.259, loss_b 0.033, un_loss_b 0.648, accuracy_a 1.000, accuracy_b 1.000
2022-05-30 06:00:37 - INFO - Epoch 11 step 31220 eta 02:03:54: loss_a 0.030, un_loss_a 0.089, loss_b 0.106, un_loss_b 0.100, accuracy_a 1.000, accuracy_b 0.969
2022-05-30 06:00:58 - INFO - Epoch 11 step 31240 eta 02:03:27: loss_a 0.056, un_loss_a 0.465, loss_b 0.076, un_loss_b 0.561, accuracy_a 1.000, accuracy_b 1.000
Traceback (most recent call last):
  File "main.py", line 179, in <module>
    
  File "main.py", line 175, in main
    setup_seed(args)
  File "main.py", line 86, in train_and_validate
    model.train()
  File "/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 168, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py", line 178, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 86, in parallel_apply
    output.reraise()
  File "/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/_utils.py", line 434, in reraise
    raise exception
TypeError: Caught TypeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zhangjglab01/daoan/WeChat/challenge/model.py", line 85, in forward
    un_output_a = self.model_a(unlabel_inputs)
  File "/home/zhangjglab01/miniconda3/envs/seg/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zhangjglab01/daoan/WeChat/challenge/model.py", line 30, in forward
    batch['title_input'], batch['frame_input'], batch['title_mask'], batch['frame_mask']
TypeError: 'NoneType' object is not subscriptable

